Reading list:   

We suggest the following reading list. These papers can be skimmed through before the tutorial, and are also well-served as reading material for after the tutorial. A more comprehensive reading list can be found in the multimodal ML courses at CMU, see https://cmu-multicomp-lab.github.io/adv-mmml-course/spring2022/ and https://cmu-multicomp-lab.github. io/mmml-course/fall2020/ for more details.  

1. General: Fundamentals of Multimodal Machine Learning: A Taxonomy and Open Challenges (Liang et al., 2022) 
2. General: Multimodal Machine Learning: A Survey and Taxonomy (Baltrusaitis et al., 2019) 
3. General: Representation learning: A review and new perspectives (Bengio et al., 2013) 
4. Representation: Multiplicative Interactions and Where to Find Them (Jayakumar et al., 2020) 
5. Representation: Multimodal Learning with Deep Boltzmann Machines (Srivastava and Salakhutdinov, 2014) 
6. Representation: Learning Factorized Multimodal Representations (Tsai et al., 2019) 
7. Alignment: Decoupling the Role of Data, Attention, and Losses in Multimodal Transformers (Hendricks et al., 2021) 
8. Alignment: Deep canonical correlation analysis (Andrew et al., 2013) 
9. Transference: Vokenization: Improving Language Understanding via Contextualized, Visually-Grounded Supervision (Tan and Bansal, 2020) 
10. Transference: Foundations of Multimodal Colearning (Zadeh et al., 2020) 
11. Reasoning: The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision (Mao et al., 2018) 
12. Reasoning: A Survey of Reinforcement Learning Informed by Natural Language (Luketina et al., 2019) 
13. Reasoning: VQA-LOL: Visual Question Answering Under the Lens of Logic (Gokhale et al., 2020) 
14. Generation: Cross-modal Coherence Modeling for Caption Generation (Alikhani et al., 2020) 
15. Generation: Zero-shot Text-to-Image Generation (Ramesh et al., 2021) 
16. Quantification: MultiBench: Multiscale Benchmarks for Multimodal Representation Learning (Liang et al., 2021) 
17. Quantification: M2Lens: Visualizing and Explaining Multimodal Models for Sentiment Analysis (Wang et al., 2021) 
18. Quantification: Women also Snowboard: Overcoming Bias in Captioning Models (Hendricks et al., 2018) 