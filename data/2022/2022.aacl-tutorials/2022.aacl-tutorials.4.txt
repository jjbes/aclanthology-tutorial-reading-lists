Breadth and Reading List  

This tutorial draws on a wealth of both theory and applied research in multimodal semantics, including not only the central meaning representation work mentioned above (Copestake et al., 2005; Banarescu et al., 2013; Cooper and Ginzburg, 2015; Pustejovsky et al., 2019), but also gesture semantics and situated dialogue (Kendon, 2004; Lascarides and Stone, 2006, 2009; Kelleher and Kruijff, 2006), and qualitative spatiotemporal reasoning (Freksa, 1991; Forbus et al., 1991; Zimmermann and Freksa, 1996; Cohn and Renz, 2008). We bring these diverse areas together in the modeling language VoxML (Pustejovsky and Krishnaswamy, 2016), and this tutorial will demonstrate how to exploit the strengths of both meaning representations and data-driven multimodal methods to create agents that reason with vision, language, action, and gesture about the environments they inhabit and share with human beings. 
Suggested reading is below:  

• L. Banarescu, et al. (2013). Abstract meaning representation for sembanking. In Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse, pages 178–186. https://aclanthology. org/W13-2322.pdf 
• A. Copestake, et al. (2005). Minimal recursion semantics: An introduction. Research on Language and Computation, 3(2):281–332. https://doi.org/10.1007/ s11168-006-6327-9 
• R. Cooper and J. Ginzburg. (2015). Type theory with records for natural language semantics. The Handbook of Contemporary Semantic Theory, pages 375–407. https: //doi.org/10.1002/9781118882139.ch12 
• A. Lascarides and M. Stone. (2009). A formal semantic analysis of gesture. Journal of Semantics, 26(4), 393-449. https://homepages.inf.ed.ac.uk/alex/ papers/gesture_formal.pdf 
• K. Alahverdzhieva, et al. Aligning speech and co-speech gesture in a constraint-based grammar. https://jlm.ipipan.waw.pl/index. php/JLM/article/view/167/179 
• The qualitative spatial dynamics of motion in language. J. Pustejovsky, and J. L. Moszkowicz. (2011). Spatial Cognition & Computation 11, no. 1 (2011): 1544. http://www.cs-135.org/wp-content/ uploads/2017/12/SCC-2011.pdf 25
• J. Pustejovsky and N. Krishnaswamy (2021). Situated Meaning in Multimodal Dialogue: Human-Robot and Human-Computer Interactions, in TAL Volume 61 issue 3, pp 17-41. https://www.atala.org/sites/default/ files/TAL-61-3-1_Pustejovsky.pdf 
• J. Pustejovsky and N. Krishnaswamy (2021). Embodied Human Computer Interaction, Künstliche Intelligenz, Springer. https://doi. org/10.1007/s13218-021-00727-5 