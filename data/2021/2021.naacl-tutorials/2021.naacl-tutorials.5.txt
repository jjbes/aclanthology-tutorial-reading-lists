Reading List

Reading the following papers is nice to have but not required for attendance.
• Hierarchical attention for classification (Yang et al., 2016)
• Graph network for question answering (Fang et al., 2019)
• Survey of long sequence transformers (Tay et al., 2020)
• Extractive/Abstractive summarization (Subramanian et al., 2019)