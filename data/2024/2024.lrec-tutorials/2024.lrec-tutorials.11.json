{
    "2024.lrec-tutorials.11": {
        "title": "Tutorial Proposal: Hallucination in Large Language Models",
        "author": "Vipula Rawte, Aman Chadha, Amit Sheth, Amitava Das",
        "year": 2024,
        "url": "https://aclanthology.org/2024.lrec-tutorials.11",
        "doi": null,
        "abstract": "In the fast-paced domain of Large Language Models (LLMs), the issue of hallucination is a prominent challenge. Despite continuous endeavors to address this concern, it remains a highly active area of research within the LLM landscape. Grasping the intricacies of this problem can be daunting, especially for those new to the field. This tutorial aims to bridge this knowledge gap by introducing the emerging realm of hallucination in LLMs. It will comprehensively explore the key aspects of hallucination, including benchmarking, detection, and mitigation techniques. Furthermore, we will delve into the specific constraints and shortcomings of current approaches, providing valuable insights to guide future research efforts for participants.",
        "readingList": [
            {
                "sectionName": "Hallucination in Large Language Models",
                "subsectionName": null,
                "referencesIds": [
                    "d00735241af700d21762d2f3ca00d920241a15a4",
                    "396305230ddcf915b19a19683a89e34d76321a33"
                ]
            },
            {
                "sectionName": "Hallucination in Large Foundation Models",
                "subsectionName": null,
                "referencesIds": [
                    "71bc0c97c20fffce796a355b16bd202987260029"
                ]
            }
        ]
    }
}