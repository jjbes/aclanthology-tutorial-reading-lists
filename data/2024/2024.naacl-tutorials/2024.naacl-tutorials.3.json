{
    "2024.naacl-tutorials.3": {
        "title": "Explanation in the Era of Large Language Models",
        "author": "Zining Zhu, Hanjie Chen, Xi Ye, Qing Lyu, Chenhao Tan, Ana Marasovic, Sarah Wiegreffe",
        "year": 2024,
        "url": "https://aclanthology.org/2024.naacl-tutorials.3",
        "doi": null,
        "abstract": "Explanation has long been a part of communications, where humans use language to elucidate each other and transmit information about the mechanisms of events. There have been numerous works that study the structures of the explanations and their utility to humans. At the same time, explanation relates to a collection of research directions in natural language processing (and more broadly, computer vision and machine learning) where researchers develop computational approaches to explain the (usually deep neural network) models. Explanation has received rising attention. In recent months, the advance of large language models (LLMs) provides unprecedented opportunities to leverage their reasoning abilities, both as tools to produce explanations and as the subjects of explanation analysis. On the other hand, the sheer sizes and the opaque nature of LLMs introduce challenges to the explanation methods. In this tutorial, we intend to review these opportunities and challenges of explanations in the era of LLMs, connect lines of research previously studied by different research groups, and hopefully spark thoughts of new research directions",
        "readingList": [
            {
                "sectionName": "Psychology of reasoning and explanations",
                "subsectionName": null,
                "referencesIds": [
                    "f5b1b05e8313aee94ccd98e80eab3ec56dbd2c97",
                    "49caff587dc7e08913eed9acf407bd3d4db7e363",
                    "c75acce5a6267b49f0d99e1d6d1cd2670067ce44",
                    null,
                    "e89dfa306723e8ef031765e9c44e5f6f94fd8fda"
                ]
            },
            {
                "sectionName": "Quality of explanations",
                "subsectionName": null,
                "referencesIds": [
                    "866b6c8285b8cb6e6bdef5edb8933ee2f4aebd66",
                    "faf565a1c2287279166eb55df68361b0a5d185d8",
                    "3d35362c4afcf9319e59fd3e2365e0b509791e1d",
                    "087dd95e13efd47aef2a6582e6801b39fc0f83d8",
                    "087087d91598aa62a11061ed156f8f6e699a7930",
                    "ab72b242834192b39c245d76b40adae903c7dd28",
                    "4d6e6bd7b9b3aface4a2a8908d74c99634cb2479",
                    "285d13bf3cbe6a8a0f164f584d84f8b74067271f",
                    "17f9fea1d9fd31d111a1eb8f6fc7328f046a3cee"
                ]
            },
            {
                "sectionName": "How are explanations useful to humans?",
                "subsectionName": null,
                "referencesIds": [
                    "cffd8f947ba03644f62baea31c64c8920b06288e",
                    null,
                    "866b6c8285b8cb6e6bdef5edb8933ee2f4aebd66",
                    "3d6ff845b6383838e18a429acea6f09e225076ac",
                    "19ca12d11e574036ca182250d5b220c7e3bb3c60",
                    "470876c64558e6849d7f3209ca33e8346e6ea747",
                    "101309da0732648e72929a5327341d325fca57fa",
                    "4bf3fd4859cb0d37e333ee9ed4024387e265c99e",
                    "44088885e451744849acddde9ad3ca9c1973c6fe",
                    "024087f125814fa70c6411fba9a4caff75878983",
                    "ff4113bcddab4470fff70f06fb0e3860dddab6ac",
                    "57378899b7a68365eb5d9ec86c27ef75208fdbb6"
                ]
            },
            {
                "sectionName": "Different kinds of explanations",
                "subsectionName": null,
                "referencesIds": [
                    "3d6ff845b6383838e18a429acea6f09e225076ac",
                    "87a65c172ff4ab532486523560224c4ab2f2aa02",
                    "27ea18d852729a397eea4ad10d7b1478c2c6c55e",
                    null,
                    "a550f576ff20b8cce98f3ddad0043d3783fbc9b4",
                    "47e799f83b0850f3d036a2e3a66bb337661b7e68",
                    "93055cf2cf5f59adbca7bf928810094a39055f93",
                    "968a5d418c8a4b68eb8b95ec9f72dce2b776d4c9",
                    "db27a18d04e22ddc91ff74204e074c1aaa6d239b",
                    "ebf58b3b6e0fc6612faedf94282161235dc1927c" 
                ]
            },
            {
                "sectionName": "Datasets and automatic methods to generate explanations",
                "subsectionName": null,
                "referencesIds": [
                    "c242438dac5aa4d9b13766c14240bb8426690d58",
                    "4081aeb7ff148cc4678efca4e44a72dece4542e3",
                    "962aa5b847f1692af058bd14fc0e8c3f0a0fee73",
                    "1cdfa7c3465943a295f8df2d2097c4bb3e222426",
                    "2522410b1cac0c14fa656a0aaeaff08bacb358a9"
                ]
            },
            {
                "sectionName": "Failure modes of machine-generated explanations",
                "subsectionName": null,
                "referencesIds": [
                    "4abb90edf2ec4045ae62cf6e25725043209bf57b",
                    "faaa21f4c2062d4099e4d24997a189f1c1400304",
                    "2c45657dc669b5b730cc92eccd05d2a4f7ec0e75",
                    "7dc928f41e15f65f1267bd87b0fcfcc7e715cb56"
                ]
            },
            {
                "sectionName": "relevant tutorials",
                "subsectionName": null,
                "referencesIds": [
                    "f0d6db2186d8bf2d8530f01de6c6518bb9711392",
                    "80e34f2b7f816113130c536dddd8aa980c95dfd2",
                    "1da8ab00e17f96e88fce0ad480794328e37daa99"
                ]
            }
        ]
    }
}
