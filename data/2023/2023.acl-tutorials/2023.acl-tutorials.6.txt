Reading List

• Unsupervised Dense Information Retrieval with Contrastive Learning (Izacard et al., 2022a)
• Task-aware Retrieval with Instructions (Asai et al., 2022)
• Atlas: Few-shot Learning with Retrieval Augmented Language Models (Izacard et al., 2022b)
• Improving language models by retrieving from trillions of tokens (Borgeaud et al., 2022)
• Mention Memory: incorporating textual knowledge into Transformers through entity mention attention (de Jong et al., 2022)
• Generalization through Memorization: Nearest Neighbor Language Models (Khandelwal et al., 2020)
• Nonparametric Masked Language Model (Min et al., 2022)
• Training Language Models with Memory Augmentation (Zhong et al., 2022)
• kNN-Prompt: Nearest Neighbor Zero-Shot Inference (Shi et al., 2022)
• Neuro-Symbolic Language Modeling with Automaton-augmented Retrieval (Alon et al., 2022)