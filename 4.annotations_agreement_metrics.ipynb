{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "121e123d-b194-4eee-80e4-efe97897dc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pke\n",
    "import math\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import stem\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "stemmer = stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f40eb8bf-b2e6-4d0f-bca0-fffc26a5bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    return re.sub(r'\\W+','', string).lower() \n",
    "    \n",
    "def stem_string(string):\n",
    "    return stemmer.stem(string, to_lowercase=True)\n",
    "    \n",
    "def list_word_process(lst):\n",
    "    for kp in lst:\n",
    "        for word in kp.split():\n",
    "            clean_word = re.sub('[()]', '', word)\n",
    "            stem = stem_string(clean_word)\n",
    "            if stem not in stops:\n",
    "                yield(stem)\n",
    "\n",
    "def word_exact_match(lst1, lst2):\n",
    "    return exact_match(list_word_process(lst1), list_word_process(lst2))\n",
    "    \n",
    "def exact_match(lst1, lst2):\n",
    "    if lst1 == lst2:\n",
    "        return 1\n",
    "    lst1 = list(map(stem_string, lst1))\n",
    "    lst2 = list(map(stem_string, lst2))\n",
    "    inter = list(set(lst1) & set(lst2))\n",
    "    union = list(set(lst1) | set(lst2))\n",
    "    return len(inter) / len(union) if len(union) > 0 else 0\n",
    "\n",
    "def score(annotator1_keyphrases, annotator2_keyphrases, func=exact_match):\n",
    "    return sum([func(anot1, anot2) for anot1, anot2 in zip(annotator1_keyphrases, annotator2_keyphrases)])/ max(len(annotator1_keyphrases), len(annotator2_keyphrases))\n",
    "\n",
    "def matrix_annotations(annotations_dict, func=word_exact_match, cols=[]):\n",
    "    data = defaultdict(lambda : defaultdict(list))\n",
    "    for k, annotations in annotations_dict.items():\n",
    "        for col in cols:\n",
    "            data[k][col]= score(annotations, annotations_dict[col], func=func)\n",
    "    return pd.DataFrame(data).transpose()\n",
    "\n",
    "def split_queries_keyphrases(queries):\n",
    "    queries = queries.replace(np.nan, \"\")\n",
    "    return [[v.strip() for v in query.strip().split(\",\")] if query.strip().split(\",\") != [''] else [] for query in queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b68cb3c1-803d-42f0-9190-22b0734e5bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_lists = pd.read_csv(\"reading_lists.csv\")\n",
    "reading_lists = reading_lists.replace(np.nan, None)\n",
    "\n",
    "queries_kps = {}\n",
    "for annotator_i in [1,2,3, \"bart\"]:\n",
    "    queries_kps[annotator_i] = split_queries_keyphrases(pd.read_csv(f\"annotations/annotation_{annotator_i}.csv\")[\"query_keywords\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f621ed07-4a4c-4ef7-b664-bf4b865b6074",
   "metadata": {},
   "source": [
    "# Keyphrases queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5d9b5b4-3965-4f51-9672-b89f52f0b4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean # of KP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>2.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>3.835294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3</th>\n",
       "      <td>2.341176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bart-Large-KP20K</th>\n",
       "      <td>4.447059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Mean # of KP\n",
       "A1                    2.705882\n",
       "A2                    3.835294\n",
       "A3                    2.341176\n",
       "Bart-Large-KP20K      4.447059"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"A1\": np.mean([len(kws) for kws in queries_kps[1]]),\n",
    "    \"A2\": np.mean([len(kws) for kws in queries_kps[2]]), \n",
    "    \"A3\": np.mean([len(kws) for kws in queries_kps[3]]), \n",
    "    \"Bart-Large-KP20K\": np.mean([len(kws) for kws in queries_kps[\"bart\"]])\n",
    "}, index=[\"Mean # of KP\"]).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9651e56-bbec-419f-826c-348b261dbded",
   "metadata": {},
   "source": [
    "## Agreement + comparison to baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb6e9105-2abf-47a4-a774-31dc190772db",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstphrase_title_keyphrases = []\n",
    "\n",
    "for title in reading_lists[\"title\"]:\n",
    "    extractor = pke.unsupervised.FirstPhrases()\n",
    "    extractor.load_document(input=title, language='en')\n",
    "    extractor.candidate_selection()\n",
    "    extractor.candidate_weighting()\n",
    "    keyphrases = extractor.get_n_best(n=3)\n",
    "    firstphrase_title_keyphrases.append([kp_tuple[0] for kp_tuple in keyphrases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5324ad14-2d01-4758-89d7-fbe471b080b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "topicrank_keyphrases = []\n",
    "\n",
    "for title,abstract in zip(reading_lists[\"title\"],reading_lists[\"abstract\"]):\n",
    "    extractor = pke.unsupervised.TopicRank()\n",
    "    extractor.load_document(input=title+\"\\n \"+(abstract or \"\"), language='en')\n",
    "    extractor.candidate_selection()\n",
    "    extractor.candidate_weighting()\n",
    "    keyphrases = extractor.get_n_best(n=3)\n",
    "    topicrank_keyphrases.append([kp_tuple[0] for kp_tuple in keyphrases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77cd1af0-d02f-4026-a393-dd5489523110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3529411764705883"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(kws) for kws in firstphrase_title_keyphrases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "529e45a7-37c5-408f-a98b-ca4d8a00a43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(kws) for kws in topicrank_keyphrases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fb2f817-d5f5-4233-9d72-733aa6427099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = [\"A1\", \"A2\", \"A3\"]\n",
    "annotations = {\n",
    "    \"A1\":queries_kps[1],\n",
    "    \"A2\":queries_kps[2], \n",
    "    \"A3\":queries_kps[3], \n",
    "\n",
    "    \"FirstPhrase Title\":firstphrase_title_keyphrases, \n",
    "    \"TopicRank\":topicrank_keyphrases, \n",
    "    \"Bart-Large-KP20K\":queries_kps[\"bart\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abfc97d8-2c30-4767-86fa-fb5fafeb586d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305374</td>\n",
       "      <td>0.537675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>0.305374</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.313214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3</th>\n",
       "      <td>0.537675</td>\n",
       "      <td>0.313214</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FirstPhrase Title</th>\n",
       "      <td>0.403280</td>\n",
       "      <td>0.269857</td>\n",
       "      <td>0.404577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TopicRank</th>\n",
       "      <td>0.368888</td>\n",
       "      <td>0.230942</td>\n",
       "      <td>0.407870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bart-Large-KP20K</th>\n",
       "      <td>0.412099</td>\n",
       "      <td>0.325121</td>\n",
       "      <td>0.380824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         A1        A2        A3\n",
       "A1                 1.000000  0.305374  0.537675\n",
       "A2                 0.305374  1.000000  0.313214\n",
       "A3                 0.537675  0.313214  1.000000\n",
       "FirstPhrase Title  0.403280  0.269857  0.404577\n",
       "TopicRank          0.368888  0.230942  0.407870\n",
       "Bart-Large-KP20K   0.412099  0.325121  0.380824"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = matrix_annotations(annotations, func=word_exact_match, cols=columns); df\n",
    "#print(df.to_latex(float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f33e06-5b9e-4315-a87f-393954d0a0c3",
   "metadata": {},
   "source": [
    "# Differences between anotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "692ba431-3497-4249-9731-44a78235898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_differences(preds, manual_annotations, threshold=0.05):\n",
    "    for k, annotations in manual_annotations.items():\n",
    "        for annotation_manual, annotation_preds in zip(annotations, preds):\n",
    "            if word_exact_match(annotation_manual, annotation_preds)<threshold:\n",
    "                print(k, annotation_manual, annotation_preds)\n",
    "\n",
    "manual_annotations = {\n",
    "    \"A1\":queries_kps[1],\n",
    "    \"A2\":queries_kps[2], \n",
    "    \"A3\":queries_kps[3], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be8dc2ab-faca-4839-b895-14049f700dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2 ['annotation bias', 'natural language processing (nlp)', 'subjectivity', 'socio cultural annotation'] ['geo-cultural representation', 'socio-cultural identity', 'reinforcement learning from human feedback (RLHF)']\n",
      "A3 ['annotation', 'cross-cultural differences', 'language technologies'] ['geo-cultural representation', 'socio-cultural identity', 'reinforcement learning from human feedback (RLHF)']\n"
     ]
    }
   ],
   "source": [
    "check_differences(queries_kps[1], manual_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c0b0203-f6b7-4455-87e9-bc174f44810f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 ['geo-cultural representation', 'socio-cultural identity', 'reinforcement learning from human feedback (RLHF)'] ['annotation bias', 'natural language processing (nlp)', 'subjectivity', 'socio cultural annotation']\n",
      "A3 ['DBpedia Databus'] ['knowledge graph', 'accessibility', 'structuration']\n",
      "A3 ['text representation', 'text embedding', 'control', 'analysis'] ['language model', 'formal semantics', 'distributional models']\n"
     ]
    }
   ],
   "source": [
    "check_differences(queries_kps[2], manual_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3337706b-8e90-45df-8413-74ba0f0df581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 ['geo-cultural representation', 'socio-cultural identity', 'reinforcement learning from human feedback (RLHF)'] ['annotation', 'cross-cultural differences', 'language technologies']\n",
      "A2 ['knowledge graph', 'accessibility', 'structuration'] ['DBpedia Databus']\n",
      "A2 ['language model', 'formal semantics', 'distributional models'] ['text representation', 'text embedding', 'control', 'analysis']\n"
     ]
    }
   ],
   "source": [
    "check_differences(queries_kps[3], manual_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e7120-6425-4632-ade5-f1ea01b9533d",
   "metadata": {},
   "source": [
    "## Differences between automatic and manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aec6940c-0446-4f1e-899f-f531a740f529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 ['human-nlp model interactions'] ['natural language processing', 'human-in-the-loop usability evaluation', 'model-based user interface design']\n",
      "A2 ['zero shot learning', 'few shot learning', 'review'] ['few-shot', 'language models', 'zero-shot']\n",
      "A3 ['human-NLP model interactions'] ['natural language processing', 'human-in-the-loop usability evaluation', 'model-based user interface design']\n"
     ]
    }
   ],
   "source": [
    "check_differences(queries_kps['bart'], manual_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70179a1-95ee-4547-a04d-2b844a4c0cf2",
   "metadata": {},
   "source": [
    "# Sentence queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac2fa675-ef64-4983-addb-e0f6533d5e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_sentences = {}\n",
    "for annotator_i in [1,2,3]:\n",
    "    annotator_sentences = [query.strip() for query in pd.read_csv(f\"annotations/annotation_{annotator_i}.csv\")[\"query_sentence\"].replace(np.nan, \"\")]\n",
    "    queries_sentences[annotator_i] = [[clean_string(stem_string(w)) for w in s.split() if w not in stops] for s in annotator_sentences]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0659b731-80e0-43fa-926f-1c8d8be88d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = [\"A1\", \"A2\", \"A3\"]\n",
    "annotations_sentences = {\n",
    "    \"A1\":queries_sentences[1],\n",
    "    \"A2\":queries_sentences[2], \n",
    "    \"A3\":queries_sentences[3], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87c9fdc3-1be0-4234-b00b-bf9fdf8e1659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.411043</td>\n",
       "      <td>0.603139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>0.411043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.406821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3</th>\n",
       "      <td>0.603139</td>\n",
       "      <td>0.406821</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A1        A2        A3\n",
       "A1  1.000000  0.411043  0.603139\n",
       "A2  0.411043  1.000000  0.406821\n",
       "A3  0.603139  0.406821  1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = matrix_annotations(annotations_sentences, func=word_exact_match, cols=columns); df\n",
    "#print(df.to_latex(float_format=\"%.2f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
