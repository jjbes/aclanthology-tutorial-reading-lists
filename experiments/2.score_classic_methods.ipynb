{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae60a34b-3a46-450c-b445-63826f0635a8",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4db5358-87f1-4296-bad4-bc6dfb085d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import json\n",
    "import math\n",
    "import functools\n",
    "import operator\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from metrics import recall, mrr, ndcg, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33b2e808-bb23-49b5-8e32-12ba64ce4908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    return re.sub(r'\\W+','', string).lower() \n",
    "\n",
    "def compute_results(trues, preds_annots):\n",
    "    data = {}\n",
    "    for k, preds in preds_annots.items():\n",
    "        data[k] = score(trues, preds, [recall, ndcg, mrr], k=20)\n",
    "    df = pd.DataFrame(data).transpose()\n",
    "    df.loc['Mean'] = df.mean()\n",
    "    return df.round(1)\n",
    "\n",
    "def load_preds_annotators(path, method):\n",
    "    preds = defaultdict(lambda: defaultdict(dict))\n",
    "    for annotator_i in [1,2,3]:\n",
    "        path_annots = Path(f'{path}/{method}/preds_annot{annotator_i}.json')\n",
    "        preds[f\"A{annotator_i}\"] = { id_:[clean_string(ref[\"title\"]) for ref in references] for id_, references in json.loads(path_annots.read_text()).items()}\n",
    "    return json.loads(json.dumps(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5352d8e1-1661-42d6-be7e-33ff123b2a6c",
   "metadata": {},
   "source": [
    "# Comparison of basic approaches and search engine on ACL Anthology dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1ca5b0b-7ed5-41b2-a752-d5f9ceab1fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_lists = pd.read_csv(\"../reading_lists.csv\")\n",
    "reading_lists['reading_list'] = reading_lists['reading_list'].apply(ast.literal_eval)\n",
    "\n",
    "trues = { id_:[clean_string(ref[\"title\"]) for ref in references if ref[\"acl_id\"]] for id_, references in zip(reading_lists[\"id\"], reading_lists[\"reading_list\"]) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75f51052-5bf4-41a4-899d-9747a09574c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">S2 (Any)</th>\n",
       "      <th colspan=\"3\" halign=\"left\">S2 (Acl)</th>\n",
       "      <th colspan=\"3\" halign=\"left\">BM25</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SPECTER2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>mrr</th>\n",
       "      <th>recall</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>mrr</th>\n",
       "      <th>recall</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>mrr</th>\n",
       "      <th>recall</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>4.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>2.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>7.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     S2 (Any)           S2 (Acl)              BM25           SPECTER2       \\\n",
       "       recall ndcg  mrr   recall ndcg   mrr recall ndcg  mrr   recall ndcg   \n",
       "A1        4.2  2.1  2.5      8.4  5.5   7.6    8.9  5.7  8.8      5.8  3.1   \n",
       "A2        2.7  1.5  2.0      5.2  3.7   5.3    9.2  5.5  6.3      5.7  3.4   \n",
       "A3        6.7  3.9  5.6     10.2  7.5  11.2   11.2  6.6  9.2      8.2  4.7   \n",
       "Mean      4.5  2.5  3.3      7.9  5.6   8.0    9.7  5.9  8.1      6.6  3.7   \n",
       "\n",
       "           \n",
       "      mrr  \n",
       "A1    3.3  \n",
       "A2    4.6  \n",
       "A3    5.8  \n",
       "Mean  4.6  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_semantic_scholar_all = compute_results(trues, load_preds_annotators(\"classic_methods/preds\", \"semantic_scholar_any\"))\n",
    "df_semantic_scholar_acl = compute_results(trues, load_preds_annotators(\"classic_methods/preds\", \"semantic_scholar_acl\"))\n",
    "df_bm25 = compute_results(trues, load_preds_annotators(\"classic_methods/preds\", \"bm25\"))\n",
    "df_specterv2 = compute_results(trues, load_preds_annotators(\"classic_methods/preds\", \"specterv2\"))\n",
    "table = pd.concat([df_semantic_scholar_all, df_semantic_scholar_acl, df_bm25, df_specterv2], axis=1, keys=[\"S2 (Any)\",\"S2 (Acl)\", \"BM25\", \"SPECTER2\"]); table\n",
    "\n",
    "#print(table.to_latex(float_format=\"{:0.1f}\".format))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3ac0f3-9b71-4427-976e-5ce7788a4b49",
   "metadata": {},
   "source": [
    "## Matches of correct prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ed39484-1562-4f52-9a05-f5ca7c557adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(trues, preds1, preds2):\n",
    "    match = 0\n",
    "    size = 0\n",
    "    for k, trues_v in trues.items():\n",
    "        if trues_v != []:\n",
    "            match1 = set(dict.fromkeys(trues_v)) & set(dict.fromkeys(preds1[k]))\n",
    "            match2 = set(dict.fromkeys(trues_v)) & set(dict.fromkeys(preds2[k]))\n",
    "            match+=len(match1 & match2)\n",
    "            size+=1\n",
    "    return match/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa6d667d-1d6d-4d8e-b86c-276bafdbfa7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1050228310502283"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_preds = load_preds_annotators(\"classic_methods/preds\", \"bm25\")\n",
    "specter2_preds = load_preds_annotators(\"classic_methods/preds\", \"specterv2\")\n",
    "\n",
    "(match(trues, bm25_preds[\"A1\"], specter2_preds[\"A1\"]) +\\\n",
    "match(trues, bm25_preds[\"A2\"], specter2_preds[\"A2\"]) +\\\n",
    "match(trues, bm25_preds[\"A3\"], specter2_preds[\"A3\"])) /3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
