import os
import re
import json
import argparse
from tqdm import tqdm
from pathlib import Path
from bs4 import BeautifulSoup
from typing import Optional, Generator, Callable

"""  Remove quotes and asterisks from title """
def clean_title(title: str) -> str:
    title = re.sub('["*]', '', title)
    return title.strip('"').strip('*').strip('"')

"""  Extract title string out of it's initial formating """
def extract_title_from_quotes(title: str) -> str:
    quoted_title_match = re.search(r'"(.+?)"', title)
    quoted_title_trailing_author_match = re.search(r'(.+?) by', title)
    bold_title_match = re.search(r'\*\*(.+?)\*\*', title)
    trailing_bold_match = re.search(r'([^:]+?)\*\*', title)

    if quoted_title_match:
        return quoted_title_match.group(1)
    elif quoted_title_trailing_author_match: 
        return quoted_title_trailing_author_match.group(1)
    elif bold_title_match:
        return bold_title_match.group(1)
    elif trailing_bold_match:
        return trailing_bold_match.group(1)
   
    return title  # Return original if no matches found

"""  Parse year string to int """
def parse_year(date:Optional[str]) -> Optional[int]:
    if date and re.match(r"^\d{4}$", date):
        return int(date)
    return None

"""  Parse json files extract by anystyle """
def parse_extracted_json(path: str) -> Generator:
    with open(path, "r") as file:  
        content = json.load(file)
        for item in content:
            if "citation-number" in item and "title" in item:
                title = item["title"][0].replace("\\", "")
                title = extract_title_from_quotes(title)
                title = clean_title(title)
                year = parse_year(item.get("date", [None])[0])
                yield {"title": title, "year": year}

"""  Parse json files generated by instruct models """
def parse_json(path:str) -> list[dict[str, Optional[str]]]:
    with open(str(path), "r") as file:      
        try:
            data = json.load(file)
            return [{"title": item.get("title"), "year": item.get("year")} for item in data]
        except ValueError:
            return []

"""  Find references in html pages """
def find_articles(html:str) -> str:
    soup = BeautifulSoup(html, 'html.parser') 
    results = []
    for refs in soup.find_all("div", {"class": "gs_r gs_or gs_scl"}):
        if refs.find("h3").find("a"):
            title = refs.find("h3").find("a").text
        else:
            title = refs.find("h3").find_all('span')[3].text #Citations
        year = refs.find("div", {"class": "gs_a"}).text.split(" - ")[0][-4:]
        results.append({
            "title": title,
            "year": year
        })
    return results

"""  Parse html pages """
def parse_html(pathlist:list[str]) -> dict:
    preds = {}
    for path in pathlist:
        key = path.parts[-1].replace(".html", "")
        with open(str(path)) as file:
            preds[key] = find_articles(file)
    return preds         

"""  Parse results from models based on its type """
def process_parse_results(results_folder:str, preds_folder:str, parse_func:Callable) -> None:
    for annotator_num in [1, 2, 3]:
        os.makedirs(preds_folder, exist_ok=True)
        preds_file = f"{preds_folder}/preds_annot{annotator_num}.json"
        # Load annotator queries from CSV
        if not os.path.exists(preds_file):
            results_paths = sorted(Path(f"{results_folder}/annotator{annotator_num}/").glob(f'*.json'))
            results = {path.parts[-1].replace(f".json", ""): list(parse_func(path)) for path in tqdm(results_paths, desc=f"A{annotator_num}")}
            with open(preds_file, "w") as file:
                json.dump(results , file) 

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Parse results of a models to a predictions file')
    parser.add_argument('--input', required=True,
                        help='path of the folder to process the model results')
    parser.add_argument('--output', required=True,
                        help='path of the folder to output the parsed predictions')
    parser.add_argument('--parsing_type', required=True,
                        choices=["html","json","md_to_json"],
                        help='type of parsing')
    args = parser.parse_args()

    if args.parsing_type == "html":
        parse_function = parse_html
    elif args.parsing_type == "json":
        parse_function = parse_json
    elif args.parsing_type == "md_to_json":
        parse_function = parse_extracted_json

    print(f"Parsing results of {args.input} to {args.output}.")
    process_parse_results(args.input, args.output, parse_function)
    print(f"Parsed.")
