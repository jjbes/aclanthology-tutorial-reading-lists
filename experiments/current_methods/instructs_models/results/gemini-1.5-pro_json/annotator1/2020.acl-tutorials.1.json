[{"title": "Visualizing and Understanding Recurrent Networks", "year": 2015}, {"title": "Attention Is All You Need", "year": 2017}, {"title": "Getting Inside the Black Box: Understanding Neural Networks Through Information Theory", "year": 2017}, {"title": "Lime: Why Should I Trust You? Explaining the Predictions of Any Classifier", "year": 2016}, {"title": "Axiomatic Attribution for Deep Networks", "year": 2017}, {"title": "Learning to Generate Reviews and Discovering Sentiment", "year": 2015}, {"title": "BERT Rediscovers the Classical NLP Pipeline", "year": 2019}, {"title": "Open Sesame: Getting Inside BERT's Linguistic Knowledge", "year": 2019}, {"title": "What Does BERT Look At? An Analysis of BERT's Attention", "year": 2019}, {"title": "Are Sixteen Heads Really Better than One?", "year": 2019}, {"title": "How Can We Know What Language Models Know?", "year": 2020}, {"title": "Exposing and Mitigating Gender Bias in Word Embeddings", "year": 2016}, {"title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?", "year": 2020}, {"title": "The Measure of Intelligence", "year": 2020}, {"title": "Beyond Accuracy: Behavioral Testing of NLP Models with CheckList", "year": 2020}, {"title": "Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data", "year": 2020}, {"title": "Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference", "year": 2019}, {"title": "Explainable AI for Natural Language Processing: A Survey", "year": 2020}, {"title": "Analyzing and Interpreting Neural Networks for NLP: A Report on the First BlackboxNLP Workshop", "year": 2019}, {"title": "Towards a Unified Approach to Interpreting Model Predictions", "year": 2018}]
