[{"title": "BLEU: a Method for Automatic Evaluation of Machine Translation", "year": 2002}, {"title": "A Global Model for Concept-to-Text Generation", "year": 2007}, {"title": "Discriminative Training Methods for Statistical Machine Translation", "year": 2008}, {"title": "Text Editing for Document Summarization", "year": 2009}, {"title": "Learning to Edit for Higher Summarization Quality", "year": 2011}, {"title": "Sentence Compression by Deletion with LSTMs", "year": 2016}, {"title": "Get To The Point: Summarization with Pointer-Generator Networks", "year": 2017}, {"title": "Dynamic Multi-Level Multi-Task Learning for Sentence Simplification", "year": 2017}, {"title": "A Deep Reinforced Model for Abstractive Summarization", "year": 2017}, {"title": "Delete, Retrieve, Generate: A Simple and Effective Approach for Controlled Text Generation", "year": 2018}, {"title": "Text Summarization with Pretrained Encoders", "year": 2019}, {"title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension", "year": 2020}, {"title": "Longformer: The Long-Document Transformer", "year": 2020}, {"title": "T5: Text-To-Text Transfer Transformer", "year": 2020}, {"title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization", "year": 2020}, {"title": "ProphetNet: Predicting Future N-gram for Generation with Pretrained Language Models", "year": 2020}, {"title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "year": 2021}, {"title": "ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation", "year": 2021}, {"title": "Controllable Abstractive Dialogue Summarization with Sketch Supervision", "year": 2022}, {"title": "A Survey of Text Summarization Extractive Techniques", "year": 2022}]
