[{"title": "Privacy and Security Risks in Deep Learning: A Survey", "year": 2018}, {"title": "Stealing Machine Learning Models via Prediction APIs", "year": 2016}, {"title": "Explaining and Harnessing Adversarial Examples", "year": 2015}, {"title": "Model Inversion Attacks against Collaborative Inference", "year": 2020}, {"title": "Hidden Voice Commands", "year": 2016}, {"title": "BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain", "year": 2017}, {"title": "Poisoning Attacks against Machine Learning: A Comprehensive Tutorial", "year": 2022}, {"title": "Data Poisoning Attacks on Federated Learning", "year": 2019}, {"title": "The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks", "year": 2018}, {"title": "Protecting Privacy in Deep Learning", "year": 2018}, {"title": "Adversarial Examples in Natural Language Processing: A Survey", "year": 2019}, {"title": "Certified Robustness to Adversarial Word Substitutions", "year": 2019}, {"title": "TextFooler: Fool Natural Language Inference Models with Semantically Equivalent Adversarial Rules", "year": 2019}, {"title": "Backdooring Interpretability Methods: How to Hide a Backdoor in Your Explanation", "year": 2021}, {"title": "Trojaning Language Models for Fun and Profit", "year": 2021}, {"title": "Deepfakes and Beyond: A Survey of Face Manipulation and Fake Detection", "year": 2020}, {"title": "Defending Against Neural Fake News", "year": 2019}, {"title": "Exposing DeepFake Videos By Detecting Face Warping Artifacts", "year": 2019}, {"title": "Deep Learning for Deepfakes Creation and Detection: A Survey", "year": 2020}, {"title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?", "year": 2021}]
