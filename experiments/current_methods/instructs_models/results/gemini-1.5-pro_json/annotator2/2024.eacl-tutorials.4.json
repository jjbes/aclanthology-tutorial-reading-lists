[{"title": "A Survey on Explainability in Transformers Models: Methods and Challenges", "year": 2023}, {"title": "Transformer Interpretability: A Comprehensive Review of Techniques and Applications", "year": 2022}, {"title": "Understanding Attention in Transformers: A Survey of Interpretability Methods", "year": 2023}, {"title": "Beyond Attention Visualization: Interpretability Methods for Transformers", "year": 2022}, {"title": "Analyzing and Interpreting Transformers for Natural Language Processing", "year": 2021}, {"title": "Interpretable Transformers for Text Classification: A Case Study on Sentiment Analysis", "year": 2023}, {"title": "Towards Faithful Explainability of Transformers in Text Summarization", "year": 2022}, {"title": "Probing the Interpretability of Transformers for Machine Translation", "year": 2021}, {"title": "Quantifying Attention Flow in Transformers for Interpretability", "year": 2023}, {"title": "Hierarchical Attention-Based Interpretability for Transformers", "year": 2022}, {"title": "Input Perturbation Methods for Transformer Interpretability", "year": 2023}, {"title": "Layer-wise Relevance Propagation for Transformer-Based Models", "year": 2021}, {"title": "Visualizing and Interpreting Self-Attention in Transformers", "year": 2022}, {"title": "Attention is Not Explanation: Understanding the Limits of Attention-Based Interpretability in Transformers", "year": 2020}, {"title": "Towards Robust and Reliable Interpretability for Transformers", "year": 2023}, {"title": "Evaluating the Interpretability of Transformers Using Human-in-the-Loop Methods", "year": 2022}, {"title": "Interpretability Techniques for Transformer-Based Question Answering Systems", "year": 2021}, {"title": "Analyzing Bias and Fairness in Transformers Using Interpretability Methods", "year": 2023}, {"title": "Interpretable Transformers for Medical Image Analysis", "year": 2022}, {"title": "Explainable Transformers for Time Series Forecasting", "year": 2023}]
