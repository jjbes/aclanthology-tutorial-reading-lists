[{"authors": ["William Chan, Navdeep Jaitly, Quoc V. Le"], "title": "Listen, Attend and Spell", "year": 2015}, {"authors": ["Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le"], "title": "Learning to Retrieve Passages without Supervision", "year": 2021}, {"authors": ["Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela"], "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks", "year": 2020}, {"authors": ["Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer"], "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension", "year": 2019}, {"authors": ["Sascha Rothe, Shashi Narayan, Aliaksei Severyn"], "title": "Rethinking Attention with Performers", "year": 2020}, {"authors": ["Nikita Kitaev, Łukasz Kaiser, Anselm Levskaya"], "title": "Reformer: The Efficient Transformer", "year": 2020}, {"authors": ["Iz Beltagy, Matthew E. Peters, Arman Cohan"], "title": "Longformer: The Long-Document Transformer", "year": 2020}, {"authors": ["Manzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed"], "title": "Big Bird: Transformers for Longer Sequences", "year": 2020}, {"authors": ["Yi Tay, Mostafa Dehghani, Dara Bahri, Donald Metzler"], "title": "Efficient Transformers: A Survey", "year": 2022}, {"authors": ["Noam Shazeer"], "title": "Fast Transformer Decoding: One Write-Head is All You Need", "year": 2019}, {"authors": ["Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus"], "title": "End-To-End Memory Networks", "year": 2015}, {"authors": ["Ankit Gupta, Jonathan Berant"], "title": "Encoding Input with Convolutional Neural Network for Text Matching", "year": 2017}, {"authors": ["Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, Yann N. Dauphin"], "title": "Convolutional Sequence to Sequence Learning", "year": 2017}, {"authors": ["Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin"], "title": "Attention Is All You Need", "year": 2017}, {"authors": ["Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio"], "title": "Neural Machine Translation by Jointly Learning to Align and Translate", "year": 2014}, {"authors": ["Ilya Sutskever, Oriol Vinyals, Quoc V. Le"], "title": "Sequence to Sequence Learning with Neural Networks", "year": 2014}, {"authors": ["Tomáš Kociský, Gábor Melis, Edward Grefenstette, Chris Dyer, Wang Ling, Phil Blunsom, Karl Moritz Hermann"], "title": "Semantic Parsing with Semi-Supervised Sequential Autoencoders", "year": 2016}, {"authors": ["Adji B. Dieng, Yoon Kim, Alexander M. Rush, David M. Blei"], "title": "Avoiding Latent Variable Collapse with Generative Skip Models", "year": 2018}, {"authors": ["Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron C. Courville, Yoshua Bengio"], "title": "A Recurrent Latent Variable Model for Sequential Data", "year": 2015}, {"authors": ["Alex Graves"], "title": "Generating Sequences With Recurrent Neural Networks", "year": 2013}]
