[{"title": "Cross-lingual Language Model Pretraining", "year": 2019}, {"title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "year": 2018}, {"title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "year": 2020}, {"title": "Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond", "year": 2018}, {"title": "Improving Neural Machine Translation Models with Monolingual Data", "year": 2015}, {"title": "Neural Machine Translation of Rare Words with Subword Units", "year": 2015}, {"title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation", "year": 2016}, {"title": "Word Translation without Parallel Data", "year": 2017}, {"title": "Unsupervised Cross-Lingual Representation Learning at Scale", "year": 2019}, {"title": "Cross-lingual Transfer Learning for Language Modeling", "year": 2019}, {"title": "Multilingual Denoising Pre-training for Neural Machine Translation", "year": 2020}, {"title": "Pre-training for Neural Machine Translation with Monolingual Data", "year": 2018}, {"title": "Improving Low-Resource Neural Machine Translation with Transfer Learning and Language Clustering", "year": 2019}, {"title": "Cross-Lingual Language Model Fine-Tuning for Low-Resource Neural Machine Translation", "year": 2019}, {"title": "Investigating Back-Translation in Neural Machine Translation", "year": 2018}, {"title": "Understanding Back-Translation at Scale", "year": 2018}, {"title": "Data Augmentation by Back-Translation for Low-Resource Neural Machine Translation", "year": 2016}, {"title": "Domain Adaptation for Neural Machine Translation", "year": 2019}, {"title": "When and Why are Pre-trained Word Embeddings Useful for Neural Machine Translation?", "year": 2017}, {"title": "On the Use of BERT for Neural Machine Translation", "year": 2020}]
