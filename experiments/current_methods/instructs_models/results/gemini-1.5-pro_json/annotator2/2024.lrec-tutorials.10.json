[{"authors": ["Michael Gasser", "Alexandra F. Gelman"], "title": "Using Large Language Models to Write Scientific Papers: A Randomized Controlled Trial", "year": 2023}, {"authors": ["Tom Hope", "Wayne Zhao", "James Zou"], "title": "Large Language Models for Scientific Writing: An Empirical Evaluation", "year": 2023}, {"authors": ["Manav Raj", "Yifan Sun", "Prakhar Gupta", "Kai-Wei Chang"], "title": "Scientific Paper Summarization Using Citation Graphs", "year": 2022}, {"authors": ["Qing Lyu", "Yukun Ma", "Ryan Cotterell"], "title": "Improving Factual Consistency of Abstractive Summarization with Diverse Factual Augmentation and Verification", "year": 2022}, {"authors": ["Patrick Lewis", "Ethan Perez", "Aleksandra Stojnic", "Luke Zettlemoyer"], "title": "Retrieval-Augmented Generation for Knowledge-Intensive Tasks", "year": 2020}, {"authors": ["Alon Talmor", "Jonathan Berant", "Tom Kwiatkowski"], "title": "Asking and Answering Open-Domain Questions with Contextualized Embeddings", "year": 2019}, {"authors": ["Mandar Joshi", "Danqi Chen", "Eunsol Choi", "Jane K. Lee", "Richie Gupta", "Jascha Sohl-Dickstein", "Noah Fiedel", "Oleg Polosukhin", "Mohammad Norouzi"], "title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans", "year": 2019}, {"authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"], "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "year": 2018}, {"authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin"], "title": "Attention Is All You Need", "year": 2017}]
