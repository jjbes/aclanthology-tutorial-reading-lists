[{"authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "title": "\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier", "year": 2016}, {"authors": ["Sarthak Jain", "Byron C. Wallace"], "title": "Attention is not Explanation", "year": 2019}, {"authors": ["Sarah Wiegreffe", "Yuval Pinter"], "title": "Attention is not not Explanation", "year": 2019}, {"authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"], "title": "Axiomatic Attribution for Deep Networks", "year": 2017}, {"authors": ["Scott Lundberg", "Su-In Lee"], "title": "A Unified Approach to Interpreting Model Predictions", "year": 2017}, {"authors": ["W. James Murdoch", "Chandan Singh", "Karl Kumbier", "Bin Yu", "Evan Patterson"], "title": "Interpretable Machine Learning: Definitions, Methods, and Applications", "year": 2019}, {"authors": ["Daniel W. Otter", "Julian R. Ritz", "Elias B. Moss"], "title": "Causal Inference in Natural Language Processing: Estimation, Prediction, and Explanation", "year": 2020}, {"authors": ["Yixin Nie", "Adina Williams", "Emily Dinan", "Mohit Bansal", "Jason Weston", "Douwe Kiela"], "title": "Adversarial NLI: A New Benchmark for Natural Language Understanding", "year": 2020}, {"authors": ["Yonatan Belinkov", "James Glass"], "title": "Analysis Methods in Neural Language Processing: A Survey", "year": 2019}, {"authors": ["Jesse Vig"], "title": "A Multiscale Visualization of Attention in the Transformer Model", "year": 2019}, {"authors": ["Ian Tenney", "Dipanjan Das", "Ellie Pavlick"], "title": "BERT Rediscovers the Classical NLP Pipeline", "year": 2019}, {"authors": ["Kevin Clark", "Urvashi Khandelwal", "Omer Levy", "Christopher D. Manning"], "title": "What Does BERT Look At? An Analysis of BERT's Attention", "year": 2019}, {"authors": ["Tal Linzen"], "title": "What Can We Learn from LSTM and Transformer Language Models about Syntactic Structure?", "year": 2019}, {"authors": ["John Hewitt", "Christopher D. Manning"], "title": "A Structural Probe for Finding Syntax in Word Representations", "year": 2019}, {"authors": ["Allyson Ettinger"], "title": "What BERT Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models", "year": 2020}, {"authors": ["Zhengbao Jiang", "Frank F. Xu", "Jun Araki", "Graham Neubig"], "title": "How Can We Know What Language Models Know?", "year": 2020}, {"authors": ["Anna Rogers", "Olga Kovaleva", "Anna Rumshisky"], "title": "A Primer in BERTology: What We Know About How BERT Works", "year": 2020}, {"authors": ["Dan Jurafsky"], "title": "What Does BERT Learn about Syntax?", "year": 2020}, {"authors": ["Yoav Goldberg"], "title": "What Can We Learn from Language Model Representation Spaces?", "year": 2020}, {"authors": ["Emily Bender", "Timnit Gebru", "Angelina McMillan-Major", "Shmargaret Shmitchell"], "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?", "year": 2021}]
