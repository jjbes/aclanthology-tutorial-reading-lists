[{"title": "Benchmarking Large Language Models for News Summarization", "year": 2023}, {"title": "Evaluating Large Language Models Trained on Code", "year": 2022}, {"title": "Beyond Accuracy: Behavioral Testing of NLP models with CheckList", "year": 2020}, {"title": "Measuring the Factual Accuracy of Generated Text", "year": 2021}, {"title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?", "year": 2021}, {"title": "Towards Faithful Evaluation of Text Generation", "year": 2020}, {"title": "Evaluating NLP Models via Contrast Sets", "year": 2020}, {"title": "Dynabench: Rethinking Benchmarking in NLP", "year": 2021}, {"title": "Measuring Bias in Natural Language Processing Models", "year": 2021}, {"title": "The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics", "year": 2021}, {"title": "Evaluating the Robustness of Neural Machine Translation Models", "year": 2019}, {"title": "Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data", "year": 2020}, {"title": "Evaluating Dialogue Generation Systems", "year": 2020}, {"title": "BLEU: a Method for Automatic Evaluation of Machine Translation", "year": 2002}, {"title": "ROUGE: A Package for Automatic Evaluation of Summaries", "year": 2004}, {"title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments", "year": 2005}, {"title": "CIDEr: Consensus-based Image Description Evaluation", "year": 2015}, {"title": "SPICE: Semantic Propositional Image Caption Evaluation", "year": 2016}, {"title": "BERTScore: Evaluating Text Generation with BERT", "year": 2020}, {"title": "MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance", "year": 2020}]
