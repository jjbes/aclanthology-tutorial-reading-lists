[{"title": "Visual Grounding in Language for Embodied Agents: A Survey", "year": 2022}, {"title": "Multimodal Few-Shot Learning for Object Detection", "year": 2021}, {"title": "Learning Grounded Meaning Representations with Neural Networks", "year": 2020}, {"title": "BERT for Grounded Commonsense Reasoning", "year": 2019}, {"title": "Multimodal Sensor Fusion for Semantic Scene Understanding", "year": 2018}, {"title": "From Image Descriptions to Visual Denotations: New Similarity Metrics for Semantic Inference over Event Descriptions", "year": 2014}, {"title": "Learning Language and Motor Control Compatibly", "year": 2017}, {"title": "Multimodal Grounding for Language Processing", "year": 2016}, {"title": "Towards Situated Reasoning: Multimodal Grounding and Beyond", "year": 2021}, {"title": "Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments", "year": 2018}, {"title": "Embodied Question Answering", "year": 2018}, {"title": "Multimodal Neural Language Models", "year": 2019}, {"title": "Grounding Language in Vision-and-Action", "year": 2020}, {"title": "Reasoning About Actions and State Changes by Injecting Commonsense Knowledge", "year": 2019}, {"title": "Multimodal Reasoning for Situated Language Comprehension", "year": 2017}, {"title": "Language Grounding with 3D Objects and Embodied Agents", "year": 2022}, {"title": "Zero-Shot Visual Relation Detection with Web-Scale Language Supervision", "year": 2020}, {"title": "Learning to Compose Visual Relations", "year": 2017}, {"title": "Visual Question Answering: A Survey of Methods and Datasets", "year": 2017}, {"title": "Connecting Language and Vision to Actions with Reinforcement Learning", "year": 2017}]
