[{"title": "Neural Machine Translation by Jointly Learning to Align and Translate", "year": 2015}, {"title": "Effective Approaches to Attention-based Neural Machine Translation", "year": 2015}, {"title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation", "year": 2016}, {"title": "Exploring the Limits of Language Modeling", "year": 2016}, {"title": "Massive Exploration of Neural Machine Translation Architectures", "year": 2017}, {"title": "Attention Is All You Need", "year": 2017}, {"title": "Improving Neural Machine Translation with Conditional Sequence Generative Adversarial Nets", "year": 2017}, {"title": "Neural Machine Translation with Reconstruction", "year": 2018}, {"title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "year": 2018}, {"title": "Cross-lingual Language Model Pretraining", "year": 2019}, {"title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension", "year": 2019}, {"title": "Investigating Pretrained Language Models for Neural Machine Translation", "year": 2019}, {"title": "Pre-training via Back-translation for Low-resource Neural Machine Translation", "year": 2019}, {"title": "Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation", "year": 2020}, {"title": "Multilingual Denoising Pre-training for Neural Machine Translation", "year": 2020}, {"title": "Pre-training for Low-resource Neural Machine Translation: A Survey", "year": 2020}, {"title": "Understanding the Impact of Data Augmentation on Neural Machine Translation", "year": 2020}, {"title": "Exploring the Effectiveness of Transfer Learning for Neural Machine Translation with Cross-lingual Embeddings", "year": 2021}, {"title": "Leveraging Monolingual Data for Neural Machine Translation: A Survey", "year": 2021}, {"title": "Pre-training Methods for Neural Machine Translation: An Empirical Study", "year": 2021}]
