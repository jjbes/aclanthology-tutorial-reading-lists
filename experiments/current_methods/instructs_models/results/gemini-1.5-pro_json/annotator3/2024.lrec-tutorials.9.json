[{"title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?", "year": 2021}, {"title": "Probing Neural Networks with Deceptive Inputs", "year": 2019}, {"title": "Black is to Criminal as Caucasian is to Police: Detecting and Mitigating Bias in Word Embeddings", "year": 2016}, {"title": "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings", "year": 2016}, {"title": "Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Bias in Word Embeddings But do not Remove It", "year": 2019}, {"title": "Evaluating Social Biases in Large Language Models", "year": 2020}, {"title": "Mitigating Gender Bias in Natural Language Processing: Literature Review", "year": 2020}, {"title": "Fairness and Machine Learning: Limitations and Opportunities", "year": 2017}, {"title": "On Measuring and Mitigating Bias in Word Embeddings", "year": 2019}, {"title": "Towards Debiasing Sentence Representations", "year": 2019}, {"title": "Analyzing and Reducing Gender Bias in Word Embeddings", "year": 2019}, {"title": "Exposing Bias in Word Embeddings through Detectability", "year": 2019}, {"title": "Measuring Social Biases in Contextualized Word Representations", "year": 2019}, {"title": "Quantifying Social Biases in Contextual Word Embeddings", "year": 2019}, {"title": "Black Sheep and Grey Wolves: A Contextual Perspective on Bias in Word Embeddings", "year": 2020}, {"title": "Towards Understanding and Mitigating Social Biases in Language Models", "year": 2020}, {"title": "Social Biases in Pretrained Language Models: A Case Study of BERT", "year": 2020}, {"title": "Measuring and Mitigating Unintended Bias in Text Classification", "year": 2019}, {"title": "Fairness in Natural Language Processing: A Survey", "year": 2021}, {"title": "On the Relationship between Debiasing Techniques and Fairness Metrics", "year": 2020}]
