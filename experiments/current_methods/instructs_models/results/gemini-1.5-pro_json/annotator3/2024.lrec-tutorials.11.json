[{"title": "Hallucinations in Large Language Models: A Survey", "year": 2023}, {"title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?", "year": 2021}, {"title": "TruthfulQA: Measuring How Large Language Models Mimic Human False Beliefs", "year": 2021}, {"title": "Measuring and Reducing Hallucinations in Open-Domain Dialogue Systems", "year": 2022}, {"title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models", "year": 2022}, {"title": "Faithful Reasoning Using Large Language Models", "year": 2022}, {"title": "Towards Faithful Neural Table-to-Text Generation with Content Planning", "year": 2022}, {"title": "Improving Factuality and Reasoning in Language Models Through Multimodal Knowledge Injection", "year": 2023}, {"title": "Detecting Hallucinations in Neural Machine Translation via Paraphrasing", "year": 2020}, {"title": "Evaluating the Factual Consistency of Abstractive Text Summarization", "year": 2019}, {"title": "Fact or Fiction: Verifying Scientific Claims", "year": 2021}, {"title": "Explain Yourself! Leveraging Language Models for Commonsense Reasoning", "year": 2020}, {"title": "Knowledge Graph Enhanced Language Model for Dialogue State Tracking", "year": 2020}, {"title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks", "year": 2020}, {"title": "Grounding Dialogue Systems with Commonsense Knowledge Graphs", "year": 2021}, {"title": "Language Models as Knowledge Bases?", "year": 2020}, {"title": "Measuring Compositional Generalization in Grounded Language Understanding", "year": 2021}, {"title": "BERT-INT: A BERT-based Model for Intent Classification with Hallucination Detection", "year": 2020}, {"title": "Detecting and Mitigating Hallucinations in Dialogue Systems", "year": 2023}, {"title": "Improving Dialogue Consistency with Turn-level Grounding", "year": 2022}]
