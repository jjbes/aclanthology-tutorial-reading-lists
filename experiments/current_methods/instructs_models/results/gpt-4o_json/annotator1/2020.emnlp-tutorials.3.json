[{"title": "A Survey of Methods for Explaining Black Box Models", "authors": ["Riccardo Guidotti", "Anna Monreale", "Salvatore Ruggieri", "Franco Turini", "Fosca Giannotti", "Dino Pedreschi"], "year": 2018}, {"title": "Interpretable Machine Learning: A Guide for Making Black Box Models Explainable", "authors": ["Christoph Molnar"], "year": 2019}, {"title": "LIME: Local Interpretable Model-Agnostic Explanations", "authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "year": 2016}, {"title": "Anchors: High-Precision Model-Agnostic Explanations", "authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "year": 2018}, {"title": "DeepLIFT: Learning Important Features Through Propagating Activation Differences", "authors": ["Avanti Shrikumar", "Peyton Greenside", "Anshul Kundaje"], "year": 2017}, {"title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization", "authors": ["Ramprasaath R. Selvaraju", "Abhishek Das", "Ramakrishna Vedantam", "Michael Cogswell", "Devi Parikh", "Dhruv Batra"], "year": 2017}, {"title": "The Building Blocks of Interpretability", "authors": ["Chris Olah", "Arvind Satyanarayan", "Ian Johnson", "Shan Carter", "Ludwig Schubert", "Katherine Ye", "Alexander Mordvintsev"], "year": 2018}, {"title": "Explaining Explanations: An Overview of Interpretability of Machine Learning", "authors": ["David Gunning"], "year": 2017}, {"title": "A Unified Approach to Interpreting Model Predictions", "authors": ["Scott M. Lundberg", "Su-In Lee"], "year": 2017}, {"title": "SHAP: Shapley Additive Explanations", "authors": ["Scott M. Lundberg", "Su-In Lee"], "year": 2017}, {"title": "Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI", "authors": ["Arrieta, Alejandro Barredo", "D\u00edaz-Rodr\u00edguez, Natalia", "Del Ser, Javier", "Bennetot, Adrien", "Tabik, Siham", "Barbado, Alberto", "Garcia, Salvador Gil-Lopez", "Molina, Daniel Benjamins", "Chatila, Raja", "Herrera, Francisco"], "year": 2020}, {"title": "Towards A Rigorous Science of Interpretable Machine Learning", "authors": ["Finale Doshi-Velez", "Been Kim"], "year": 2017}, {"title": "The Mythos of Model Interpretability", "authors": ["Zachary C. Lipton"], "year": 2016}, {"title": "Visualizing and Understanding Convolutional Networks", "authors": ["Matthew D. Zeiler", "Rob Fergus"], "year": 2014}, {"title": "Understanding Black-box Predictions via Influence Functions", "authors": ["Pang Wei Koh", "Percy Liang"], "year": 2017}, {"title": "Interpretability is Harder in the Multiclass Setting: Axiomatic Interpretability for Multiclass Additive Models", "authors": ["Logan Graham", "Markus Kalander", "Ben Lengerich", "Rich Caruana"], "year": 2020}, {"title": "Explainable Deep Learning: A Field Guide for the Uninitiated", "authors": ["Michael T. Ribeiro", "Sameer Singh", "Carlos Guestrin"], "year": 2016}, {"title": "Feature Importance Estimation for Explainable AI: A Survey", "authors": ["J. T. Springenberg", "A. Dosovitskiy", "T. Brox", "M. Riedmiller"], "year": 2014}, {"title": "Contextual Decomposition for Neural Network Interpretability", "authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"], "year": 2017}, {"title": "Learning Important Features Through Propagating Activation Differences", "authors": ["Avanti Shrikumar", "Peyton Greenside", "Anshul Kundaje"], "year": 2017}]