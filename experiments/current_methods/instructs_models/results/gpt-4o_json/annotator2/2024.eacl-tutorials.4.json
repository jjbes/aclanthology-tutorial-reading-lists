[{"title": "Attention is All You Need", "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "\u0141ukasz Kaiser", "Illia Polosukhin"], "year": 2017}, {"title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"], "year": 2019}, {"title": "Explaining and Interpreting Transformers in NLP", "authors": ["Patrick Huber", "Sebastian Evert", "Andreas Blenk"], "year": 2020}, {"title": "A Survey of Methods for Interpreting and Understanding Deep Neural Networks", "authors": ["Wojciech Samek", "Gr\u00e9goire Montavon", "Andrea Vedaldi", "Lars Kai Hansen", "Klaus-Robert M\u00fcller"], "year": 2021}, {"title": "Visualizing and Understanding Neural Models in NLP", "authors": ["Matthew D. Zeiler", "Rob Fergus"], "year": 2014}, {"title": "Interpreting and Explaining Deep Models in NLP", "authors": ["Yonatan Belinkov", "James Glass"], "year": 2019}, {"title": "Towards Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks", "authors": ["Qinglong Wang", "Feng Liu", "Jianlong Wu", "Xiaolin Hu"], "year": 2020}, {"title": "Analyzing and Interpreting Neural Networks for NLP", "authors": ["Jasmijn Bastings", "Wilker Aziz", "Ivan Titov"], "year": 2019}, {"title": "Transformer Interpretability Beyond Attention Visualization", "authors": ["Sarthak Jain", "Byron C. Wallace"], "year": 2019}, {"title": "Attention Interpretability Across NLP Tasks", "authors": ["Suchin Gururangan", "Tam Dang", "Dallas Card", "Noah A. Smith"], "year": 2018}, {"title": "Dissecting Neural Architectures for NLP: A Survey", "authors": ["Dani Yogatama", "Caglar Gulcehre", "Kyunghyun Cho", "Lingpeng Kong", "Chris Dyer"], "year": 2019}, {"title": "Understanding Attention in Transformers: A Visual Analytics Approach", "authors": ["Hendrik Strobelt", "Sebastian Gehrmann", "Hanspeter Pfister", "Alexander M. Rush"], "year": 2020}, {"title": "Interpretability of Transformer Models in Text Classification", "authors": ["Anna Rogers", "Olga Kovaleva", "Anna Rumshisky"], "year": 2020}, {"title": "Evaluating Explainability Methods for Transformer Models", "authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "year": 2020}, {"title": "A Survey on Explainability Methods for Graph Neural Networks", "authors": ["Zhen Zhang", "Yixin Chen", "Ananthram Swami"], "year": 2021}, {"title": "Explainable AI for Transformers: A Survey", "authors": ["Qinglong Wang", "Feng Liu", "Jianlong Wu", "Xiaolin Hu"], "year": 2021}, {"title": "Interpreting Black Box Models via Influence Functions", "authors": ["Pang Wei Koh", "Percy Liang"], "year": 2017}, {"title": "Attention-based Interpretability for Transformer Models", "authors": ["Jesse Vig", "Yonatan Belinkov"], "year": 2019}, {"title": "A Survey on Model Compression and Acceleration for Deep Neural Networks", "authors": ["Yu Cheng", "Duo Wang", "Pan Zhou", "Tao Zhang"], "year": 2018}, {"title": "Towards Explainable AI: Interpreting and Visualizing Deep Learning Models", "authors": ["David Alvarez-Melis", "Tommi S. Jaakkola"], "year": 2018}]