[{"title": "Attention is All You Need", "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "\u0141ukasz Kaiser", "Illia Polosukhin"], "year": 2017}, {"title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"], "year": 2019}, {"title": "Explaining in Style: Training a GAN to explain a classifier in StyleSpace", "authors": ["Harkirat Singh Behl", "Leonid Keselman", "Adrian Bulat", "Georgios Tzimiropoulos"], "year": 2022}, {"title": "Visualizing and Understanding Neural Models in NLP", "authors": ["Matthew D. Zeiler", "Rob Fergus"], "year": 2014}, {"title": "A Unified Approach to Interpreting Model Predictions", "authors": ["Scott M. Lundberg", "Su-In Lee"], "year": 2017}, {"title": "Interpretable and Explainable Deep Learning: A Survey", "authors": ["Wojciech Samek", "Thomas Wiegand", "Klaus-Robert M\u00fcller"], "year": 2017}, {"title": "Attention-based Interpretability with Applications to Sentiment Analysis", "authors": ["Jesse Vig"], "year": 2019}, {"title": "Transformer Interpretability Beyond Attention Visualization", "authors": ["Cheolhyoung Lee", "Jongseok Kim", "Jongwuk Lee"], "year": 2020}, {"title": "Towards Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks", "authors": ["Zhi-Qi Cheng", "Yongxin Yang", "Tao Xiang", "Timothy M. Hospedales"], "year": 2021}, {"title": "Analyzing and Interpreting Neural Networks for NLP: A Report on the First BlackboxNLP Workshop", "authors": ["Yonatan Belinkov", "James Glass"], "year": 2018}, {"title": "Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions", "authors": ["Pang Wei Koh", "Percy Liang"], "year": 2017}, {"title": "Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?", "authors": ["Been Kim", "Rajiv Khanna", "Oluwasanmi Koyejo"], "year": 2016}, {"title": "Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)", "authors": ["Been Kim", "Martin Wattenberg", "Justin Gilmer", "Carrie Cai", "James Wexler", "Fernanda Vi\u00e9gas", "Ruth Fong"], "year": 2018}, {"title": "Attention Interpretability Across NLP Tasks", "authors": ["Jesse Vig", "Yonatan Belinkov"], "year": 2019}, {"title": "Dissecting Neural Networks by Analyzing Hidden Representations", "authors": ["Chris Olah", "Arvind Satyanarayan", "Ian Johnson", "Shan Carter", "Ludwig Schubert", "Katherine Ye", "Alexander Mordvintsev"], "year": 2018}, {"title": "The Building Blocks of Interpretability", "authors": ["Chris Olah", "Shan Carter", "Ludwig Schubert", "Ian Johnson", "Ferenc Husz\u00e1r"], "year": 2018}, {"title": "Towards Robust and Interpretable Neural Networks", "authors": ["Bin Yu", "Cynthia Rudin"], "year": 2019}, {"title": "Explainable AI: Interpreting, Explaining and Visualizing Deep Learning", "authors": ["Wojciech Samek", "Gr\u00e9goire Montavon", "Andrea Vedaldi", "Lars Kai Hansen", "Klaus-Robert M\u00fcller"], "year": 2019}, {"title": "Understanding Neural Networks Through Deep Visualization", "authors": ["Jason Yosinski", "Jeff Clune", "Anh Nguyen", "Thomas Fuchs", "Hod Lipson"], "year": 2015}, {"title": "A Survey of Methods for Explaining Black Box Models", "authors": ["Riccardo Guidotti", "Anna Monreale", "Salvatore Ruggieri", "Franco Turini", "Fosca Giannotti", "Dino Pedreschi"], "year": 2018}]