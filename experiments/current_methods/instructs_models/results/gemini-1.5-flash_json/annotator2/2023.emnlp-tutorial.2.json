[{"authors": ["Moustafa Alzantot,  Bhavani Shankar,  Kevin  Gimpel"], "title": "Generating Natural Language Adversarial Examples", "year": 2018}, {"authors": ["Nicholas Carlini,  David Wagner"], "title": "Towards Evaluating the Robustness of Natural Language Processing Models", "year": 2017}, {"authors": ["Ian  Goodfellow,  Jonathon  Shlens,  Christian  Szegedy"], "title": "Explaining and Harnessing Adversarial Examples", "year": 2014}, {"authors": ["Robin  Jia,  Percy  Liang"], "title": "Data Poisoning Attacks Against  Deep  Learning  Models", "year": 2018}, {"authors": ["Nicholas  Carlini,  David  Wagner"], "title": "Audio Adversarial Examples: Targeted Attacks on Speech Recognition", "year": 2018}, {"authors": ["Anish  Athalye,  Nicholas  Carlini,  David  Wagner"], "title": "Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples", "year": 2018}, {"authors": ["Aleksander  Madry,  Aleksander  Makelov,  Ludwig  Schmidt,  Dimitris  Tsipras,  Adrian  Vladu"], "title": "Towards Deep Learning Models Resistant to Adversarial Attacks", "year": 2017}, {"authors": ["Florian Tramèr,  Nicolas  Papernot,  Ian  Goodfellow,  Dan  Boneh,  Patrick  McDaniel"], "title": "The Space of Transferable Adversarial Examples", "year": 2017}, {"authors": ["Nicholas  Carlini,  David  Wagner"], "title": "Defensive Distillation:  A  Defense  Against  Adversarial  Examples", "year": 2016}, {"authors": ["Christian  Szegedy,  Wojciech  Zaremba,  Ilya  Sutskever,  Joan  Bruna,  Dumitru  Erhan,  Ian  Goodfellow,  Rob  Fergus"], "title": "Intriguing Properties of Neural Networks", "year": 2013}, {"authors": ["Ekin  D.  Ciftci,  Soroush  Bateni,  Seyed  Mohsen  Pourmohammad,  Hamed  Pirsiavash"], "title": "Towards  Robust  Deep  Learning  Models  with  Adversarial  Training", "year": 2018}, {"authors": ["Shiqi  Wang,  Yizheng  Chen,  Heng  Sheng,  Han  Zhang,  Chaowei  Xiao,  Jun  Zhu,  Bo  Zhang"], "title": "Robust  Neural  Networks  Against  Adversarial  Examples", "year": 2018}, {"authors": ["Nicholas  Carlini,  David  Wagner"], "title": "Adversarial Examples Are Not Easily Detected:  Ensemble  Adversarial  Training  and  Black-Box  Attacks", "year": 2017}, {"authors": ["Aleksander  Madry,  Aleksander  Makelov,  Ludwig  Schmidt,  Dimitris  Tsipras,  Adrian  Vladu"], "title": "Towards Deep Learning Models Resistant to Adversarial Attacks", "year": 2017}, {"authors": ["Florian Tramèr,  Nicolas  Papernot,  Ian  Goodfellow,  Dan  Boneh,  Patrick  McDaniel"], "title": "The Space of Transferable Adversarial Examples", "year": 2017}, {"authors": ["Nicholas  Carlini,  David  Wagner"], "title": "Defensive Distillation:  A  Defense  Against  Adversarial  Examples", "year": 2016}, {"authors": ["Christian  Szegedy,  Wojciech  Zaremba,  Ilya  Sutskever,  Joan  Bruna,  Dumitru  Erhan,  Ian  Goodfellow,  Rob  Fergus"], "title": "Intriguing Properties of Neural Networks", "year": 2013}, {"authors": ["Ekin  D.  Ciftci,  Soroush  Bateni,  Seyed  Mohsen  Pourmohammad,  Hamed  Pirsiavash"], "title": "Towards  Robust  Deep  Learning  Models  with  Adversarial  Training", "year": 2018}, {"authors": ["Shiqi  Wang,  Yizheng  Chen,  Heng  Sheng,  Han  Zhang,  Chaowei  Xiao,  Jun  Zhu,  Bo  Zhang"], "title": "Robust  Neural  Networks  Against  Adversarial  Examples", "year": 2018}, {"authors": ["Nicholas  Carlini,  David  Wagner"], "title": "Adversarial Examples Are Not Easily Detected:  Ensemble  Adversarial  Training  and  Black-Box  Attacks", "year": 2017}]
