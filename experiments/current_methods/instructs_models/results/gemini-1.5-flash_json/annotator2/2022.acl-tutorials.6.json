[{"authors": ["Brown, Tom B.", "Mann, Benjamin", "Rytting, Nick", "Kabra, Sandeep", "Dhariwal, Pieter", "Amodei, Dario", "Akhter, Ilia", "Tran, Blake", "McCandlish, Sam", "Henighan, Tom", "Shah, Aditya", "Lu, Lu", "Zhao, Xi", "Qiao, Greg", "Le, Shi", "Sachdev, Vishal", "McCann, Bill", "Sutskever, Ilya", "Olah, Chris"], "title": "Language Models are Few-Shot Learners", "year": 2020}, {"authors": ["Radford, Alec", "Wu, Jeffrey", "Child, Rewon", "Lu, David", "Amodei, Dario", "Sutskever, Ilya"], "title": "Language Models are Unsupervised Multitask Learners", "year": 2019}, {"authors": ["Liu, Yinhan", "Ott, Myle", "Goyal, Naman", "Du, Jingfei", " Joshi, Mandar", "Chen, Danqi", "Levy, Omer", "Lewis, Mike", "Zettlemoyer, Luke"], "title": "Roberta: A Robustly Optimized BERT Pretraining Approach", "year": 2019}, {"authors": ["Devlin, Jacob", "Chang, Ming-Wei", "Lee, Kenton", "Toutanova, Kristina"], "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "year": 2018}, {"authors": ["Conneau, Alexis", "Kiela, Douwe", "Schwenk, Holger", "Barrault, Loïc", "Lecun, Yann"], "title": "Few-Shot Text Classification with Pre-Trained Language Models", "year": 2020}, {"authors": ["Wang, Alex", "Singh, Amanpreet", "Michael, Julian", "Hill, Felix", "Levy, Omer", "Bowman, Samuel R"], "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding", "year": 2018}, {"authors": ["Sanh, Victor", "Dehaene, Etienne", "Strub, Frederic", "Winata, Genta Indra", "Abadi, Martin", "Duval, Sylvain", "Liao, Clement", "Furukawa, Thomas", "Jernite, Yacine", "Dauphin, Yann", "Conneau, Alexis"], "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter", "year": 2019}, {"authors": ["Gururangan, Suchin", "Marasović, Ana", "Beltagy, Ido", "Smith, Noah A.", "Hovy, Eduard"], "title": "Don't Stop Pretraining: Adapt Language Models to Domains and Tasks", "year": 2020}, {"authors": ["Schick, Timo", "Schuster, Sebastian"], "title": "Few-Shot Text Classification with Pre-Trained Language Models: A Meta-Learning Perspective", "year": 2020}, {"authors": ["Liu, Pengfei", "Deng, Jie", "Wang, Wei", "Li, Jun", "Zhang, Wei", "Liu, Bing"], "title": "Multi-Task Deep Neural Networks for Natural Language Understanding", "year": 2019}, {"authors": ["Peters, Matthew E.", "Neumann, Mark", "Iyyer, Mohit", "Gardner, Matt", "Clark, Christopher", "Lee, Kenton", "Zettlemoyer, Luke"], "title": "Deep contextualized word representations", "year": 2018}, {"authors": ["Wang, Yifan", "Ma, Jingjing", "Li, Wei", "Wang, Haijun", "Zhou, Michael R"], "title": "Few-Shot Text Classification with Pre-Trained Language Models: A Survey", "year": 2021}, {"authors": ["Sun, Shengyao", "Wang, Yifan", "Li, Wei", "Wang, Haijun", "Zhou, Michael R"], "title": "Meta-Learning for Few-Shot Text Classification with Pre-Trained Language Models", "year": 2021}, {"authors": ["Zhang, Xiang", "Zhao, Jun", "LeCun, Yann"], "title": "Character-Level Convolutional Networks for Text Classification", "year": 2015}, {"authors": ["Kim, Yoon"], "title": "Convolutional Neural Networks for Sentence Classification", "year": 2014}, {"authors": ["Howard, Jeremy", "Ruder, Sebastian"], "title": "Universal Language Model Fine-tuning for Text Classification", "year": 2018}, {"authors": ["Dai, Andrew M.", "Yang, Zihang", "Yang, Yiming", "Carbonell, Jaime G.", "Le, Quoc V"], "title": "Semantic Embeddings from Language Models: Towards Compositional Semantics", "year": 2015}, {"authors": ["Mikolov, Tomas", "Chen, Kai", "Corrado, Greg S.", "Dean, Jeffrey"], "title": "Efficient Estimation of Word Representations in Vector Space", "year": 2013}, {"authors": ["Pennington, Jeffrey", "Socher, Richard", "Manning, Christopher D"], "title": "Glove: Global Vectors for Word Representation", "year": 2014}, {"authors": ["Bansal, Mohit", "Srikumar, Ramanathan", "Belanger, David", "Hovy, Eduard"], "title": "Learning to Represent Programs with Code Embeddings", "year": 2016}]
