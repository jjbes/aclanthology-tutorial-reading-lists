[{"authors": ["Li, J.", "Ding, N.", "Tang, J.", "Zhou, M.", "Wang, Y.", "Li, H.", "Zhang, Z.", "Wang, J.", "Zhang, B.", "Yu, P. S.", "et al."],"title": "Towards Interpretable Transformer for Text Classification","year": 2022},{"authors": ["Jain, S.", "Bhattacharya, P."],"title": "Interpretability in Transformers: A Survey","year": 2022},{"authors": ["Pruksachatkun, Y.", "Guu, K.", "Chen, T.", "Krasheninnikov, D.", "Chen, M.", "Chen, W.", "Yang, Y.", "Chang, M. W."],"title": "The Neural Attention Mechanism Explained","year": 2020},{"authors": ["Wiegreffe, S.", "Papp, G.", "Clark, P."],"title": "Attention is not Explanation: A Critical Review of Attention Mechanisms in NLP","year": 2022},{"authors": ["Voita, E.", "Croce, D.", "Titov, I."],"title": "Analyzing Transformers","year": 2021},{"authors": ["Hooker, S.", "Kiela, D.", "Clark, P."],"title": "Are Attention Weights Actually Interpretable?","year": 2021},{"authors": ["Abnar, S.", "Bhattacharya, P."],"title": "Interpretable Transformers","year": 2021},{"authors": ["Liao, R.", "Zhao, H.", "Zhao, L.", "Wang, W.", "Zhou, M."],"title": "Towards Interpretable Transformer with Local Attention","year": 2021},{"authors": ["Serrano, S.", "Kiela, D."],"title": "What Does BERT Look At? Analyzing BERT's Attention","year": 2020},{"authors": ["Clark, K.", "Khan, M.", "King, S.", "Kiela, D."],"title": "What Does BERT Learn? Analyzing the Representations of BERT","year": 2020},{"authors": ["Jain, S.", "Bhattacharya, P."],"title": "Interpretable Transformers","year": 2021},{"authors": ["Hendrycks, D.", "Burns, C.", "Moritz, P.", "Steinhardt, J."],"title": "Measuring and Reducing the Inductive Bias of Transformers","year": 2021},{"authors": ["Liu, H.", "Zhou, D.", "Zhao, T.", "Wang, W."],"title": "Towards Interpretable Transformer with Local Attention","year": 2021},{"authors": ["Vig, J."],"title": "Why do Transformers Work? A Theoretical Explanation from the Perspective of Function Spaces","year": 2021},{"authors": ["Michel, P.", "Søgaard, A."],"title": "On the Interpretability of Attention Weights","year": 2021},{"authors": ["Du, M.", "Liu, H.", "Wang, W."],"title": "Towards Interpretable Transformer with Local Attention","year": 2021},{"authors": ["Zhang, X.", "Zhao, J.", "LeCun, Y."],"title": "Interpretable Convolutional Neural Networks","year": 2018},{"authors": ["Zhou, B.", "Khosla, A.", "Lapedriza, A.", "Oliva, A.", "Torralba, A."],"title": "Learning Deep Features for Discriminative Localization","year": 2016},{"authors": ["Selvaraju, R. R.", "Cogswell, M.", "Das, A.", "Vedantam, R.", "Parikh, D.", "Batra, D."],"title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization","year": 2017},{"authors": ["Kindermans, P. J.", "Schütt, K. T.", "Verbeek, J."],"title": "Learning to Explain: An Information-Theoretic Perspective on Model Interpretation","year": 2017}]
