## Reading List: Explaining & Interpreting NLP Neural Models (up to 2020)

This list focuses on articles exploring methods for explaining and interpreting NLP neural models, with a focus on techniques and applications.

**General Overviews & Introductions:**

1. **"Towards Explainable NLP: A Survey of Methods and Applications"** (Li et al., 2020) - Comprehensive survey covering various techniques for explaining NLP models.
2. **"Interpretable Machine Learning for Natural Language Processing"** (Li et al., 2019) - Overview of interpretable ML methods applied to NLP tasks.
3. **"Explainable Artificial Intelligence (XAI): Concepts, Techniques, and Applications"** (Adadi & Berrada, 2018) - Broad introduction to XAI, including relevant NLP applications.

**Attention-Based Explanations:**

4. **"Attention is All You Need"** (Vaswani et al., 2017) - Introduces the Transformer architecture, which uses attention mechanisms for interpretability.
5. **"Visualizing and Understanding Attention in Deep Learning"** (Jain & Wallace, 2019) - Explores visualization techniques for understanding attention mechanisms.
6. **"Attention: A Critical Review"** (Voita et al., 2019) - Discusses the limitations and potential of attention mechanisms for interpretability.

**Feature Importance & Saliency:**

7. **"DeepLIFT: Learning Important Features for Explainable Deep Learning"** (Shrikumar et al., 2017) - Introduces DeepLIFT, a method for attributing predictions to input features.
8. **"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"** (Selvaraju et al., 2017) - Presents Grad-CAM, a technique for visualizing class-specific activations in CNNs.
9. **"Integrated Gradients: Interpreting Model Predictions by Connecting Gradients with Input Features"** (Sundararajan et al., 2017) - Introduces Integrated Gradients, a method for attributing predictions to input features.

**Model-Agnostic Techniques:**

10. **"LIME: Explaining the Predictions of Any Classifier"** (Ribeiro et al., 2016) - Introduces LIME, a model-agnostic method for explaining predictions locally.
11. **"SHAP: A Unified Approach to Explainable AI"** (Lundberg & Lee, 2017) - Presents SHAP, a game-theoretic approach for explaining predictions.
12. **"Counterfactual Explanations for Machine Learning"** (Wachter et al., 2017) - Explores counterfactual explanations for understanding model decisions.

**Applications in NLP:**

13. **"Explainable Neural Networks for Text Classification"** (Jain & Wallace, 2019) - Applies attention and saliency methods to explain text classification models.
14. **"Towards Explainable Machine Translation"** (Bahar et al., 2019) - Explores techniques for explaining machine translation models.
15. **"Interpretable Neural Networks for Sentiment Analysis"** (Li et al., 2018) - Investigates interpretable models for sentiment analysis tasks.
16. **"Explainable Dialogue Systems"** (Li et al., 2019) - Discusses the importance of explainability in dialogue systems.

**Challenges & Future Directions:**

17. **"The Myth of Model Interpretability"** (Lipton, 2018) - Critiques the limitations of current interpretability methods.
18. **"Challenges and Opportunities for Explainable AI in NLP"** (Li et al., 2020) - Highlights challenges and future directions for explainable NLP.
19. **"Towards Trustworthy AI: A Framework for Explainable and Interpretable Machine Learning"** (Guidotti et al., 2019) - Discusses the need for trustworthy AI, including explainability.
20. **"Human-in-the-Loop Explainable AI"** (Miller, 2019) - Explores the role of human interaction in improving explainability.

This list provides a starting point for exploring the field of explainable NLP. Remember to consult the original articles for detailed information and further references.