[{"authors": ["Carlini, Nicholas;  Athalye, Anish;  Papernot, Nicolas;  Goodfellow, Ian;  Shlens, Jonathan;  Szegedy, Christian"], "title": "Evaluating adversarial robustness", "year": 2017}, {"authors": ["Wallace, Eric;  Bhojanapalli, Srinadh;  Hinton, Geoffrey;  Srebro, Nathan"], "title": "Addressing the data scarcity problem via adversarial learning", "year": 2018}, {"authors": ["Carlini, Nicholas;  Wagner, David"], "title": "Towards evaluating the robustness of neural networks", "year": 2017}, {"authors": ["Papernot, Nicolas;  McDaniel, Patrick;  Jha, Somesh;  Fredrikson, Matt;  Cui, Z. Berkay;  Swami, Ananthram"], "title": "The limitations of deep learning in adversarial settings", "year": 2016}, {"authors": ["Madry, Aleksander;  Makelov, Aleksandar;  Schmidt, Ludwig;  Tsipras, Dimitris;  Vladu, Adrian"], "title": "Towards deep learning models resistant to adversarial attacks", "year": 2017}, {"authors": ["Ebrahimi, Javid;  Rao, Aditya;  Dou, Wei;  Keutzer, Kurt;  Salakhutdinov, Ruslan"], "title": "Adversarial training for large language models", "year": 2021}, {"authors": ["Carlini, Nicholas;  Wagner, David"], "title": "Audio adversarial examples: Targeted attacks on speech recognition", "year": 2018}, {"authors": ["Liu, Shiqi;  Li, Jinfeng;  Li, Bo;  Wang, Ting;  Zhang, Jun"], "title": "Towards robust deep learning models with adversarial training", "year": 2019}, {"authors": ["Athalye, Anish;  Carlini, Nicholas;  Wagner, David"], "title": "Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples", "year": 2018}, {"authors": ["Tramèr, Florian;  Boneh, Dan;  McDaniel, Patrick"], "title": "Differential privacy and the robustness of machine learning", "year": 2019}, {"authors": ["Shokri, Reza;  Stronati, Marco;  Song, Song;  Shmatikov, Vitaly"], "title": "Membership inference attacks against machine learning models", "year": 2017}, {"authors": ["Fredrikson, Matt;  Lantz, Eric;  Jha, Somesh;  Lin, Suman;  Chi,  Daniel"], "title": "Privacy in pharmacogenetics: An end-to-end case study of personalized medicine", "year": 2014}, {"authors": ["Nasr, Mohammad;  Shokri, Reza;  Houmansadr, Amir;  Shmatikov, Vitaly"], "title": "Privacy-preserving deep learning", "year": 2019}, {"authors": ["Geiping, Jonas;  Bauer,  Sebastian;  Bock,  Michael;  Moeller,  Matthias;  Dröge,  Carolin"], "title": "Inverting gradients - how easy is it to break privacy in federated learning?", "year": 2020}, {"authors": ["Carlini, Nicholas;  Wagner, David"], "title": "Defensive distillation is not robust to adversarial examples", "year": 2017}, {"authors": ["Papernot, Nicolas;  Jha, Somesh;  Cui, Z. Berkay;  Du, W.  Richard;  McDaniel, Patrick"], "title": "Practical black-box attacks against machine learning", "year": 2017}, {"authors": ["Goodfellow, Ian;  Shlens, Jonathan;  Szegedy, Christian"], "title": "Explaining and harnessing adversarial examples", "year": 2014}, {"authors": ["Szegedy, Christian;  Zaremba, Wojciech;  Sutskever, Ilya;  Bruna, Joan;  Erhan, Dumitru;  Goodfellow, Ian;  Fergus, Rob"], "title": "Intriguing properties of neural networks", "year": 2013}, {"authors": ["Biggio, Battista;  Nelson, Blaine;  Laskov, Pavel"], "title": "Poisoning attacks against support vector machines", "year": 2012}, {"authors": ["Barreno, Marco;  Nelson, Blaine;  Tygar,  J.D.;  Setty,  S.  Ravi"], "title": "Can machine learning be secure?", "year": 2010}]
