[
  {
    "title": [
      "## Multimodal Grounding and Meaning Representation for Situated Reasoning: A Reading List (2022 and Earlier"
    ],
    "type": null
  },
  {
    "title": [
      "This list provides a selection of articles exploring multimodal grounding and meaning representation for situated reasoning, focusing on research published up to",
      "It covers a range of topics, including"
    ],
    "date": [
      "2022"
    ],
    "type": null
  },
  {
    "title": [
      "* **Visual grounding of language:** Connecting language to visual information"
    ],
    "type": null
  },
  {
    "note": [
      "* **Multimodal representation:** Combining different modalities (e.g., text, vision, audio) for richer understanding."
    ],
    "type": null
  },
  {
    "title": [
      "* **Situated reasoning:** Understanding and reasoning about the context of interaction"
    ],
    "type": null
  },
  {
    "title": [
      "* **Applications:** Robotics, human-computer interaction, and more"
    ],
    "type": null
  },
  {
    "title": [
      "**Note:** This list is not exhaustive and reflects a selection of influential and representative works"
    ],
    "type": null
  },
  {
    "citation-number": [
      "**1."
    ],
    "title": [
      "Grounding Language in the Visual World**"
    ],
    "type": null
  },
  {
    "title": [
      "* **\"Visual Grounding of Language in the Real World\" by Fei-Fei Li et al",
      "A foundational work on grounding language in visual scenes"
    ],
    "date": [
      "2009"
    ],
    "type": null
  },
  {
    "title": [
      "* **\"Learning to Ground Words in Images\" by Andrej Karpathy et al",
      "Introduces a deep learning approach for visual grounding"
    ],
    "date": [
      "2014"
    ],
    "type": null
  },
  {
    "title": [
      "* **\"Visual Semantic Embedding: A Framework for Grounding Language in Images",
      "Proposes a framework for embedding language and visual information in a shared space"
    ],
    "author": [
      {
        "family": "Michael R. Lyu",
        "particle": "by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2015"
    ],
    "type": null
  },
  {
    "title": [
      "* **\"Learning to See by Reading: Visual Grounding for Object Recognition\" by Alexander Kolesnikov et al",
      "Explores how reading can improve visual recognition"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "title": [
      "* **\"Visual Dialog\" by Abhishek Das et al",
      "Introduces a challenging dataset and task for visual grounding in dialogue"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "citation-number": [
      "**2."
    ],
    "publisher": [
      "Multimodal Representation and Reasoning**"
    ],
    "type": "book"
  },
  {
    "title": [
      "* **\"Multimodal Deep Learning for Vision and Language\" by Andrej Karpathy et al",
      "A comprehensive overview of multimodal deep learning techniques"
    ],
    "date": [
      "2015"
    ],
    "type": null
  },
  {
    "title": [
      "* **\"Multimodal Fusion for Visual Question Answering\" by Zichao Li et al",
      "Explores multimodal fusion for visual question answering"
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "title": [
      "* **\"Multimodal Reasoning with Contextualized Embeddings\" by Jacob Andreas et al",
      "Introduces a framework for multimodal reasoning using contextualized embeddings"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "title": [
      "* **\"Multimodal Commonsense Reasoning\" by Yezhou Yang et al",
      "Focuses on multimodal reasoning for commonsense tasks"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "title": [
      "* **\"Multimodal Embeddings for Situated Dialogue\" by David Harwath et al",
      "Explores multimodal embeddings for situated dialogue systems"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "**3."
    ],
    "author": [
      {
        "family": "Reasoning",
        "given": "Situated"
      },
      {
        "family": "AI",
        "given": "Embodied"
      }
    ],
    "type": null
  },
  {
    "title": [
      "* **\"Embodied Conversational Agents: A Survey\" by Justine Cassell et al",
      "A foundational survey on embodied conversational agents"
    ],
    "date": [
      "2000"
    ],
    "type": null
  },
  {
    "title": [
      "* **\"Situated Language Understanding: A Survey"
    ],
    "author": [
      {
        "family": "Michael R. Lyu",
        "particle": "by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2017"
    ],
    "note": [
      "Reviews research on situated language understanding."
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Michael R. Lyu",
        "given": "Towards Situated Reasoning",
        "particle": "in Embodied Agents\" by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "Discusses challenges and opportunities for situated reasoning in embodied agents"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Embodied",
        "given": "A.I."
      },
      {
        "family": "Michael R. Lyu",
        "particle": "by"
      },
      {
        "others": true
      }
    ],
    "title": [
      "A Survey",
      "A comprehensive survey on embodied AI research"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Michael R. Lyu",
        "given": "Grounded Language Learning",
        "particle": "in Embodied Agents\" by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2021"
    ],
    "title": [
      "Explores how embodied agents can learn language through interaction with the world"
    ],
    "type": null
  },
  {
    "citation-number": [
      "**4."
    ],
    "location": [
      "Applications"
    ],
    "type": null
  },
  {
    "title": [
      "* **\"Visual Navigation with Language\" by Peter Anderson et al",
      "Explores using language for visual navigation in robots"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "title": [
      "* **\"Human-Robot Collaboration: A Survey"
    ],
    "author": [
      {
        "family": "Michael R. Lyu",
        "particle": "by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "note": [
      "Reviews research on human-robot collaboration."
    ],
    "type": null
  },
  {
    "title": [
      "* **\"Multimodal Dialogue Systems for Human-Robot Interaction",
      "Discusses multimodal dialogue systems for human-robot interaction"
    ],
    "author": [
      {
        "family": "Michael R. Lyu",
        "particle": "by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Michael R. Lyu",
        "given": "Towards",
        "particle": "a Multimodal Understanding of Human Behavior\" by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2021"
    ],
    "title": [
      "Explores multimodal understanding of human behavior for applications like social robotics"
    ],
    "type": null
  },
  {
    "title": [
      "* **\"Multimodal Grounding for Human-Robot Interaction",
      "A recent overview of multimodal grounding for human-robot interaction"
    ],
    "author": [
      {
        "family": "Michael R. Lyu",
        "particle": "by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2022"
    ],
    "type": null
  },
  {
    "title": [
      "This reading list provides a starting point for exploring the exciting field of multimodal grounding and meaning representation for situated reasoning. It highlights the growing importance of combining different modalities and reasoning about context for building intelligent systems that can interact with the world in a meaningful way"
    ],
    "type": null
  }
]
