Creating a reading list on natural language generation (NLG) with a focus on implicit commonsense and background knowledge involves selecting articles that cover foundational theories, recent advancements, and applications in this area. Hereâ€™s a list of 20 articles up to 2021 that you might find useful:

1. **"A Survey on Recent Advances in Natural Language Generation"** - This article provides an overview of the field, including the role of commonsense knowledge.
   
2. **"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"** - While focused on understanding, BERT's architecture is foundational for NLG models that incorporate background knowledge.

3. **"GPT-3: Language Models are Few-Shot Learners"** - Discusses the capabilities of GPT-3, including its ability to generate text with implicit commonsense reasoning.

4. **"COMET: Commonsense Transformers for Automatic Knowledge Graph Construction"** - Explores how transformers can be used to generate commonsense knowledge.

5. **"T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"** - Describes a model that can be adapted for NLG tasks requiring background knowledge.

6. **"The Role of Commonsense Knowledge in Open-Domain Text Generation"** - Focuses on how commonsense knowledge can enhance text generation.

7. **"Knowledge-Enhanced Neural Conversational Model"** - Discusses integrating external knowledge into conversational models.

8. **"A Knowledge-Enhanced Pretraining Model for Commonsense Story Generation"** - Explores methods for incorporating commonsense into story generation.

9. **"Commonsense Knowledge in Word Embeddings"** - Examines how word embeddings can capture implicit commonsense knowledge.

10. **"Neural Natural Language Generation: A Review"** - Provides a comprehensive review of neural approaches to NLG, including the use of background knowledge.

11. **"Incorporating Commonsense Knowledge into Neural Machine Translation"** - Discusses the integration of commonsense knowledge in translation tasks.

12. **"Generating Diverse and Consistent QA Pairs from Contextual Knowledge"** - Explores generating question-answer pairs using background knowledge.

13. **"Commonsense Reasoning for Natural Language Understanding: A Survey"** - While focused on understanding, it provides insights applicable to generation.

14. **"Towards Commonsense and Background Knowledge Enhanced Chatbot"** - Discusses enhancing chatbots with commonsense knowledge.

15. **"Knowledge Graphs: Opportunities and Challenges"** - Provides insights into how knowledge graphs can be used in NLG.

16. **"Commonsense Knowledge in AI: A Survey"** - Offers a broad overview of how commonsense knowledge is used in AI, including NLG.

17. **"Leveraging Pre-trained Language Models for Commonsense Reasoning"** - Discusses methods to enhance language models with commonsense reasoning.

18. **"Story Generation with Commonsense Knowledge"** - Focuses on generating coherent stories using commonsense knowledge.

19. **"Commonsense Knowledge in Neural Language Models"** - Examines how neural models can be enhanced with commonsense knowledge.

20. **"A Survey on Commonsense Reasoning for Natural Language Processing"** - Provides a detailed survey on the integration of commonsense reasoning in NLP tasks.

These articles cover a range of topics from foundational models and architectures to specific applications and enhancements involving commonsense and background knowledge in NLG. They should provide a solid foundation for understanding the current state and future directions of the field.