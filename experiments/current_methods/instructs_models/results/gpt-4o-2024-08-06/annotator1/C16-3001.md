Creating a reading list of 20 articles on compositional distributional models of meaning (CDMs) up to 2016 involves selecting foundational and influential works in the field. Here’s a list that covers various aspects of CDMs, including theoretical foundations, applications, and advancements:

1. **Baroni, M., Bernardi, R., & Zamparelli, R. (2014).** "Frege in space: A program for compositional distributional semantics." *Linguistic Issues in Language Technology*.

2. **Clark, S. (2015).** "Vector space models of lexical meaning." *Handbook of Contemporary Semantics*.

3. **Coecke, B., Sadrzadeh, M., & Clark, S. (2010).** "Mathematical foundations for a compositional distributional model of meaning." *Lambek Festschrift*.

4. **Grefenstette, E., & Sadrzadeh, M. (2011).** "Experimental support for a categorical compositional distributional model of meaning." *Conference on Empirical Methods in Natural Language Processing (EMNLP)*.

5. **Mitchell, J., & Lapata, M. (2010).** "Composition in distributional models of semantics." *Cognitive Science*.

6. **Baroni, M., Dinu, G., & Kruszewski, G. (2014).** "Don't count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors." *ACL*.

7. **Turney, P. D., & Pantel, P. (2010).** "From frequency to meaning: Vector space models of semantics." *Journal of Artificial Intelligence Research*.

8. **Socher, R., et al. (2013).** "Recursive deep models for semantic compositionality over a sentiment treebank." *Conference on Empirical Methods in Natural Language Processing (EMNLP)*.

9. **Mikolov, T., et al. (2013).** "Efficient estimation of word representations in vector space." *arXiv preprint arXiv:1301.3781*.

10. **Pennington, J., Socher, R., & Manning, C. D. (2014).** "GloVe: Global vectors for word representation." *EMNLP*.

11. **Firth, J. R. (1957).** "A synopsis of linguistic theory 1930-1955." *Studies in Linguistic Analysis*.

12. **Harris, Z. S. (1954).** "Distributional structure." *Word*.

13. **Landauer, T. K., & Dumais, S. T. (1997).** "A solution to Plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge." *Psychological Review*.

14. **Bengio, Y., et al. (2003).** "A neural probabilistic language model." *Journal of Machine Learning Research*.

15. **Levy, O., & Goldberg, Y. (2014).** "Neural word embedding as implicit matrix factorization." *NIPS*.

16. **Erk, K. (2012).** "Vector space models of word meaning and phrase meaning: A survey." *Language and Linguistics Compass*.

17. **Grefenstette, E. (2013).** "Category-theoretic quantitative compositional distributional models of natural language semantics." *arXiv preprint arXiv:1301.1539*.

18. **Paperno, D., Pham, N. T., & Baroni, M. (2014).** "A practical and linguistically-motivated approach to compositional distributional semantics." *ACL*.

19. **Kartsaklis, D., Sadrzadeh, M., & Pulman, S. (2012).** "A unified sentence space for categorical distributional-compositional semantics: Theory and experiments." *COLING*.

20. **Bojanowski, P., et al. (2016).** "Enriching word vectors with subword information." *arXiv preprint arXiv:1607.04606*.

These articles provide a comprehensive overview of the development and application of CDMs in computational linguistics and natural language processing.