[
  {
    "title": [
      "Creating a reading list of articles on multi-modal information extraction for semi-structured and unstructured data understanding involves selecting influential and relevant papers that cover various aspects of the field. Here is a list of 20 articles up to 2020 that you might find useful"
    ],
    "type": null
  },
  {
    "citation-number": [
      "1."
    ],
    "author": [
      {
        "given": "B.E.R.T."
      }
    ],
    "title": [
      "Pre-training of Deep Bidirectional Transformers for Language Understanding\"** by Jacob Devlin et al",
      "- While not specifically about multi-modal data, BERT has been foundational in NLP, which is crucial for text-based information extraction"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "2."
    ],
    "author": [
      {
        "family": "Ashish Vaswani",
        "given": "Attention",
        "particle": "is All You Need\" by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2017"
    ],
    "title": [
      "- Introduces the Transformer model, which is pivotal for processing sequences of data, including text and other modalities"
    ],
    "type": null
  },
  {
    "citation-number": [
      "3."
    ],
    "title": [
      "**\"Visual Question Answering\"** by Aishwarya Agrawal et al",
      "- Discusses a multi-modal task combining image and text understanding"
    ],
    "date": [
      "2015"
    ],
    "type": null
  },
  {
    "citation-number": [
      "4."
    ],
    "author": [
      {
        "given": "Show"
      }
    ],
    "title": [
      "Attend and Tell: Neural Image Caption Generation with Visual Attention\"** by Kelvin Xu et al",
      "- Explores generating textual descriptions from images using attention mechanisms"
    ],
    "date": [
      "2015"
    ],
    "type": null
  },
  {
    "citation-number": [
      "5."
    ],
    "title": [
      "**\"Deep Visual-Semantic Alignments for Generating Image Descriptions\"** by Andrej Karpathy and Li Fei-Fei",
      "- Focuses on aligning visual and textual data for image captioning"
    ],
    "date": [
      "2015"
    ],
    "type": null
  },
  {
    "citation-number": [
      "6."
    ],
    "title": [
      "**\"Multimodal Machine Learning: A Survey and Taxonomy\"** by Hao-Ting Chang et al",
      "- Provides a comprehensive survey of multi-modal machine learning techniques"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "citation-number": [
      "7."
    ],
    "author": [
      {
        "given": "V.I.L.B.E.R.T."
      }
    ],
    "title": [
      "Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\"** by Jiasen Lu et al",
      "- Discusses a model for joint vision and language representation learning"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "8."
    ],
    "title": [
      "**\"Unified Visual-Semantic Embeddings: Bridging Vision and Language with Structured Meaning Representations\"** by Vicente Ordonez et al",
      "- Explores embeddings that unify visual and semantic information"
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "citation-number": [
      "9."
    ],
    "title": [
      "**\"Deep Multimodal Representation Learning: A Survey\"** by Zhenhua Guo et al",
      "- Surveys methods for learning representations from multiple modalities"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "10."
    ],
    "title": [
      "**\"ImageNet Large Scale Visual Recognition Challenge\"** by Olga Russakovsky et al",
      "- While focused on image classification, it has implications for multi-modal tasks involving images"
    ],
    "date": [
      "2015"
    ],
    "type": null
  },
  {
    "citation-number": [
      "11."
    ],
    "title": [
      "**\"Learning Transferable Visual Models From Natural Language Supervision\"** by Alec Radford et al"
    ],
    "date": [
      "2021"
    ],
    "note": [
      "- Although published in 2021, it builds on prior work in multi-modal learning."
    ],
    "type": null
  },
  {
    "citation-number": [
      "12."
    ],
    "title": [
      "**\"Multimodal Deep Learning\"** by Ngiam Jiquan et al",
      "- One of the earlier works on deep learning for multi-modal data"
    ],
    "date": [
      "2011"
    ],
    "type": null
  },
  {
    "citation-number": [
      "13."
    ],
    "title": [
      "**\"Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books\"** by Yukun Zhu et al",
      "- Discusses aligning textual and visual narratives"
    ],
    "date": [
      "2015"
    ],
    "type": null
  },
  {
    "citation-number": [
      "14."
    ],
    "author": [
      {
        "family": "Matthew Peters",
        "given": "Deep Contextualized Word Representations\"",
        "particle": "by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "- Introduces ELMo, which is important for contextual text understanding"
    ],
    "type": null
  },
  {
    "citation-number": [
      "15."
    ],
    "title": [
      "**\"VideoBERT: A Joint Model for Video and Language Representation Learning\"** by Chen Sun et al"
    ],
    "date": [
      "2019"
    ],
    "note": [
      "- Focuses on learning representations from video and text."
    ],
    "type": null
  },
  {
    "citation-number": [
      "16."
    ],
    "title": [
      "**\"Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks\"** by Bhaskar Mitra et al"
    ],
    "date": [
      "2017"
    ],
    "note": [
      "- Discusses ranking tasks that can be applied to multi-modal data."
    ],
    "type": null
  },
  {
    "citation-number": [
      "17."
    ],
    "title": [
      "**\"Hierarchical Attention Networks for Document Classification\"** by Zichao Yang et al",
      "- Explores attention mechanisms for text, applicable to multi-modal tasks"
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "citation-number": [
      "18."
    ],
    "title": [
      "**\"Deep Learning for Natural Language Processing\"** by Yoon Kim",
      "- Introduces CNNs for text classification, relevant for text-based information extraction"
    ],
    "date": [
      "2014"
    ],
    "type": null
  },
  {
    "citation-number": [
      "19."
    ],
    "author": [
      {
        "family": "Qi Wu",
        "given": "A.Survey",
        "particle": "on Image-based Question Answering\" by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2017"
    ],
    "title": [
      "- Surveys methods for answering questions based on images, a multi-modal task"
    ],
    "type": null
  },
  {
    "citation-number": [
      "20."
    ],
    "title": [
      "**\"Multimodal Sentiment Analysis: Addressing Key Issues and Setting Up the Baselines\"** by Soujanya Poria et al",
      "- Discusses sentiment analysis using multiple data modalities"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "title": [
      "These articles cover a range of topics from foundational models and techniques to specific applications in multi-modal information extraction. They provide a solid foundation for understanding the field up to"
    ],
    "date": [
      "2020"
    ],
    "type": null
  }
]
