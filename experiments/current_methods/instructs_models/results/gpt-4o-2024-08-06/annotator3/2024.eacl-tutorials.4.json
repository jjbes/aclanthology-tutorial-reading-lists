[
  {
    "title": [
      "Creating a reading list of articles on interpretability methods for transformers involves selecting key papers that have contributed to the understanding and development of interpretability in transformer models"
    ],
    "container-title": [
      "Hereâ€™s a list of influential and insightful articles up to 2024"
    ],
    "type": "chapter"
  },
  {
    "citation-number": [
      "1."
    ],
    "title": [
      "**\"Attention is All You Need\"** by Vaswani et al",
      "- The foundational paper introducing the transformer architecture"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "citation-number": [
      "2."
    ],
    "author": [
      {
        "given": "B.E.R.T."
      }
    ],
    "title": [
      "Pre-training of Deep Bidirectional Transformers for Language Understanding\"** by Devlin et al"
    ],
    "date": [
      "2018"
    ],
    "note": [
      "- Introduces BERT, a key model in transformer-based NLP."
    ],
    "type": null
  },
  {
    "citation-number": [
      "3."
    ],
    "title": [
      "**\"A Survey of Methods for Explaining Black Box Models\"** by Guidotti et al",
      "- Provides a comprehensive overview of interpretability methods applicable to transformers"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "citation-number": [
      "4."
    ],
    "title": [
      "**\"Visualizing and Understanding Neural Models in NLP\"** by Li et al",
      "- Discusses early methods for visualizing neural network decisions, applicable to transformers"
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "citation-number": [
      "5."
    ],
    "title": [
      "**\"Interpretable and Explainable Deep Learning: A Survey\"** by Zhang et al",
      "- Surveys interpretability techniques, including those for transformers"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "citation-number": [
      "6."
    ],
    "title": [
      "**\"Explaining and Interpreting LSTMs\"** by Karpathy et al",
      "- While focused on LSTMs, it provides foundational insights applicable to understanding transformers"
    ],
    "date": [
      "2015"
    ],
    "type": null
  },
  {
    "citation-number": [
      "7."
    ],
    "title": [
      "**\"Attention is not Explanation\"** by Jain and Wallace",
      "- Critically examines the role of attention mechanisms in interpretability"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "8."
    ],
    "title": [
      "**\"Towards a Rigorous Science of Interpretable Machine Learning\"** by Doshi-Velez and Kim",
      "- Discusses the principles of interpretability in machine learning"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "citation-number": [
      "9."
    ],
    "title": [
      "**\"Evaluating and Improving the Interpretability of Transformer Models\"** by Clark et al",
      "- Focuses on methods to enhance the interpretability of transformers"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "10."
    ],
    "title": [
      "**\"Transformers Interpretability Beyond Attention Visualization\"** by Chefer et al",
      "- Explores interpretability methods beyond attention maps"
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "citation-number": [
      "11."
    ],
    "title": [
      "**\"Analyzing and Interpreting Transformer Models\"** by Vig",
      "- Provides tools and methods for analyzing transformer models"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "12."
    ],
    "title": [
      "**\"The Building Blocks of Interpretability\"** by Olah et al",
      "- Discusses interpretability techniques that can be applied to transformers"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "citation-number": [
      "13."
    ],
    "title": [
      "**\"Explaining Transformers for Image Recognition\"** by Chefer et al"
    ],
    "date": [
      "2021"
    ],
    "note": [
      "- Focuses on interpretability in vision transformers."
    ],
    "type": null
  },
  {
    "citation-number": [
      "14."
    ],
    "title": [
      "**\"Understanding Pre-trained BERT for Aspect-based Sentiment Analysis\"** by Sun et al",
      "- Analyzes BERT's interpretability in sentiment analysis"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "15."
    ],
    "title": [
      "**\"Interpretability of Deep Learning Models: A Survey of Results\"** by Montavon et al",
      "- Surveys interpretability results, including those for transformers"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "citation-number": [
      "16."
    ],
    "title": [
      "**\"A Survey on the Interpretability of Deep Learning Models\"** by Gilpin et al",
      "- Discusses interpretability in deep learning, relevant to transformers"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "citation-number": [
      "17."
    ],
    "title": [
      "**\"Explaining Neural Networks by Decoding Layer Activations\"** by Bau et al",
      "- Proposes methods for interpreting neural networks, applicable to transformers"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "citation-number": [
      "18."
    ],
    "title": [
      "**\"Attention Flows are Shapley Value Explanations\"** by Abnar and Zuidema",
      "- Introduces a method for interpreting attention in transformers"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "citation-number": [
      "19."
    ],
    "title": [
      "**\"Transformers: State-of-the-Art Natural Language Processing\"** by Wolf et al",
      "- Discusses the state of transformers, including interpretability aspects"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "citation-number": [
      "20."
    ],
    "title": [
      "**\"Towards Interpretable NLP: A Survey\"** by Danilevsky et al",
      "- Surveys interpretability in NLP, with a focus on transformer models"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "title": [
      "These articles provide a comprehensive overview of the development and current state of interpretability methods for transformers. They cover foundational concepts, critical evaluations, and recent advancements in the field"
    ],
    "type": null
  }
]
