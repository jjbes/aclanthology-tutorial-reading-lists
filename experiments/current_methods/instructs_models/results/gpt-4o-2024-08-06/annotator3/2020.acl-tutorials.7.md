Here's a list of 20 articles on commonsense reasoning in natural language processing (NLP) up to 2020. These papers cover various aspects of integrating commonsense knowledge into NLP models, benchmarks, and applications:

1. **"Commonsense Knowledge and Commonsense Reasoning: An Overview"** by Ernest Davis and Gary Marcus (2015)
   - A comprehensive overview of commonsense knowledge and reasoning in AI.

2. **"ConceptNet 5: A Large Semantic Network for Relational Knowledge"** by Robyn Speer and Catherine Havasi (2012)
   - Discusses ConceptNet, a semantic network designed to help computers understand commonsense knowledge.

3. **"COMET: Commonsense Transformers for Automatic Knowledge Graph Construction"** by Antoine Bosselut et al. (2019)
   - Introduces COMET, a model that generates commonsense knowledge using transformers.

4. **"SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference"** by Rowan Zellers et al. (2018)
   - Presents SWAG, a dataset for evaluating grounded commonsense inference.

5. **"CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge"** by Alon Talmor et al. (2019)
   - Introduces CommonsenseQA, a dataset for evaluating commonsense reasoning in QA systems.

6. **"Social IQa: Commonsense Reasoning about Social Interactions"** by Maarten Sap et al. (2019)
   - Proposes Social IQa, a benchmark for evaluating social commonsense reasoning.

7. **"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"** by Jacob Devlin et al. (2019)
   - While not solely focused on commonsense, BERT has been foundational in NLP, including commonsense tasks.

8. **"RoBERTa: A Robustly Optimized BERT Pretraining Approach"** by Yinhan Liu et al. (2019)
   - An optimized version of BERT that has been used in commonsense reasoning tasks.

9. **"LAMA: Analyzing the Knowledge of Language Models"** by Fabio Petroni et al. (2019)
   - Analyzes the factual and commonsense knowledge captured by language models.

10. **"Zero-Shot Text Classification with Generative Language Models"** by Yinfei Yang et al. (2019)
    - Explores zero-shot learning for text classification, relevant for commonsense reasoning.

11. **"The Winograd Schema Challenge"** by Hector J. Levesque et al. (2012)
    - Introduces a challenge for evaluating commonsense reasoning in AI.

12. **"The Winograd Schema Challenge and Machine Reading Comprehension"** by Trieu H. Trinh and Quoc V. Le (2018)
    - Discusses approaches to solving the Winograd Schema Challenge using machine reading comprehension.

13. **"Reasoning about Actions and State Changes by Injecting Commonsense Knowledge"** by Nasrin Mostafazadeh et al. (2016)
    - Explores the use of commonsense knowledge in reasoning about actions and state changes.

14. **"Story Cloze Test: A New Benchmark for Story Understanding and Generation"** by Nasrin Mostafazadeh et al. (2016)
    - Introduces a benchmark for evaluating story understanding, involving commonsense reasoning.

15. **"Event2Mind: Commonsense Inference on Events, Intents, and Reactions"** by Hannah Rashkin et al. (2018)
    - Proposes a model for inferring commonsense knowledge about events, intents, and reactions.

16. **"OpenAI GPT: Generative Pre-trained Transformer"** by Alec Radford et al. (2018)
    - Discusses the GPT model, which has been used for various commonsense reasoning tasks.

17. **"Knowledge-Enhanced Contextual Word Representations"** by Kenton Lee et al. (2019)
    - Explores enhancing word representations with knowledge for improved commonsense reasoning.

18. **"Probing Neural Network Comprehension of Natural Language Arguments"** by Ellie Pavlick and Tom Kwiatkowski (2019)
    - Investigates how well neural networks understand natural language arguments, including commonsense reasoning.

19. **"Commonsense Knowledge Mining from Pretrained Models"** by Yao Fu et al. (2020)
    - Discusses methods for extracting commonsense knowledge from pretrained language models.

20. **"ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"** by Zhenzhong Lan et al. (2020)
    - Introduces ALBERT, a model that has been applied to commonsense reasoning tasks.

These articles provide a solid foundation for understanding the development and application of commonsense reasoning in NLP up to 2020.