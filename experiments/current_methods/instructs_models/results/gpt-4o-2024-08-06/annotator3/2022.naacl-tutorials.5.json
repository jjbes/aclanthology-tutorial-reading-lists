[
  {
    "title": [
      "Creating a reading list of 20 articles on multimodal machine learning up to 2022 involves selecting influential and foundational papers that cover various aspects of the field. Here’s a curated list that includes seminal works, surveys, and recent advancements"
    ],
    "type": null
  },
  {
    "citation-number": [
      "1."
    ],
    "title": [
      "**\"Multimodal Machine Learning: A Survey and Taxonomy\"** by Tadas Baltrušaitis, Chaitanya Ahuja, and Louis-Philippe Morency",
      "- A comprehensive survey that categorizes and reviews the field of multimodal ML"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "citation-number": [
      "2."
    ],
    "title": [
      "**\"Deep Multimodal Representation Learning: A Survey\"** by Hao Wang, Zheng-Jun Zha, and Heng Tao Shen",
      "- This paper provides an overview of deep learning approaches for multimodal representation"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "citation-number": [
      "3."
    ],
    "title": [
      "**\"Multimodal Sentiment Analysis: Addressing Key Issues and Setting Up the Baselines\"** by Amir Zadeh et al",
      "- Discusses challenges and baseline methods in multimodal sentiment analysis"
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "citation-number": [
      "4."
    ],
    "title": [
      "**\"Learning Transferable Visual Models From Natural Language Supervision\"** by Alec Radford et al",
      "- Introduces CLIP, a model that learns visual concepts from natural language descriptions"
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "citation-number": [
      "5."
    ],
    "author": [
      {
        "given": "V.A.T.T."
      }
    ],
    "title": [
      "Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text\"** by Hassan Akbari et al",
      "- Proposes a transformer-based model for learning from video, audio, and text"
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "citation-number": [
      "6."
    ],
    "title": [
      "**\"VisualBERT: A Simple and Performant Baseline for Vision and Language\"** by Liunian Harold Li et al",
      "- Introduces a model that integrates visual and textual information for various tasks"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "7."
    ],
    "author": [
      {
        "given": "L.X.M.E.R.T."
      }
    ],
    "title": [
      "Learning Cross-Modality Encoder Representations from Transformers\"** by Hao Tan and Mohit Bansal",
      "- A model that learns joint representations of image and text data"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "8."
    ],
    "title": [
      "**\"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\"** by Jiasen Lu et al",
      "- Discusses a model that extends BERT to handle visual and linguistic data"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "9."
    ],
    "title": [
      "**\"Multimodal Transformers: A Survey\"** by Zhun Liu et al",
      "- A survey focusing on the use of transformers in multimodal learning"
    ],
    "date": [
      "2022"
    ],
    "type": null
  },
  {
    "citation-number": [
      "10."
    ],
    "title": [
      "**\"Align before Fuse: Vision and Language Representation Learning with Momentum Distillation\"** by Jianwei Yang et al",
      "- Proposes a method for aligning and fusing visual and textual data"
    ],
    "date": [
      "2022"
    ],
    "type": null
  },
  {
    "citation-number": [
      "11."
    ],
    "title": [
      "**\"Unsupervised Learning of Visual Features by Contrasting Cluster Assignments\"** by Mathilde Caron et al",
      "- Discusses a method for learning visual features that can be extended to multimodal settings"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "citation-number": [
      "12."
    ],
    "title": [
      "**\"Multimodal Neurons in Artificial Neural Networks\"** by Gabriel Goh et al",
      "- Explores the emergence of multimodal neurons in large-scale neural networks"
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "citation-number": [
      "13."
    ],
    "title": [
      "**\"Self-Supervised Learning of Audio-Visual Objects from Video\"** by Andrew Owens and",
      "- A study on learning audio-visual object representations without supervision"
    ],
    "author": [
      {
        "family": "Efros",
        "given": "Alexei A."
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "citation-number": [
      "14."
    ],
    "title": [
      "**\"Multimodal Few-Shot Learning with Frozen Language Models\"** by Maria Tsimpoukelli et al",
      "- Investigates few-shot learning using language models for multimodal tasks"
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "citation-number": [
      "15."
    ],
    "title": [
      "**\"ImageBERT: Cross-modal Pre-training with Large-scale Weak-supervised Image-Text Data\"** by Yu Du et al"
    ],
    "date": [
      "2020"
    ],
    "note": [
      "- Introduces a model pre-trained on large-scale image-text data."
    ],
    "type": null
  },
  {
    "citation-number": [
      "16."
    ],
    "title": [
      "**\"VideoBERT: A Joint Model for Video and Language Representation Learning\"** by Chen Sun et al",
      "- Proposes a model for joint video and language representation learning"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "17."
    ],
    "title": [
      "**\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\"** by Zhen Zhu et al",
      "- A survey on multimodal intelligence covering representation learning and fusion techniques"
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "citation-number": [
      "18."
    ],
    "title": [
      "**\"Learning Multimodal Representations for the AI2D Diagram Dataset\"** by Kembhavi et al",
      "- Discusses learning representations from diagrams, integrating visual and textual information"
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "citation-number": [
      "19."
    ],
    "title": [
      "**\"Multimodal Machine Learning: A Survey and Benchmark\"** by Paul Pu Liang et al",
      "- Provides a survey and benchmark for multimodal machine learning methods"
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "citation-number": [
      "20."
    ],
    "title": [
      "**\"Self-Supervised Learning of Multimodal Representations with Cross-Modal Transformers\"** by Yuwei Fang et al",
      "- Explores self-supervised learning using cross-modal transformers"
    ],
    "date": [
      "2022"
    ],
    "type": null
  },
  {
    "title": [
      "These articles provide a broad overview of the field, covering foundational concepts, recent advancements, and applications in multimodal machine learning"
    ],
    "type": null
  }
]
