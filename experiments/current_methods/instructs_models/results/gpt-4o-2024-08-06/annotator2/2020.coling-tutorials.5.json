[
  {
    "title": [
      "Creating a reading list of articles that discuss benchmarking datasets in question answering (QA), natural language inference (NLI), and commonsense reasoning, particularly focusing on the problems of these datasets, is a great way to delve into the challenges and limitations of these fields"
    ],
    "note": [
      "Here’s a list of 20 articles up to 2020 that you might find useful:"
    ],
    "type": null
  },
  {
    "citation-number": [
      "1."
    ],
    "title": [
      "**\"SQuAD: 100,000+ Questions for Machine Comprehension of Text\"** by Rajpurkar et al"
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the Stanford Question Answering Dataset (SQuAD) and its limitations"
    ],
    "type": null
  },
  {
    "citation-number": [
      "2."
    ],
    "title": [
      "**\"The Stanford Question Answering Dataset\"** by Rajpurkar et al"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "An extended discussion on SQuAD and its challenges"
    ],
    "type": null
  },
  {
    "citation-number": [
      "3."
    ],
    "title": [
      "**\"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding\"** by Wang et al"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces the GLUE benchmark and discusses its limitations"
    ],
    "type": null
  },
  {
    "citation-number": [
      "4."
    ],
    "title": [
      "**\"SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems\"** by Wang et al"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the SuperGLUE benchmark and its challenges"
    ],
    "type": null
  },
  {
    "citation-number": [
      "5."
    ],
    "title": [
      "**\"Adversarial Examples for Evaluating Reading Comprehension Systems\"** by Jia and Liang"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Explores adversarial examples in QA datasets"
    ],
    "type": null
  },
  {
    "citation-number": [
      "6."
    ],
    "title": [
      "**\"SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference\"** by Zellers et al"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the SWAG dataset and its limitations"
    ],
    "type": null
  },
  {
    "citation-number": [
      "7."
    ],
    "title": [
      "**\"CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge\"** by Talmor et al"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces CommonsenseQA and discusses its challenges"
    ],
    "type": null
  },
  {
    "citation-number": [
      "8."
    ],
    "title": [
      "**\"QuAC: Question Answering in Context\"** by Choi et al"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the QuAC dataset and its limitations"
    ],
    "type": null
  },
  {
    "citation-number": [
      "9."
    ],
    "title": [
      "**\"Natural Questions: A Benchmark for Question Answering Research\"** by Kwiatkowski et al"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces the Natural Questions dataset and its challenges"
    ],
    "type": null
  },
  {
    "citation-number": [
      "10."
    ],
    "title": [
      "**\"MultiNLI: The Stanford Natural Language Inference Corpus\"** by Williams et al"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the MultiNLI dataset and its limitations"
    ],
    "type": null
  },
  {
    "citation-number": [
      "11."
    ],
    "author": [
      {
        "given": "R.A.C.E."
      }
    ],
    "title": [
      "Large-scale ReAding Comprehension Dataset From Examinations\"** by Lai et al"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the RACE dataset and its challenges"
    ],
    "type": null
  },
  {
    "citation-number": [
      "12."
    ],
    "title": [
      "**\"DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs\"** by Dua et al"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces the DROP dataset and discusses its limitations"
    ],
    "type": null
  },
  {
    "citation-number": [
      "13."
    ],
    "author": [
      {
        "given": "BoolQ"
      }
    ],
    "title": [
      "Exploring the Surprising Difficulty of Natural Yes/No Questions\"** by Clark et al"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the BoolQ dataset and its challenges"
    ],
    "type": null
  },
  {
    "citation-number": [
      "14."
    ],
    "title": [
      "**\"The Story Cloze Test: A New Benchmark for Story Understanding\"** by Mostafazadeh et al"
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the Story Cloze Test and its limitations"
    ],
    "type": null
  },
  {
    "citation-number": [
      "15."
    ],
    "title": [
      "**\"Probing Neural Network Comprehension of Natural Language Arguments\"** by Glockner et al"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Explores the limitations of NLI datasets"
    ],
    "type": null
  },
  {
    "citation-number": [
      "16."
    ],
    "title": [
      "**\"On the Limitations of Unsupervised Bilingual Dictionary Induction\"** by Søgaard et al"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses challenges in cross-lingual datasets"
    ],
    "type": null
  },
  {
    "citation-number": [
      "17."
    ],
    "title": [
      "**\"Beyond Accuracy: Behavioral Testing of NLP Models with CheckList\"** by Ribeiro et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the limitations of current NLP benchmarks"
    ],
    "type": null
  },
  {
    "citation-number": [
      "18."
    ],
    "title": [
      "**\"ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning\"** by Yu et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces ReClor and discusses its challenges"
    ],
    "type": null
  },
  {
    "citation-number": [
      "19."
    ],
    "title": [
      "**\"The Pile: An 800GB Dataset of Diverse Text for Language Modeling\"** by Gao et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the Pile dataset and its limitations"
    ],
    "type": null
  },
  {
    "citation-number": [
      "20."
    ],
    "title": [
      "**\"Adversarial NLI: A New Benchmark for Natural Language Understanding\"** by Nie et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces the Adversarial NLI dataset and discusses its challenges"
    ],
    "type": null
  },
  {
    "title": [
      "These articles provide a comprehensive overview of the datasets used in QA, NLI, and commonsense reasoning, along with a critical analysis of their limitations and challenges"
    ],
    "type": null
  }
]
