[
  {
    "title": [
      "Creating a reading list of 20 articles on retrieval-based language models, including reviews on retrieval systems and language models, involves selecting a mix of foundational papers, recent advancements, and comprehensive reviews. Hereâ€™s a curated list that should provide a solid understanding of the field"
    ],
    "type": null
  },
  {
    "citation-number": [
      "1."
    ],
    "title": [
      "**\"Attention is All You Need\"** by Vaswani et al"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "This foundational paper introduces the Transformer model, which is crucial for understanding modern language models"
    ],
    "type": null
  },
  {
    "citation-number": [
      "2."
    ],
    "author": [
      {
        "given": "B.E.R.T."
      }
    ],
    "title": [
      "Pre-training of Deep Bidirectional Transformers for Language Understanding\"** by Devlin et al"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "A seminal paper on BERT, a model that has influenced many retrieval-based systems"
    ],
    "type": null
  },
  {
    "citation-number": [
      "3."
    ],
    "title": [
      "**\"GPT-3: Language Models are Few-Shot Learners\"** by Brown et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the capabilities of large language models and their implications for retrieval tasks"
    ],
    "type": null
  },
  {
    "citation-number": [
      "4."
    ],
    "title": [
      "**\"Dense Passage Retrieval for Open-Domain Question Answering\"** by Karpukhin et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces a dense retrieval approach that has been influential in the field"
    ],
    "type": null
  },
  {
    "citation-number": [
      "5."
    ],
    "author": [
      {
        "given": "R.E.A.L.M."
      }
    ],
    "title": [
      "Retrieval-Augmented Language Model Pre-Training\"** by Guu et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Explores the integration of retrieval mechanisms into language model pre-training"
    ],
    "type": null
  },
  {
    "citation-number": [
      "6."
    ],
    "author": [
      {
        "given": "R.A.G."
      }
    ],
    "title": [
      "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\"** by Lewis et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses a model that combines retrieval with generation for improved performance on knowledge-intensive tasks"
    ],
    "type": null
  },
  {
    "citation-number": [
      "7."
    ],
    "author": [
      {
        "given": "ColBERT"
      }
    ],
    "title": [
      "Efficient and Effective Passage Search via Contextualized Late Interaction over BERT\"** by Khattab and Zaharia"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Proposes an efficient retrieval model that leverages BERT"
    ],
    "type": null
  },
  {
    "citation-number": [
      "8."
    ],
    "title": [
      "**\"A Survey on Contextual Embeddings\"** by Peters et al"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Provides a comprehensive review of contextual embeddings, which are foundational for retrieval-based language models"
    ],
    "type": null
  },
  {
    "citation-number": [
      "9."
    ],
    "title": [
      "**\"Pre-trained Models for Natural Language Processing: A Survey\"** by Qiu et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "A survey that covers various pre-trained models, including those used in retrieval systems"
    ],
    "type": null
  },
  {
    "citation-number": [
      "10."
    ],
    "author": [
      {
        "given": "Anserini"
      }
    ],
    "title": [
      "Enabling the Use of Lucene for Information Retrieval Research\"** by Yang et al"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses Anserini, a toolkit for information retrieval research"
    ],
    "type": null
  },
  {
    "citation-number": [
      "11."
    ],
    "title": [
      "**\"Learning to Retrieve Passages without Supervision\"** by Lee et al"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces an unsupervised approach to passage retrieval"
    ],
    "type": null
  },
  {
    "citation-number": [
      "12."
    ],
    "title": [
      "**\"Beyond Accuracy: Behavioral Testing of NLP Models with CheckList\"** by Ribeiro et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "While not exclusively about retrieval, this paper discusses evaluation methods that are relevant for assessing retrieval-based models"
    ],
    "type": null
  },
  {
    "citation-number": [
      "13."
    ],
    "title": [
      "**\"A Survey on Neural Network-Based Retrieval Models\"** by Mitra and Craswell"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Reviews various neural network approaches to retrieval"
    ],
    "type": null
  },
  {
    "citation-number": [
      "14."
    ],
    "title": [
      "**\"Improving Language Understanding by Generative Pre-Training\"** by Radford et al"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the generative pre-training approach that underpins models like GPT"
    ],
    "type": null
  },
  {
    "citation-number": [
      "15."
    ],
    "title": [
      "**\"T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\"** by Raffel et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Explores a unified approach to NLP tasks, including retrieval"
    ],
    "type": null
  },
  {
    "citation-number": [
      "16."
    ],
    "title": [
      "**\"The Transformer Model in Information Retrieval: A Survey\"** by Lin et al"
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "A survey focused on the application of Transformer models in information retrieval"
    ],
    "type": null
  },
  {
    "citation-number": [
      "17."
    ],
    "title": [
      "**\"Neural Approaches to Conversational AI: Question Answering, Task-Oriented Dialogues, and Social Chatbots\"** by Gao et al"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Reviews neural approaches to conversational AI, including retrieval-based methods"
    ],
    "type": null
  },
  {
    "citation-number": [
      "18."
    ],
    "title": [
      "**\"Efficient Transformers: A Survey\"** by Tay et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses efficient Transformer architectures, relevant for scaling retrieval-based models"
    ],
    "type": null
  },
  {
    "citation-number": [
      "19."
    ],
    "title": [
      "**\"A Survey on Knowledge-Enhanced Pre-trained Language Models\"** by Yao et al"
    ],
    "date": [
      "2022"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Reviews models that integrate external knowledge, a key aspect of retrieval-based systems"
    ],
    "type": null
  },
  {
    "citation-number": [
      "20."
    ],
    "title": [
      "**\"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\"** by Lewis et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Explores the combination of retrieval and generation in language models"
    ],
    "type": null
  },
  {
    "title": [
      "These articles provide a comprehensive overview of retrieval-based language models, covering both theoretical foundations and practical applications"
    ],
    "type": null
  }
]
