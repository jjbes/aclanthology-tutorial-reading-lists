[{"authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "title": "\"LIME: Why Should I Trust You? Explaining Predictions of Any Classifier\"", "year": 2016}, {"authors": ["Scott Lundberg", "Su-In Lee"], "title": "\"Unified framework for interpretable methods with feature interactions\"", "year": 2017}, {"authors": ["Avanti Shrikant", "Yash Goyal", "Soumik Saha", "Aishwarya Agrawal"], "title": "\"Generating Natural Language Explanations for Black-box Deep Learning Models\"", "year": 2020}, {"authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"], "title": "\"Axiomatic Attribution for Deep Networks\"", "year": 2017}, {"authors": ["Daniel W. Howey", "Jason Yoshimura", "Cameron Mcelfresh", "Rebecca Boyer", "Daniel Lindberg"], "title": "\"Explainable AI for Deep NLP: A Medical Case Study\"", "year": 2019}, {"authors": ["Sarthak Jain", "Byron C. Wallace", "Shi Feng"], "title": "\"Attention is not Explanation\"", "year": 2019}, {"authors": ["Sarah Wiegand", "Michael Roth", "Sebastian Ebert"], "title": "\"Assessing the Reliability of Saliency Methods for Neural Networks: Towards Better Saliency Map Evaluation\"", "year": 2020}, {"authors": ["W. Randall Collins", "Judith A. Howard"], "title": "\"Theories of Action, Theories of Causation, and Theories of Explanation\"", "year": 2000}, {"authors": ["Jonathan Pearl"], "title": "\"Causality: Models, Reasoning and Inference\"", "year": 2002}, {"authors": ["Judea Pearl"], "title": "\"The Book of Why: The Science of Cause and Effect\"", "year": 2018}, {"authors": ["David Alvarez-Melis", "Tommi S. Jaakkola"], "title": "\"On the Robustness of Interpretability Methods\"", "year": 2018}, {"authors": ["Yixin Wang", "David Alvarez-Melis", "Tommi S. Jaakkola"], "title": "\"Towards Robust Interpretability with Self-Explaining Neural Networks\"", "year": 2019}, {"authors": ["Guanhua Chen", "Shengjia Zhao", "Ran Tian", "Kun Zhang", "Zizhen Pan"], "title": "\"Generating Contrastive Explanations for Model Interpretability in Text Classification\"", "year": 2021}, {"authors": ["Alon Jacovi", "Yoav Goldberg"], "title": "\"Towards Faithfully Interpretable NLP Systems: Evaluating Factuality and Correctness in Generation\"", "year": 2020}, {"authors": ["Zhengping Zhou", "Hongyun Bao",  "Yan Fang", "Haiguang Wang", "Changsheng Xu"], "title": "\"Evaluating Explainability for Natural Language Processing Tasks: A Taxonomy, Survey, and Empirical Study\"", "year": 2021}, {"authors": ["Diego Antognini", "Jasmijn van der Waa", "Mark Weele"], "title": "\"Information Theoretic Feature Selection for Text Classification Using the Class Discriminate Function\"", "year": 2012}, {"authors": ["Marina Ermon", "Yixin Wang", "D. Kale"], "title": "\"The Challenges of Crafting Evaluation Metrics for Interpretability\"", "year": 2019}, {"authors": ["Forough Poursabari", "Li Xiong", "Quan Tran"], "title": "\"Causality-based Text Summarization\"", "year": 2020}, {"authors": ["Xisen Jin", "Zhongyu Wei", "Junyi Du", "Yan Wang", "Dan Goldwasser"], "title": "\"Towards Faithfully Explaining Graph Neural Networks in Natural Language\"", "year": 2021}, {"authors": ["Hanxiao Tan", "Ben Krause", "Josue Degol", "Aidan N. Gomez", "Yarin Gal"], "title": "\"The Limits of Post-Hoc Feature Alignment for Robustness\"", "year": 2020}]
