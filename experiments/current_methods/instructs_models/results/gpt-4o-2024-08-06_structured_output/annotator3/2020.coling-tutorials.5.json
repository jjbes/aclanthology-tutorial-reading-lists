[{"title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text", "authors": ["Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang"], "year": 2016}, {"title": "The Stanford Question Answering Dataset", "authors": ["Pranav Rajpurkar", "Robin Jia", "Percy Liang"], "year": 2018}, {"title": "Natural Questions: A Benchmark for Question Answering Research", "authors": ["Tom Kwiatkowski", "Jennimaria Palomaki", "Olga Pitler", "Michael Collins"], "year": 2019}, {"title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension", "authors": ["Mandar Joshi", "Eunsol Choi", "Daniel Weld", "Luke Zettlemoyer"], "year": 2017}, {"title": "QuAC: Question Answering in Context", "authors": ["Eunsol Choi", "He He", "Mohit Iyyer", "Mark Yatskar", "Yejin Choi", "Percy Liang", "Luke Zettlemoyer"], "year": 2018}, {"title": "MultiNLI: The Stanford Natural Language Inference Corpus", "authors": ["Samuel R. Bowman", "Gabor Angeli", "Christopher Potts", "Christopher D. Manning"], "year": 2015}, {"title": "SNLI: A Corpus for Natural Language Inference", "authors": ["Samuel R. Bowman", "Gabor Angeli", "Christopher Potts", "Christopher D. Manning"], "year": 2015}, {"title": "Adversarial NLI: A New Benchmark for Natural Language Understanding", "authors": ["Yixin Nie", "Adina Williams", "Emily Dinan", "Mohit Bansal", "Jason Weston", "Douwe Kiela"], "year": 2020}, {"title": "CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge", "authors": ["Alon Talmor", "Jonathan Herzig", "Nicholas Lourie", "Jonathan Berant"], "year": 2019}, {"title": "SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference", "authors": ["Rowan Zellers", "Yonatan Bisk", "Roy Schwartz", "Yejin Choi"], "year": 2018}, {"title": "Winograd Schema Challenge: A New Approach to Evaluating AI", "authors": ["Hector J. Levesque", "Ernest Davis", "Leora Morgenstern"], "year": 2012}, {"title": "RACE: Large-scale ReAding Comprehension Dataset From Examinations", "authors": ["Guokun Lai", "Qizhe Xie", "Hanxiao Liu", "Yiming Yang", "Eduard Hovy"], "year": 2017}, {"title": "CoQA: A Conversational Question Answering Challenge", "authors": ["Siva Reddy", "Danqi Chen", "Christopher D. Manning"], "year": 2019}, {"title": "HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering", "authors": ["Zhilin Yang", "Peng Qi", "Saizheng Zhang", "Yoshua Bengio", "William Cohen", "Ruslan Salakhutdinov", "Christopher D. Manning"], "year": 2018}, {"title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions", "authors": ["Christopher Clark", "Mark Yatskar", "Kenton Lee", "Michael Collins"], "year": 2019}, {"title": "Commonsense Reasoning in Natural Language Processing", "authors": ["Ernest Davis", "Gary Marcus"], "year": 2015}, {"title": "OpenBookQA: A New Benchmark for Open Book Question Answering", "authors": ["Todor Mihaylov", "Peter Clark", "Tushar Khot", "Ashish Sabharwal"], "year": 2018}, {"title": "ARC: A Machine Reading Comprehension Dataset for Reasoning Over Science Text", "authors": ["Peter Clark", "Isaac Cowhey", "Oren Etzioni", "Tushar Khot", "Ashish Sabharwal", "Carissa Schoenick", "Oyvind Tafjord"], "year": 2018}, {"title": "DREAM: A Challenge Dataset and Models for Dialogue-Based Reading Comprehension", "authors": ["Guangtao Wang", "Yunfang Wu", "Wei Wu", "Zhoujun Li", "Ming Zhou"], "year": 2019}, {"title": "HellaSwag: Can a Machine Really Finish Your Sentence?", "authors": ["Rowan Zellers", "Ari Holtzman", "Hannah Rashkin", "Yonatan Bisk", "Ali Farhadi", "Yejin Choi"], "year": 2019}]