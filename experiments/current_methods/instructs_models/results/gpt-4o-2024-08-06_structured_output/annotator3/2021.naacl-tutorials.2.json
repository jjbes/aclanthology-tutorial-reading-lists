[{"title": "A Survey on Interpretability of Deep Learning in Natural Language Processing", "authors": ["Jieyu Zhao", "Yichao Zhou", "Zeyu Chen", "Yuxiao Dong", "Jiawei Han"], "year": 2020}, {"title": "Interpretable and Explainable Deep Learning: A Survey for NLP", "authors": ["Qingkai Zeng", "Xiaojun Wan"], "year": 2021}, {"title": "Towards a Rigorous Science of Interpretable Machine Learning", "authors": ["Finale Doshi-Velez", "Been Kim"], "year": 2017}, {"title": "Attention is not Explanation", "authors": ["Sarthak Jain", "Byron C. Wallace"], "year": 2019}, {"title": "Rationalizing Neural Predictions", "authors": ["Tao Lei", "Regina Barzilay", "Tommi Jaakkola"], "year": 2016}, {"title": "A Survey of Methods for Explaining Black Box Models", "authors": ["Riccardo Guidotti", "Anna Monreale", "Salvatore Ruggieri", "Franco Turini", "Fosca Giannotti", "Dino Pedreschi"], "year": 2018}, {"title": "Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI", "authors": ["Arrieta, Alejandro Barredo", "D\u00edaz-Rodr\u00edguez, Natalia", "Del Ser, Javier", "Bennetot, Adrien", "Tabik, Siham", "Barbado, Alberto", "Garcia, Salvador", "Gil-Lopez, Sergio", "Molina, Daniel", "Benjamins, Richard", "Chatila, Raja", "Herrera, Francisco"], "year": 2020}, {"title": "Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)", "authors": ["Been Kim", "Martin Wattenberg", "Justin Gilmer", "Carrie Cai", "James Wexler", "Fernanda Vi\u00e9gas"], "year": 2018}, {"title": "Explaining and Harnessing Adversarial Examples", "authors": ["Ian J. Goodfellow", "Jonathon Shlens", "Christian Szegedy"], "year": 2015}, {"title": "The Building Blocks of Interpretability", "authors": ["Chris Olah", "Arvind Satyanarayan", "Ian Johnson", "Shan Carter", "Ludwig Schubert", "Katherine Ye", "Alexander Mordvintsev"], "year": 2018}, {"title": "Anchors: High-Precision Model-Agnostic Explanations", "authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "year": 2018}, {"title": "LIME: Local Interpretable Model-Agnostic Explanations", "authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "year": 2016}, {"title": "A Unified Approach to Interpreting Model Predictions", "authors": ["Scott M. Lundberg", "Su-In Lee"], "year": 2017}, {"title": "DeepLIFT: Learning Important Features Through Propagating Activation Differences", "authors": ["Avanti Shrikumar", "Peyton Greenside", "Anshul Kundaje"], "year": 2017}, {"title": "Visualizing and Understanding Convolutional Networks", "authors": ["Matthew D. Zeiler", "Rob Fergus"], "year": 2014}, {"title": "The Mythos of Model Interpretability", "authors": ["Zachary C. Lipton"], "year": 2016}, {"title": "Towards Interpretable RNNs: Let Us Sum Up What We Have Learned", "authors": ["Chunyang Xiao", "Peilin Zhao", "Junzhou Huang", "Bo Li"], "year": 2019}, {"title": "A Survey of Methods for Explaining Black Box Models", "authors": ["Riccardo Guidotti", "Anna Monreale", "Salvatore Ruggieri", "Franco Turini", "Fosca Giannotti", "Dino Pedreschi"], "year": 2018}, {"title": "Interpretable Machine Learning: A Guide for Making Black Box Models Explainable", "authors": ["Christoph Molnar"], "year": 2019}, {"title": "The Shapley Value in Machine Learning", "authors": ["Scott M. Lundberg", "Su-In Lee"], "year": 2017}]