[{"title": "Attention is Not Explanation", "authors": ["Sarthak Jain", "Byron C. Wallace"], "year": 2019}, {"title": "Interpretable and Explainable Deep Learning: A Survey", "authors": ["Jie Ren", "Ping Zhang", "Xiaoli Li"], "year": 2019}, {"title": "A Survey of Methods for Explaining Black Box Models", "authors": ["Riccardo Guidotti", "Anna Monreale", "Salvatore Ruggieri", "Franco Turini", "Fosca Giannotti", "Dino Pedreschi"], "year": 2018}, {"title": "Towards a Rigorous Science of Interpretable Machine Learning", "authors": ["Finale Doshi-Velez", "Been Kim"], "year": 2017}, {"title": "Rationalizing Neural Predictions", "authors": ["Tao Lei", "Regina Barzilay", "Tommi Jaakkola"], "year": 2016}, {"title": "Visualizing and Understanding Neural Models in NLP", "authors": ["Kyunghyun Cho", "Bart van Merri\u00ebnboer", "Dzmitry Bahdanau", "Yoshua Bengio"], "year": 2014}, {"title": "The Building Blocks of Interpretability", "authors": ["Chris Olah", "Arvind Satyanarayan", "Ian Johnson", "Shan Carter", "Ludwig Schubert", "Katherine Ye", "Alexander Mordvintsev"], "year": 2018}, {"title": "Interpretable Machine Learning: Definitions, Methods, and Applications", "authors": ["Wojciech Samek", "Thomas Wiegand", "Klaus-Robert M\u00fcller"], "year": 2017}, {"title": "Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)", "authors": ["Been Kim", "Martin Wattenberg", "Justin Gilmer", "Carrie Cai", "James Wexler", "Fernanda Vi\u00e9gas"], "year": 2018}, {"title": "Explaining and Harnessing Adversarial Examples", "authors": ["Ian J. Goodfellow", "Jonathon Shlens", "Christian Szegedy"], "year": 2015}, {"title": "Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps", "authors": ["Karen Simonyan", "Andrea Vedaldi", "Andrew Zisserman"], "year": 2013}, {"title": "Understanding Neural Networks Through Deep Visualization", "authors": ["Jason Yosinski", "Jeff Clune", "Anh Nguyen", "Thomas Fuchs", "Hod Lipson"], "year": 2015}, {"title": "A Unified Approach to Interpreting Model Predictions", "authors": ["Scott M. Lundberg", "Su-In Lee"], "year": 2017}, {"title": "Anchors: High-Precision Model-Agnostic Explanations", "authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "year": 2018}, {"title": "LIME: Local Interpretable Model-Agnostic Explanations", "authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "year": 2016}, {"title": "DeepLIFT: Learning Important Features Through Propagating Activation Differences", "authors": ["Avanti Shrikumar", "Peyton Greenside", "Anshul Kundaje"], "year": 2017}, {"title": "Gradient-Based Attribution Methods", "authors": ["Sebastian Bach", "Alexander Binder", "Gr\u00e9goire Montavon", "Frederick Klauschen", "Klaus-Robert M\u00fcller", "Wojciech Samek"], "year": 2015}, {"title": "The Mythos of Model Interpretability", "authors": ["Zachary C. Lipton"], "year": 2016}, {"title": "Axiomatic Attribution for Deep Networks", "authors": ["David Alvarez-Melis", "Tommi S. Jaakkola"], "year": 2017}, {"title": "Explaining Explanations: An Overview of Interpretability of Machine Learning", "authors": ["David Gunning"], "year": 2017}]