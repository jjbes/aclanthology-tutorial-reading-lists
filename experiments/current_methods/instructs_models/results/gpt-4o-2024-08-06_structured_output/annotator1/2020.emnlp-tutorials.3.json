[{"title": "A Survey of Methods for Explaining Black Box Models", "authors": ["Riccardo Guidotti", "Anna Monreale", "Salvatore Ruggieri", "Franco Turini", "Fosca Giannotti", "Dino Pedreschi"], "year": 2018}, {"title": "Interpretable Machine Learning: A Guide for Making Black Box Models Explainable", "authors": ["Christoph Molnar"], "year": 2019}, {"title": "LIME: Local Interpretable Model-Agnostic Explanations", "authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "year": 2016}, {"title": "DeepLIFT: Learning Important Features Through Propagating Activation Differences", "authors": ["Avanti Shrikumar", "Peyton Greenside", "Anshul Kundaje"], "year": 2017}, {"title": "SHAP: Shapley Additive Explanations", "authors": ["Scott M. Lundberg", "Su-In Lee"], "year": 2017}, {"title": "Anchors: High-Precision Model-Agnostic Explanations", "authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "year": 2018}, {"title": "The Building Blocks of Interpretability", "authors": ["Chris Olah", "Arvind Satyanarayan", "Ian Johnson", "Shan Carter", "Ludwig Schubert", "Katherine Ye", "Alexander Mordvintsev"], "year": 2018}, {"title": "Axiomatic Attribution for Deep Networks", "authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"], "year": 2017}, {"title": "Visualizing and Understanding Convolutional Networks", "authors": ["Matthew D. Zeiler", "Rob Fergus"], "year": 2014}, {"title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization", "authors": ["Ramprasaath R. Selvaraju", "Abhishek Das", "Ramya Vedantam", "Michael Cogswell", "Devi Parikh", "Dhruv Batra"], "year": 2017}, {"title": "Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps", "authors": ["Karen Simonyan", "Andrea Vedaldi", "Andrew Zisserman"], "year": 2014}, {"title": "Understanding Neural Networks Through Deep Visualization", "authors": ["Jason Yosinski", "Jeff Clune", "Anh Nguyen", "Thomas Fuchs", "Hod Lipson"], "year": 2015}, {"title": "Feature Visualization", "authors": ["Chris Olah", "Alexander Mordvintsev", "Ludwig Schubert"], "year": 2017}, {"title": "Explaining Explanations: An Overview of Interpretability of Machine Learning", "authors": ["Finale Doshi-Velez", "Been Kim"], "year": 2017}, {"title": "Towards a Rigorous Science of Interpretable Machine Learning", "authors": ["Cynthia Rudin"], "year": 2019}, {"title": "The Mythos of Model Interpretability", "authors": ["Zachary C. Lipton"], "year": 2016}, {"title": "Interpretability is Harder in the Multiclass Setting: A Case Study in Neural Natural Language Inference", "authors": ["Jasmijn Bastings", "Wilker Aziz", "Ivan Titov"], "year": 2019}, {"title": "Understanding Black-box Predictions via Influence Functions", "authors": ["Pang Wei Koh", "Percy Liang"], "year": 2017}, {"title": "Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR", "authors": ["Sandra Wachter", "Brent Mittelstadt", "Chris Russell"], "year": 2017}, {"title": "The Tree of Thoughts: Understanding Neural Network Decisions with Integrated Gradients", "authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"], "year": 2017}]