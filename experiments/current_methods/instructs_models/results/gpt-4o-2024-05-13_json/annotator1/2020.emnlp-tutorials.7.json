[{"title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"], "year": 2019}, {"title": "GPT-2: Better Language Models and Their Implications", "authors": ["Alec Radford", "Jeffrey Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever"], "year": 2019}, {"title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding", "authors": ["Zhilin Yang", "Zihang Dai", "Yiming Yang", "Jaime Carbonell", "Ruslan Salakhutdinov", "Quoc V. Le"], "year": 2019}, {"title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "authors": ["Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov"], "year": 2019}, {"title": "T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "authors": ["Colin Raffel", "Noam Shazeer", "Adam Roberts", "Katherine Lee", "Sharan Narang", "Michael Matena", "Yanqi Zhou", "Wei Li", "Peter J. Liu"], "year": 2020}, {"title": "ERNIE: Enhanced Representation through Knowledge Integration", "authors": ["Yu Sun", "Shuohuan Wang", "Yukun Li", "Shikun Feng", "Hao Tian", "Hua Wu", "Haifeng Wang"], "year": 2019}, {"title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations", "authors": ["Zhenzhong Lan", "Mingda Chen", "Sebastian Goodman", "Kevin Gimpel", "Piyush Sharma", "Radu Soricut"], "year": 2020}, {"title": "ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators", "authors": ["Kevin Clark", "Minh-Thang Luong", "Quoc V. Le", "Christopher D. Manning"], "year": 2020}, {"title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter", "authors": ["Victor Sanh", "Lysandre Debut", "Julien Chaumond", "Thomas Wolf"], "year": 2019}, {"title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans", "authors": ["Mandar Joshi", "Danqi Chen", "Yinhan Liu", "Daniel S. Weld", "Luke Zettlemoyer", "Omer Levy"], "year": 2020}, {"title": "CTRL: A Conditional Transformer Language Model for Controllable Generation", "authors": ["Nitish Shirish Keskar", "Bryan McCann", "Lav R. Varshney", "Caiming Xiong", "Richard Socher"], "year": 2019}, {"title": "UniLM: Unified Language Model Pre-training for Natural Language Understanding and Generation", "authors": ["Li Dong", "Nan Yang", "Wenhui Wang", "Furu Wei", "Xiaodong Liu", "Yu Wang", "Jianfeng Gao", "Ming Zhou", "Hsiao-Wuen Hon"], "year": 2019}, {"title": "mBERT: Multilingual BERT using Monolingual Corpora", "authors": ["Wenhui Wang", "Furu Wei", "Li Dong", "Hangbo Bao", "Nan Yang", "Ming Zhou"], "year": 2019}, {"title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding", "authors": ["Zhilin Yang", "Zihang Dai", "Yiming Yang", "Jaime Carbonell", "Russ R. Salakhutdinov", "Quoc V. Le"], "year": 2019}, {"title": "OpenAI GPT: Improving Language Understanding by Generative Pre-Training", "authors": ["Alec Radford", "Karthik Narasimhan", "Tim Salimans", "Ilya Sutskever"], "year": 2018}, {"title": "Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context", "authors": ["Zihang Dai", "Zhilin Yang", "Yiming Yang", "Jaime Carbonell", "Quoc V. Le", "Ruslan Salakhutdinov"], "year": 2019}, {"title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension", "authors": ["Mike Lewis", "Yinhan Liu", "Naman Goyal", "Marjan Ghazvininejad", "Abdelrahman Mohamed", "Omer Levy", "Veselin Stoyanov", "Luke Zettlemoyer"], "year": 2020}, {"title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization", "authors": ["Jingqing Zhang", "Yao Zhao", "Mohammad Saleh", "Peter J. Liu"], "year": 2020}, {"title": "Turing-NLG: A 17-billion-parameter language model by Microsoft", "authors": ["Chenguang Zhu", "Michael Zeng", "Xuedong Huang"], "year": 2020}, {"title": "ERNIE 2.0: A Continual Pre-training Framework for Language Understanding", "authors": ["Yu Sun", "Shuohuan Wang", "Yukun Li", "Shikun Feng", "Hao Tian", "Hua Wu", "Haifeng Wang"], "year": 2020}]