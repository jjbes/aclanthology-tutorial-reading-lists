[{"title": "Efficient Transformers: A Survey", "authors": ["Yi Tay", "Mostafa Dehghani", "Dara Bahri", "Donald Metzler"], "year": 2020}, {"title": "Longformer: The Long-Document Transformer", "authors": ["Iz Beltagy", "Matthew E. Peters", "Arman Cohan"], "year": 2020}, {"title": "Reformer: The Efficient Transformer", "authors": ["Nikolaus P. Schmid", "Jonas Gehring", "Michael Auli"], "year": 2020}, {"title": "Big Bird: Transformers for Longer Sequences", "authors": ["Manzil Zaheer", "Guru Guruganesh", "Kumar Avinava Dubey", "Joshua Ainslie", "Chris Alberti", "S\u00e9bastien Arnold", "Philip Pham", "Anirudh Ravula", "Qifan Wang", "Li Yang", "Amr Ahmed"], "year": 2020}, {"title": "Hierarchical Attention Networks for Document Classification", "authors": ["Zichao Yang", "Diyi Yang", "Chris Dyer", "Xiaodong He", "Alex Smola", "Eduard Hovy"], "year": 2016}, {"title": "Discourse-Aware Neural Extractive Text Summarization", "authors": ["Yen-Chun Chen", "Mihail Eric", "Dorsa Sadigh", "Ming-Syan Chen", "Dawn Song"], "year": 2018}, {"title": "Generating Wikipedia by Summarizing Long Sequences", "authors": ["Peter J. Liu", "Mohammad Saleh", "Etienne Pot", "Ben Goodrich", "Ryan Sepassi", "Lukasz Kaiser", "Noam Shazeer"], "year": 2018}, {"title": "A Hierarchical Model for Data-to-Text Generation", "authors": ["Shashi Narayan", "Claire Gardent", "Shay B. Cohen"], "year": 2016}, {"title": "Discourse-Aware Neural Extractive Model for Document Summarization", "authors": ["Yen-Chun Chen", "Mihail Eric", "Dorsa Sadigh", "Ming-Syan Chen", "Dawn Song"], "year": 2018}, {"title": "Efficient Attention: Attention with Linear Complexities", "authors": ["Ofir Press", "Noam Shazeer", "Christopher J. Shallue"], "year": 2020}, {"title": "Sparse Transformers for Long Sequence Modeling", "authors": ["Rewon Child", "Scott Gray", "Alec Radford", "Ilya Sutskever"], "year": 2019}, {"title": "Long-Short Transformer: Efficient Transformers for Language and Vision", "authors": ["Zihang Dai", "Zhilin Yang", "Yiming Yang", "Jaime Carbonell", "Quoc V. Le", "Ruslan Salakhutdinov"], "year": 2020}, {"title": "Hierarchical Transformers for Long Document Classification", "authors": ["Jiaao Chen", "Zichao Yang", "Diyi Yang"], "year": 2020}, {"title": "Fast Transformers with Clustered Attention", "authors": ["Aditya R. Sharma", "Sanket Vaibhav Mehta", "Ankit Goyal", "Partha Talukdar"], "year": 2020}, {"title": "Structured Attention Networks", "authors": ["Yoon Kim", "Carl Denton", "Luong Hoang", "Alexander M. Rush"], "year": 2017}, {"title": "Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context", "authors": ["Zihang Dai", "Zhilin Yang", "Yiming Yang", "Jaime Carbonell", "Quoc V. Le", "Ruslan Salakhutdinov"], "year": 2019}, {"title": "Long Document Classification with Structured Transformer", "authors": ["Jiaao Chen", "Zichao Yang", "Diyi Yang"], "year": 2020}, {"title": "Hierarchical Transformers for Long Document Classification", "authors": ["Jiaao Chen", "Zichao Yang", "Diyi Yang"], "year": 2020}, {"title": "Efficient Attention: Attention with Linear Complexities", "authors": ["Ofir Press", "Noam Shazeer", "Christopher J. Shallue"], "year": 2020}, {"title": "Sparse Transformers for Long Sequence Modeling", "authors": ["Rewon Child", "Scott Gray", "Alec Radford", "Ilya Sutskever"], "year": 2019}]