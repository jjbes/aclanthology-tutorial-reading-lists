[{"title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text", "authors": ["Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang"], "year": 2016}, {"title": "The Stanford Question Answering Dataset", "authors": ["Pranav Rajpurkar", "Robin Jia", "Percy Liang"], "year": 2018}, {"title": "Natural Questions: A Benchmark for Question Answering Research", "authors": ["Tom Kwiatkowski", "Jennimaria Palomaki", "Olutobi Owoputi", "Michael Collins", "Ankur Parikh", "Chris Alberti", "Dan Garrette", "Patrick Kelcey", "Kuzman Ganchev", "Neville Stoyanov", "Luke Zettlemoyer"], "year": 2019}, {"title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding", "authors": ["Alex Wang", "Amanpreet Singh", "Julian Michael", "Felix Hill", "Omer Levy", "Samuel R. Bowman"], "year": 2018}, {"title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems", "authors": ["Alex Wang", "Yada Pruksachatkun", "Nikita Nangia", "Amanpreet Singh", "Julian Michael", "Felix Hill", "Omer Levy", "Samuel R. Bowman"], "year": 2019}, {"title": "CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge", "authors": ["Alon Talmor", "Jonathan Herzig", "Nicholas Lourie", "Jonathan Berant"], "year": 2019}, {"title": "SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference", "authors": ["Rowan Zellers", "Yonatan Bisk", "Roy Schwartz", "Yejin Choi"], "year": 2018}, {"title": "RACE: Large-scale ReAding Comprehension Dataset From Examinations", "authors": ["Guokun Lai", "Qizhe Xie", "Hanxiao Liu", "Yiming Yang", "Eduard Hovy"], "year": 2017}, {"title": "MultiNLI: The Stanford Natural Language Inference Corpus", "authors": ["Samuel R. Bowman", "Gabor Angeli", "Christopher Potts", "Christopher D. Manning"], "year": 2015}, {"title": "Adversarial NLI: A New Benchmark for Natural Language Understanding", "authors": ["Yixin Nie", "Adina Williams", "Emily Dinan", "Mohit Bansal", "Jason Weston", "Douwe Kiela"], "year": 2020}, {"title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling", "authors": ["Leo Gao", "Stella Biderman", "Sid Black", "Laurence Golding", "Travis Hoppe", "Charles Foster", "Jason Phang", "Horace He", "Anish Thite", "Noa Nabeshima", "Shawn Presser", "Connor Leahy"], "year": 2020}, {"title": "HellaSwag: Can a Machine Really Finish Your Sentence?", "authors": ["Rowan Zellers", "Ari Holtzman", "Yonatan Bisk", "Ali Farhadi", "Yejin Choi"], "year": 2019}, {"title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions", "authors": ["Christopher Clark", "Mark Yatskar", "Kenton Lee", "Michael Collins"], "year": 2019}, {"title": "DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs", "authors": ["Dheeru Dua", "Yizhong Wang", "Pradeep Dasigi", "Gabriel Stanovsky", "Sameer Singh", "Matt Gardner"], "year": 2019}, {"title": "QuAC: Question Answering in Context", "authors": ["Eunsol Choi", "He He", "Mohit Iyyer", "Mark Yatskar", "Yejin Choi", "Percy Liang", "Luke Zettlemoyer"], "year": 2018}, {"title": "HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering", "authors": ["Zhenzhong Chen", "Wenhan Xiong", "Hong Wang", "William Yang Wang"], "year": 2018}, {"title": "Cosmos QA: Machine Reading Comprehension with Contextual Commonsense Reasoning", "authors": ["Heng Ji", "Rui Zhang", "Yuan Zhang", "Ming Zhang", "Jiawei Han"], "year": 2019}, {"title": "OpenBookQA: A Book of Challenges on Commonsense Reasoning", "authors": ["Todor Mihaylov", "Peter Clark", "Tushar Khot", "Ashish Sabharwal"], "year": 2018}, {"title": "SocialIQA: Commonsense Reasoning about Social Interactions", "authors": ["Maarten Sap", "Hannah Rashkin", "Derek Chen", "Ronan LeBras", "Yejin Choi"], "year": 2019}, {"title": "ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning", "authors": ["Yichong Xu", "Hongming Zhang", "Yue Zhang", "Zhiyuan Liu", "Maosong Sun"], "year": 2020}]