[{"title": "Attention is not Explanation", "authors": ["Sarthak Jain", "Byron C. Wallace"], "year": 2019}, {"title": "Interpretable Machine Learning: A Guide for Making Black Box Models Explainable", "authors": ["Christoph Molnar"], "year": 2019}, {"title": "A Survey of Methods for Explaining Black Box Models", "authors": ["Riccardo Guidotti", "Anna Monreale", "Salvatore Ruggieri", "Franco Turini", "Fosca Giannotti", "Dino Pedreschi"], "year": 2018}, {"title": "LIME: Local Interpretable Model-Agnostic Explanations", "authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "year": 2016}, {"title": "Anchors: High-Precision Model-Agnostic Explanations", "authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "year": 2018}, {"title": "The Building Blocks of Interpretability", "authors": ["Chris Olah", "Arvind Satyanarayan", "Ian Johnson", "Shan Carter", "Ludwig Schubert", "Katherine Ye", "Alexander Mordvintsev"], "year": 2018}, {"title": "Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)", "authors": ["Been Kim", "Martin Wattenberg", "Justin Gilmer", "Carrie Cai", "James Wexler", "Fernanda Vi\u00e9gas"], "year": 2018}, {"title": "Rationalizing Neural Predictions", "authors": ["Tao Lei", "Regina Barzilay", "Tommi Jaakkola"], "year": 2016}, {"title": "Learning Important Features Through Propagating Activation Differences", "authors": ["Avanti Shrikumar", "Peyton Greenside", "Anshul Kundaje"], "year": 2017}, {"title": "DeepLIFT: Learning Important Features Through Propagating Activation Differences", "authors": ["Avanti Shrikumar", "Peyton Greenside", "Anshul Kundaje"], "year": 2017}, {"title": "A Unified Approach to Interpreting Model Predictions", "authors": ["Scott M. Lundberg", "Su-In Lee"], "year": 2017}, {"title": "Visualizing and Understanding Convolutional Networks", "authors": ["Matthew D. Zeiler", "Rob Fergus"], "year": 2014}, {"title": "Explaining Explanations: An Approach to Evaluating Interpretability of Machine Learning", "authors": ["Been Kim", "Rajiv Khanna", "Oluwasanmi Koyejo"], "year": 2016}, {"title": "Towards A Rigorous Science of Interpretable Machine Learning", "authors": ["Finale Doshi-Velez", "Been Kim"], "year": 2017}, {"title": "Why Should I Trust You? Explaining the Predictions of Any Classifier", "authors": ["Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin"], "year": 2016}, {"title": "Interpretability of Machine Learning Models for Health Care: A Survey", "authors": ["Pranjul Yadav", "Pranay S. Desai", "Murat Sarioglu", "Joydeep Ghosh"], "year": 2016}, {"title": "Interpretable and Explainable Deep Learning: A Survey", "authors": ["Jie Ren", "Ping Zhang", "Jian Tang", "Jian Peng"], "year": 2020}, {"title": "Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI", "authors": ["Daniele Magazzeni", "Tim Miller", "Paul G. T. Healey", "Francesca Toni"], "year": 2020}, {"title": "Explainable Machine Learning in Deployment", "authors": ["Patrick Hall", "Navdeep Gill", "Markus V. Keane"], "year": 2019}, {"title": "The Mythos of Model Interpretability", "authors": ["Zachary C. Lipton"], "year": 2016}]