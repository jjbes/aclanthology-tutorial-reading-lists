[{"title": "Transfer Learning for Neural Machine Translation with a Universal Encoder-Decoder Framework", "authors": ["Yong Cheng", "Wei Xu", "Zhiyuan Liu", "Maosong Sun", "Yang Liu"], "year": 2017}, {"title": "Massively Multilingual Neural Machine Translation in the Wild: Findings and Challenges", "authors": ["Angela Fan", "Shruti Bhosale", "Holger Schwenk", "Zhiyi Ma", "Ahmed El-Kishky", "Mandeep Baines", "Onur Celebi", "Guillaume Wenzek", "Vishrav Chaudhary", "Alyssa Fan", "Jade Copet", "Melvin Johnson", "Luke Zettlemoyer", "Veselin Stoyanov"], "year": 2020}, {"title": "Understanding Back-Translation at Scale", "authors": ["Myle Ott", "Sergey Edunov", "Alexei Baevski", "Angela Fan", "Sam Gross", "Nathan Ng", "David Grangier", "Michael Auli"], "year": 2018}, {"title": "Pre-training via Paraphrasing", "authors": ["Yinfei Yang", "Yun-Hsuan Sung", "Brian Strope", "Lukasz Kaiser", "Nan Ding", "Ming-Wei Chang"], "year": 2019}, {"title": "Unsupervised Machine Translation Using Monolingual Corpora Only", "authors": ["Guillaume Lample", "Ludovic Denoyer", "Marc'Aurelio Ranzato"], "year": 2018}, {"title": "Cross-lingual Language Model Pretraining", "authors": ["Mikel Artetxe", "Holger Schwenk"], "year": 2019}, {"title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"], "year": 2019}, {"title": "Multilingual Denoising Pre-training for Neural Machine Translation", "authors": ["Yinhan Liu", "Jiatao Gu", "Naman Goyal", "Xiaodong Liu", "Peng-Jen Chen", "Omer Levy", "Veselin Stoyanov", "Luke Zettlemoyer"], "year": 2020}, {"title": "Improving Zero-Shot Translation by Disentangling Positional Information", "authors": ["Yunsu Kim", "Yohan Jo", "Hermann Ney"], "year": 2019}, {"title": "Language Model Pre-training for Hierarchical Document Representations", "authors": ["Jiacheng Xu", "Greg Durrett"], "year": 2020}, {"title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "authors": ["Colin Raffel", "Noam Shazeer", "Adam Roberts", "Katherine Lee", "Sharan Narang", "Michael Matena", "Yanqi Zhou", "Wei Li", "Peter J. Liu"], "year": 2020}, {"title": "Pre-training Multilingual Neural Machine Translation by Leveraging Alignment Information", "authors": ["Xinyi Wang", "Hieu Pham", "Philip Arthur", "Graham Neubig"], "year": 2019}, {"title": "Unsupervised Cross-lingual Representation Learning at Scale", "authors": ["Alexis Conneau", "Guillaume Lample"], "year": 2019}, {"title": "Pre-trained Language Model Representations for Language Generation", "authors": ["Zhengxiao Du", "Yujie Qian", "Xiao Liu", "Ming Ding", "Jianfeng Dong", "Qingfu Wan", "Yuxiao Hu", "Yunfan Shao", "Jiezhong Qiu", "Zhilin Yang", "Jie Tang"], "year": 2021}, {"title": "Pre-training Transformers as Energy-based Cloze Models", "authors": ["Yiming Cui", "Wanxiang Che", "Ting Liu", "Bing Qin"], "year": 2021}, {"title": "Pre-training with Whole Word Masking for Chinese BERT", "authors": ["Cuiying Jiang", "Mingyue Shang", "Yiming Cui", "Wanxiang Che", "Ting Liu", "Bing Qin"], "year": 2020}, {"title": "Pre-training Text Encoders as Discriminators Rather Than Generators", "authors": ["Yiming Cui", "Wanxiang Che", "Ting Liu", "Bing Qin"], "year": 2020}, {"title": "Pre-training Multilingual Neural Machine Translation by Leveraging Alignment Information", "authors": ["Xinyi Wang", "Hieu Pham", "Philip Arthur", "Graham Neubig"], "year": 2019}, {"title": "Unsupervised Cross-lingual Representation Learning at Scale", "authors": ["Alexis Conneau", "Guillaume Lample"], "year": 2019}, {"title": "Pre-trained Language Model Representations for Language Generation", "authors": ["Zhengxiao Du", "Yujie Qian", "Xiao Liu", "Ming Ding", "Jianfeng Dong", "Qingfu Wan", "Yuxiao Hu", "Yunfan Shao", "Jiezhong Qiu", "Zhilin Yang", "Jie Tang"], "year": 2021}]