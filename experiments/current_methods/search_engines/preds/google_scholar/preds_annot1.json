{"C16-3001": [], "2020.acl-tutorials.1": [{"id": "f0d6db2186d8bf2d8530f01de6c6518bb9711392", "title": "Interpretability and analysis in neural NLP", "year": "2020"}, {"id": "e2bee23ac912cf36f0479b830ff78d4bb6cc73c3", "title": "Analyzing and interpreting neural networks for NLP: A report on the first BlackboxNLP workshop", "year": "2019"}, {"id": "fafa541419b3756968fe5b3156c6f0257cb29c23", "title": "Visualizing and understanding neural models in NLP", "year": "2015"}, {"id": "56edaa1368ff4dfa45388e4be24fdfbded7d88a7", "title": "A primer on neural network models for natural language processing", "year": "2016"}, {"id": "ec4ba9b4743b7092205d967300032191f02f7c14", "title": "Proceedings of the 2018 EMNLP workshop BlackboxNLP: Analyzing and interpreting neural networks for NLP", "year": "2018"}, {"id": "97f713a5c64a801c003ee943e4abe855473495e9", "title": "Twitter sentiment analysis with a deep neural network: An enhanced approach using user behavioral information", "year": "2019"}, {"id": "3410e91c55ec78e4ec94b6a56897945e136d7cd8", "title": "Progress in neural NLP: modeling, learning, and reasoning", "year": "2020"}, {"id": "844edcb9961c4b00f5df9a3fa1935905e5f8a2ad", "title": "Illuminating the black box: interpreting deep neural network models for psychiatric research", "year": "2020"}, {"id": "f22ac2e3e45debb13d635fddaccfff7e997e7db9", "title": "Explaining recurrent neural network predictions in sentiment analysis", "year": "2017"}, {"id": "4c41104e871bccbd56494350a71d77a7f1da5bb0", "title": "Understanding neural networks through representation erasure", "year": "2016"}, {"id": "80e34f2b7f816113130c536dddd8aa980c95dfd2", "title": "Interpreting predictions of NLP models", "year": "2020"}, {"id": "a99c491cde6e5c45aa8fe7c388b0e18c93ff1801", "title": "Interpretable neural models for natural language processing", "year": " Lei"}, {"id": "74e9053d6f44f4507bd40bbea999ee65f0cbefb2", "title": "Pathologies of neural models make interpretations difficult", "year": "2018"}, {"id": "6b3586e43a2b6ac42cfbb23c74863bfbf504732a", "title": "Interpreting deep models for text analysis via optimization and regularization methods", "year": "2019"}, {"id": "ddd27dba038d0ed14c48cd027812df58a902ece2", "title": "AllenNLP interpret: A framework for explaining predictions of NLP models", "year": "2019"}, {"id": "ec6d889a96ec1ef379b388633ddf97e6de9a0ead", "title": "Evaluating neural network explanation methods using hybrid documents and morphological agreement", "year": "2018"}, {"id": "bbd4f99c65d677dc82ac4c051b289626f1e8f435", "title": "To what extent do human explanations of model behavior align with actual model behavior?", "year": "2020"}, {"id": "f447c73de2f5cee843ad14d70e1d373294611934", "title": "Interpreting recurrent and attention-based neural models: a case study on natural language inference", "year": "2018"}, {"id": "8dce62b18bdea587c07cb4769a05ca0a816d09ba", "title": "The language interpretability tool: Extensible, interactive visualizations and analysis for NLP models", "year": "2020"}, {"id": "9c2156bc35c6f8e68aa21d4b2f339134a4d28708", "title": "What is one grain of sand in the desert? analyzing individual neurons in deep nlp models", "year": "2019"}], "2020.acl-tutorials.2": [{"id": "9566afe3f27d7b81417d6b59e5aaedcf75c4079a", "title": "Ethical by design: Ethics best practices for natural language processing", "year": "2017"}, {"id": "1ec1a4275efbe3cb27d792d1a548e5fcc44813a6", "title": "Integrating ethics into the NLP curriculum", "year": "2020"}, {"id": "0ee4aad344e03ba68267199652946d1260b0fd93", "title": "Ethical considerations in NLP shared tasks", "year": "ens\u2026"}, {"id": "c4dba2263bb636c3a0a55e87a445094217c024b4", "title": "Case study: Deontological ethics in NLP", "year": "2020"}, {"id": "5ce29321aaa727cf5daadf73bcd8a7788a894bf7", "title": "Ethics and good practice in computational paralinguistics", "year": "2020"}, {"id": "2cb7cc2adcfd3c7264f79093e73c4daff22d43b7", "title": "Natural language processing accurately measures adherence to best practice guidelines for palliative care in trauma", "year": "2020"}, {"id": "97bfa89addc6e5d76361e4c1e296949cad887b86", "title": "Data statements for natural language processing: Toward mitigating system bias and enabling better science", "year": "2018"}, {"id": "505d655df513d990ab63ad59d7166497e7a03037", "title": "Towards best practices for leveraging human language processing signals for natural language processing", "year": "2020"}, {"id": null, "title": "Towards Efficient Software Engineering in the Era of AI and ML: Best Practices and Challenges", "year": "2019"}, {"id": null, "title": "Bridging the gap between ethics and practice: guidelines for reliable, safe, and trustworthy human-centered AI systems", "year": "2020"}, {"id": null, "title": "Advanced analytics: Moving toward AI, machine learning, and natural language processing", "year": "2017"}, {"id": "7d73aab9db1016fc9aa0393be0143be9da694b7f", "title": "Ethics and artificial intelligence: suicide prevention on Facebook", "year": "2018"}, {"id": "65906e6027246ae9e4ecd18d6e019a24505c842e", "title": "Aligning ai with shared human values", "year": "2020"}, {"id": "7f1a013d7f84e7369d78666f14b178f0538acfa3", "title": "Recommendations for the ethical use and design of artificial intelligent care providers", "year": "2014"}, {"id": "d00392eecebee4befa9e45a4d60fcd62f60d1514", "title": "Using deep learning based natural language processing techniques for clinical decision-making with EHRs", "year": "2020"}, {"id": "30b923111a5c8ec27bf9a409d10daf614d46435b", "title": "Towards ethics by design in online abusive content detection", "year": "2020"}, {"id": "595b1c086f9a1cfffeef2870445364b2cbcb399d", "title": "Crowdsourcing research opportunities: lessons from natural language processing", "year": "2012"}, {"id": "a8f262b28aa4a35196814b447346f99173c4795a", "title": "Ethical artificial intelligence for digital health organizations", "year": "2020"}, {"id": "aad993bf2166fcbe598e154a1fe8264424736989", "title": "An nlp-powered human rights monitoring platform", "year": "2020"}, {"id": "2435b48cc30e30f3849b9670f263b501ba9c0024", "title": "Corpus annotation through crowdsourcing: Towards best practice guidelines.", "year": "2014"}], "2020.acl-tutorials.3": [{"id": "b2b41790d33770ba43c45ed2da89c644840debf0", "title": "A knowledge-grounded multimodal search-based conversational agent", "year": "2018"}, {"id": "594ad264d6b92afb9d13cb56ad8ffadba94a9f7a", "title": "Multimodal transformer networks for end-to-end video-grounded dialogue systems", "year": "2019"}, {"id": "67c9fed93cb6df4cdbefe0188942ae90144f620f", "title": "Enhancing conversational dialogue models with grounded knowledge", "year": "2019"}, {"id": "dca2c92be53531de4646087542f09d74d151b94e", "title": "Ideas on multi-layer dialogue management for multi-party, multi-conversation, multi-modal communication", "year": "2002"}, {"id": "311a3619d7e5409ccedfd646b1a2e3d82eb85502", "title": "Multimodal dialogue systems via capturing context-aware dependencies of semantic elements", "year": "2020"}, {"id": "59ee2e2ed78da75c356ba063c0a88466ffb62391", "title": "Multidm-gcn: Aspect-guided response generation in multi-domain multi-modal dialogue system using graph convolutional network", "year": "2020"}, {"id": "9593768993a3e4af7c9f0f86ae9f68289ab890b4", "title": "Grounding in multi-modal task-oriented collaboration", "year": "1996"}, {"id": "073360639b94aca04bf4f4c2f80880432fa7bc27", "title": "Towards building large scale multimodal domain-aware conversation systems", "year": "2018"}, {"id": "8384387a3739280b15d38f39429aadb7c9bd620f", "title": "Knowledge-aware multimodal dialogue systems", "year": "2018"}, {"id": "be6631af7e61fd02adcb13043010e819df391d18", "title": "Dialogue systems go multimodal: The smartkom experience", "year": "2006"}, {"id": null, "title": "An information state approach in a multi-modal dialogue system for human-robot conversation", "year": "2003"}, {"id": "60986c08f2f18fdfaf18db1a637bc1e7ebea9efd", "title": "Multimodal language grounding for human-robot collaboration: Yrrsds 2019-dimosthenis kontogiorgos", "year": "2019"}, {"id": "cf58cbdaf475109da7c528e6d5d390ed97fba6b2", "title": "Multi-modal open-domain dialogue", "year": "2020"}, {"id": "32eab735c5c41de82930dc873cde46d07a45b971", "title": "EmoSen: Generating sentiment and emotion controlled responses in a multimodal dialogue system", "year": "2020"}, {"id": "9f76b2bf0de083c77f8730809b2c01c28c388c41", "title": "More to diverse: Generating diversified responses in a task oriented multimodal dialog system", "year": "2020"}, {"id": "44f63b0bd01631f7213623c09a62599016e9dfdc", "title": "Situated and interactive multimodal conversations", "year": "2020"}, {"id": "72a6a3f8dc2e157809637bb9bfabc9ae4337f3fc", "title": "Multi-modal repairs of conversational breakdowns in task-oriented dialogs", "year": "2020"}, {"id": "cc0e396ad163a5395af485107a5ca1f1f11101d9", "title": "Simmc: Situated interactive multi-modal conversational data collection and evaluation platform", "year": "2019"}, {"id": "0430064ca3a41628b92723d51af4764d42c1661d", "title": "Multimodal fusion in human-agent dialogue", "year": "2013"}, {"id": "c880fca26169023a900c0f7d65d9b85abc5240a0", "title": "Image-grounded conversations: Multimodal context for natural question and response generation", "year": "2017"}], "2020.acl-tutorials.4": [{"id": "5aada9835d93e361e4e1941ff01352af1e85da8e", "title": "Publication bias in the social sciences: Unlocking the file drawer", "year": "2014"}, {"id": "8264b80b26b294a165ce3184611ceb126c127502", "title": "The performance of tests of publication bias and other sample size effects in systematic reviews of diagnostic test accuracy was assessed", "year": "2005"}, {"id": "5eb5ae39487d3f39365dfa89862c264da5fd377a", "title": "Publication bias in clinical research", "year": "1991"}, {"id": "2bf1f08932f4d5c7e69dccf887a03c989568e0fb", "title": "The existence of publication bias and risk factors for its occurrence", "year": "1990"}, {"id": "14ed79f911c68b2489a7a915de7f169ac1b9358e", "title": "Investigating and dealing with publication and other biases in meta-analysis", "year": "2001"}, {"id": "05001a6f6c8242773aaa951c34360cf65dc7c882", "title": "GRADE guidelines: 5. Rating the quality of evidence\u2014publication bias", "year": "2011"}, {"id": "18cefb1b104288fa4df0cb85853350c681cbb26b", "title": "Comparison of two methods to detect publication bias in meta-analysis", "year": "2006"}, {"id": "502c9122dda395eb30bd0707a85bc235d4e6e3ba", "title": "How to do a systematic review: a best practice guide for conducting and reporting narrative reviews, meta-analyses, and meta-syntheses", "year": "2019"}, {"id": "4b9bd6ccfa84e0ec0402700c392552bd71b4bfed", "title": "Exercise as a treatment for depression: a meta-analysis adjusting for publication bias", "year": "2016"}, {"id": "939f713c00383b717a1aa06620dddafe00f5964d", "title": "Publication bias in meta\u2010analysis", "year": "2005"}, {"id": "3f729900f4f2a1ae5d086fc8e8a1ab74ff020faa", "title": "Publication and related bias in meta-analysis: power of statistical tests and prevalence in the literature", "year": "2000"}, {"id": "3e0a34b33fbb66a2fd0394b100869ecbf22849e0", "title": "A nonparametric \u201ctrim and fill\u201d method of accounting for publication bias in meta-analysis", "year": "2000"}, {"id": "aaf46b5f4fb75acf2892c9b4a7dae9e856daf062", "title": "Methods of meta-analysis: Correcting error and bias in research findings", "year": "midt"}, {"id": "a8e8b03ac9877d289ad345f849a5b4cb6defcea4", "title": "PRESS peer review of electronic search strategies: 2015 guideline statement", "year": "2016"}, {"id": "ad9a62f03c5fc26abf36f965ac33fd1078c07af6", "title": "Bias in meta-analysis detected by a simple, graphical test", "year": "1997"}, {"id": "a1726a7bb59e3ddadd4c61d7769db734b56cc5f3", "title": "Tools for assessing quality and susceptibility to bias in observational studies in epidemiology: a systematic review and annotated bibliography", "year": "2007"}, {"id": "6d426910acb83373ab5caf5f31f1be127bfc666e", "title": "Trim and fill: a simple funnel-plot\u2013based method of testing and adjusting for publication bias in meta-analysis", "year": "2000"}, {"id": "bd5b9c8ef53bc8ff29441a0aa832851171c211bf", "title": "A typology of reviews: an analysis of 14 review types and associated methodologies", "year": "2009"}, {"id": "e23120b7031227d3787100efbf6519c02643216f", "title": "A guide to writing the dissertation literature review", "year": "2019"}, {"id": "2891ed5e9446774153278007a9a09a353dcee258", "title": "What reviewers should expect from authors regarding common method bias in organizational research", "year": "2010"}], "2020.acl-tutorials.6": [{"id": "ebe2eacf5c9ec18be89ad2262b43a5d0c93dccbd", "title": "Multi-modal information extraction from text, semi-structured, and tabular data on the web", "year": "2020"}, {"id": "206dad0b40920a68d0223e3721626ae0e6e12faa", "title": "doc2dial: A goal-oriented document-grounded dialogue dataset", "year": "2020"}, {"id": "2c0b7ce42d41e67f8ee0d4aecb65d33de92a4921", "title": "Examining the application of modular and contextualised ontology in query expansions for information retrieval", "year": "orge"}, {"id": "acc9a473ac7fd0f34b43bb88014fb64b24ac643f", "title": "Semantic and distributed entity search in the web of data", "year": "ayer"}, {"id": "54cbabd7bbe22eb56ccb87a0d0e190eb689fc984", "title": "A survey of deep learning approaches for ocr and document understanding", "year": "2020"}, {"id": "90c8196e5076412a926193d2aef60c04d0dd54d5", "title": "Incentives for the Semantic Web (INSEMTIVE 2008)", "year": "ecic"}, {"id": "254df7db5695f0c33e9738925a2d6413e099d768", "title": "Cheap IR evaluation: fewer topics, no relevance judgements, and crowdsourced assessments", "year": "2020"}, {"id": "7408fd246ddeb4ecf2db43710110c5244133fd67", "title": "for Grid", "year": "2003"}, {"id": null, "title": "ECOLLABORATION TECHNOLOGY SURVEY TECHNICAL NOTE", "year": " ESA"}], "2020.acl-tutorials.7": [{"id": "d7b6753a2d4a2b286c396854063bde3a91b75535", "title": "A simple method for commonsense reasoning", "year": "2018"}, {"id": null, "title": "Commonsense reasoning: an event calculus based approach", "year": "ller"}, {"id": "2bf2c3598f1ee3a2fa22185cb2aaeb425de004ad", "title": "Commonsense reasoning and commonsense knowledge in artificial intelligence", "year": "2015"}, {"id": "b3fea597033a46d5ae282464a8f16d6715187e70", "title": "ConceptNet\u2014a practical commonsense reasoning tool-kit", "year": "2004"}, {"id": null, "title": "Socialiqa: Commonsense reasoning about social interactions", "year": "2019"}, {"id": "6dfc2ff03534a4325d06c6f88c3144831996629b", "title": "From recognition to cognition: Visual commonsense reasoning", "year": "2019"}, {"id": "b7436c9593e6f8cda7a1b32e1f2ec2f7b6f04145", "title": "The role of logic in knowledge representation and commonsense reasoning", "year": "oore"}, {"id": "a550f576ff20b8cce98f3ddad0043d3783fbc9b4", "title": "Abductive commonsense reasoning", "year": "2019"}, {"id": "710d183174844da5b7f392667f3cc25d2b098dde", "title": "Kagnet: Knowledge-aware graph networks for commonsense reasoning", "year": "2019"}, {"id": "7e63b661797906f69791a4454bbf9444a743bfd8", "title": "Commonsense reasoning about causality: deriving behavior from structure", "year": "1984"}, {"id": "874e9318c09c711ecd48a903b3824a3a03e2cd62", "title": "Explain yourself! leveraging language models for commonsense reasoning", "year": "2019"}, {"id": null, "title": "Atomic: An atlas of machine commonsense for if-then reasoning", "year": "2019"}, {"id": "5cfbbf3cdff0f905874589bcd21b2646340a5447", "title": "Choice of plausible alternatives: An evaluation of commonsense causal reasoning", "year": "2011"}, {"id": "66117f82def0c69a3b9cc77eb3e2694b0245ca86", "title": "Cosmos QA: Machine reading comprehension with contextual commonsense reasoning", "year": "2019"}, {"id": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "Piqa: Reasoning about physical commonsense in natural language", "year": "2020"}, {"id": "87bb01056b3523043ecd213033eef71689da54de", "title": "Introduction: Progress in formal commonsense reasoning", "year": "2004"}, {"id": "ff3f26fc186b0c8a1dcf05a3f743151ebc9c0a33", "title": "Fuzzy commonsense reasoning for multimodal sentiment analysis", "year": "2019"}, {"id": "cf3955f27c54f425c29c372af3aa19778abe2051", "title": "Representations of commonsense knowledge", "year": "avis"}, {"id": "9679fc2bbdc7242c825c128049de8829b6410fd5", "title": "Common sense reasoning for detection, prevention, and mitigation of cyberbullying", "year": "2012"}, {"id": "2bcafcd4addd16d408da97c187ba69c02eb6df60", "title": "Automating commonsense reasoning using the event calculus", "year": "2009"}], "2020.coling-tutorials.1": [{"id": "4ddb820ad3dceeb777967d98fbae6711de5077eb", "title": "Cross-lingual semantic representation for NLP with UCCA", "year": "2020"}, {"id": "3ac112897f09ed967a1499febf5300428dbfb99f", "title": "SemEval-2019 task 1: Cross-lingual semantic parsing with UCCA", "year": "2019"}, {"id": "b22fec0525be3f4dbeb90fbe287d22e4c94c8430", "title": "\u2026\u00a0@ UIT. VNU-HCM at SemEval 2019 task 1: Graph transformation system from Stanford basic dependencies to Universal Conceptual Cognitive Annotation (UCCA)", "year": "2019"}, {"id": "6c1494ea9c4cf74ea1d7170c81008857051543b2", "title": "Semantic Parsing for Vietnamese: A Cross-Lingual Approach", "year": "Pham"}, {"id": "69fde0ea22b628e6347922f787e4340eafda503d", "title": "Conceptual annotations preserve structure across translations: A French-English case study", "year": "2015"}, {"id": "65ab1b2e456ed44628a32301bbc9237e1ded046c", "title": "Universal Semantic Parsing with Neural Networks", "year": "vich"}, {"id": "8a3edb63a595cde35bbd254240e1f71ebb8e7f6e", "title": "Made for each other: Broad-coverage semantic structures meet preposition supersenses", "year": "2019"}, {"id": null, "title": "UCCA's Foundational Layer: Annotation Guidelines v2. 1", "year": "2020"}, {"id": "16a60cddc23cce31dc4f711b109bb41f0a4e0b6e", "title": "MaskParse@ deskin at SemEval-2019 task 1: Cross-lingual UCCA semantic parsing using recursive masked sequence tagging", "year": "2019"}, {"id": "dff49c89b2d15704b7122c309e76bf7c545200b2", "title": "MRP 2020: The second shared task on cross-framework and cross-lingual meaning representation parsing", "year": "2020"}, {"id": "60981aedd0b0a0f33c84cf1d2a2cc650765efd85", "title": "Low-Resource Sequence Labeling via Unsupervised Multilingual Contextualized Representations", "year": "2019"}, {"id": "eca6dde8e52160a9306b3039f279c2c9778e4e26", "title": "Comparison by conversion: Reverse-engineering UCCA from syntax and lexical semantics", "year": "2020"}, {"id": "187407c9903b3ddbcd83e223597215ee9edf9ec8", "title": "Refining implicit argument annotation for UCCA", "year": "2020"}, {"id": "1239206f4f5af078f7bfcc248cb654dc0ffbae00", "title": "Jbnu at MRP 2019: Multi-level biaffine attention for semantic dependency parsing", "year": "2019"}, {"id": "59dd57ae98c2d9c373c9f04ea390f1ba6c5fffa8", "title": "MRP 2019: Cross-framework meaning representation parsing", "year": "2019"}, {"id": "913910c332f7c783180eab3a0830334d0dbbcbdc", "title": "\\'UFAL at MRP 2020: Permutation-invariant Semantic Parsing in PERIN", "year": "2020"}, {"id": "9c690b828a508635506018ddbd03d63d4e08a380", "title": "Hlt@ suda at semeval 2019 task 1: Ucca graph parsing as constituent tree parsing", "year": "2019"}, {"id": "f07646d92d6bb17ce3b0cee7e353e00e3a033680", "title": "Mutlitask Learning for Cross-Lingual Transfer of Semantic Dependencies", "year": "2020"}, {"id": "5fa4b65e1b7dcde9552cf270a7e4736aa4b605b1", "title": "T\u00fcpa at SemEval-2019 task1:(almost) feature-free semantic parsing", "year": "2019"}, {"id": "7dc9994fbb602140aec5c3910c0f023140df55f3", "title": "HIT-SCIR at MRP 2019: A unified pipeline for meaning representation parsing via efficient training and effective encoding", "year": "2019"}], "2020.coling-tutorials.2": [{"id": "9a0af9e48aad89512ce3e24b6a1853ed3d5d9142", "title": "Topical word embeddings", "year": "2015"}, {"id": "7c01553048a7cb56a712843736dc44f990adccef", "title": "Dynamic word embeddings", "year": "2017"}, {"id": "66021a920001bc3e6258bffe7076d647614147b7", "title": "From word embeddings to document distances", "year": "2015"}, {"id": "0183b3e9d84c15c7048e6c2149ed86257ccdc6cb", "title": "Dependency-based word embeddings", "year": "2014"}, {"id": "83df30bae85fd5888665387310a04abc35207568", "title": "The geometry of culture: Analyzing the meanings of class through word embeddings", "year": "2019"}, {"id": "8aa2cb34f19da35c7ddffc73bcef42f96b1bef5d", "title": "Short text similarity with word embeddings", "year": "2015"}, {"id": "b5d7a19bd0bae10917a8e294960fdacf224d64fe", "title": "Word embeddings quantify 100 years of gender and ethnic stereotypes", "year": "2018"}, {"id": "42cf161894f4b9ebb86a9109dc2af45d9eee8916", "title": "Integrating and evaluating neural word embeddings in information retrieval", "year": "2015"}, {"id": "babbf74939612ee2f0203c30a190b4b95881415b", "title": "Learning gender-neutral word embeddings", "year": "2018"}, {"id": "ccf6a69a7f33bcf052aa7def176d3b9de495beb7", "title": "Man is to computer programmer as woman is to homemaker? debiasing word embeddings", "year": "2016"}, {"id": "53ca064b9f1b92951c1997e90b776e95b0880e52", "title": "Learning word embeddings efficiently with noise-contrastive estimation", "year": "2013"}, {"id": "a41b880cdd9646578ab13e6e0b5356a0c4370811", "title": "Evaluation methods for unsupervised word embeddings", "year": "2015"}, {"id": "6aa3d8bcca2ebdc52ef7cd786204c338f9d609f2", "title": "Improving distributional similarity with lessons learned from word embeddings", "year": "2015"}, {"id": "7dbc24dfc2dd4f9640958790f08b377be121e5a9", "title": "A latent variable model approach to pmi-based word embeddings", "year": "2016"}, {"id": "7f40eba81644fdb356102a1d97a75fae4e7d3856", "title": "Unsupervised word embeddings capture latent knowledge from materials science literature", "year": "2019"}, {"id": "0d3233d858660aff451a6c2561a05378ed09725a", "title": "Bilingual word embeddings for phrase-based machine translation", "year": "2013"}, {"id": "11fdffe08eb1b08bfa8e3fdabe1accfd0e336be3", "title": "Learning bilingual word embeddings with (almost) no bilingual data", "year": "2017"}, {"id": "5feac39a50e5bf240a64f42dbc881a16e8f8e659", "title": "Simple task-specific bilingual word embeddings", "year": "2015"}, {"id": "7ee0a337faec1d87bbb15d84856a43a4aa64ac65", "title": "Diachronic word embeddings reveal statistical laws of semantic change", "year": "2016"}, {"id": "91d4498849fe1966a629cddb187d3cd62eedb2ca", "title": "Deep learning with word embeddings improves biomedical named entity recognition", "year": "2017"}], "2020.coling-tutorials.5": [{"id": "3905c61a2ea363afc29008d6567e481fcf7b9ece", "title": "Validation methodologies and their impact in construction productivity research", "year": "2014"}, {"id": "e2f393d815d826b22ae36c7b606caf875ffecc9e", "title": "Analyzing gene expression data in terms of gene sets: methodological issues", "year": "2007"}, {"id": "81c0b82dc4d90e9dcad9ed23c4276346d626ad19", "title": "On the methodological framework of composite indices: A review of the issues of weighting, aggregation, and robustness", "year": "2019"}, {"id": "752996f2070f5cc808aa0277fd9352d45e30c736", "title": "Visualizing a field of research: A methodology of systematic scientometric reviews", "year": "2019"}, {"id": "846fcf30dc75f04886092891e754791e9704f69f", "title": "Toward developing a systematic approach to generate benchmark datasets for intrusion detection", "year": "2012"}, {"id": "97dcab33aa0f1b8c98eec95e52e13596f3fb890d", "title": "The ecoinvent database: overview and methodological framework (7 pp)", "year": "2005"}, {"id": "664532c9d62eefd63b38e110005c3aa4de57f732", "title": "Overview and methodology: Data quality guideline for the ecoinvent database version 3", "year": "tel\u2026"}, {"id": "900876aa169e55b836411137c40efecb86fc50f2", "title": "Predictive data mining in clinical medicine: current issues and guidelines", "year": "2008"}, {"id": "09289d4ccd924efd1df57ae24cd374ad5e047259", "title": "Handbook on constructing composite indicators: methodology and user guide", "year": "man\u2026"}, {"id": "dbb9c969cee3a070da4b3525a89290b8c376d35a", "title": "Methodological issues in cross\u2010sectional and panel estimates of the human resource\u2010firm performance link", "year": "1996"}, {"id": "09289d4ccd924efd1df57ae24cd374ad5e047259", "title": "Handbook on constructing composite indicators: methodology and user guide", "year": "ntre"}, {"id": "51701284f1bba6e07eac7743f18c106facdf3b2d", "title": "The worldwide governance indicators: Methodology and analytical issues", "year": "2010"}, {"id": "9564970cdc327a5cf734e8d63a6ebf74864df5c6", "title": "Promise and pitfalls in the use of \u201csecondary\u201d data-sets: Income inequality in OECD countries as a case study", "year": "2001"}, {"id": "ecfdfcd1ef21449a01701122745a7be5ba135e7f", "title": "Data mining for imbalanced datasets: An overview", "year": "2010"}, {"id": "e12accc929ea2ab45d05f8df54d11eac2842bac5", "title": "Constructing frames of reference: an analytical method for archaeological theory building using ethnographic and environmental data sets", "year": "ford"}, {"id": "bb6b14397f69bbfbc52cbd1a04bc6302a8b938d7", "title": "The humanid gait challenge problem: Data sets, performance, and analysis", "year": "2005"}, {"id": "46fd40358f55f062ca37ec05f3f74dd08d88499b", "title": "Some methodological issues in cohort analysis of archival data", "year": "1973"}, {"id": "0272d1b0a0e6e7214eb202b7265cadafbba646ee", "title": "Methodological issues and advances in biological meta-analysis", "year": "2012"}, {"id": "a3046db7e02e302fe9661074e238be790f52c3b0", "title": "Feature extraction, construction and selection: A data mining perspective", "year": "toda"}, {"id": "1f159d534f2e150577718b92d3ccfd3e23b7e889", "title": "Constructing a research database of social and environmental reporting by UK companies", "year": "1995"}], "2020.coling-tutorials.6": [{"id": "4cac1e1eb876ffdcfda5a62d5237f942b519a502", "title": "Automatic annotation and evaluation of error types for grammatical error correction", "year": "scoe"}, {"id": "2ac38bfbf67b9897ff8a4e11951eebe3286be28b", "title": "A crash course in automatic grammatical error correction", "year": "2020"}, {"id": "935c188dedc9ffc967f2924bd42ed531e9ec2509", "title": "How far are we from fully automatic high quality grammatical error correction?", "year": "2015"}, {"id": "c7617f6a940ad7d21e1add5cd47af5f6de85fd41", "title": "Automatic annotation of error types for grammatical error correction", "year": "yant"}, {"id": "ebfab6d86bb1565ff4435d3e8afe44ce9526dd4e", "title": "A comprehensive survey of grammar error correction", "year": "2020"}, {"id": "a94d56b7c4e6574aee562d297bb9a1096d2716ab", "title": "Neural quality estimation of grammatical error correction", "year": "2018"}, {"id": "f1e8f81a776ddefb621007370c56454f47c0cdce", "title": "Automated Grammatical Error Correction for Language Learners", "year": "2014"}, {"id": "50baa2e217099356815fce033177dd7a82285216", "title": "Grammatical error correction (GEC): research approaches till now", "year": "2019"}, {"id": "b864ecde785c816bc922e65ca5e1e2c88649975a", "title": "Automatic grammatical error correction for sequence-to-sequence text generation: An empirical study", "year": "2019"}, {"id": "fcae82bd4a5fbe2542533cea5ccf1a795c9f64c6", "title": "Corpora generation for grammatical error correction", "year": "2019"}, {"id": "1fe490f22516fcc94584cdd76fa0890560ae4398", "title": "Automatic metric validation for grammatical error correction", "year": "2018"}, {"id": "1cc3e28d577b0628de05ac46e6ec3bbc275348d9", "title": "Learning to combine grammatical error corrections", "year": "2019"}, {"id": "9ad2f58f1e7f3b3d825d5c6b174fb38f601c6df0", "title": "Grammatical error correction in low-resource scenarios", "year": "2019"}, {"id": "e5a9b4c086ece839b815c9953b1dec9a25b2e172", "title": "Chinese grammatical error correction using statistical and neural models", "year": "2018"}, {"id": null, "title": "Algorithms for automatic grammatical error correction", "year": "wicz"}, {"id": "b070d6dd66d95a74965132cba2006081a5e8fb77", "title": "Neural grammatical error correction for romanian", "year": "2020"}, {"id": null, "title": "Spoken language'grammatical error correction'", "year": "Wang"}, {"id": "6865a1c95e1c85311ddeb2a0871c74749e1b0cdf", "title": "A two-stage model for Chinese grammatical error correction", "year": "2019"}, {"id": "f817803b70e27cb3def80c9e819ae537e68235d5", "title": "Automatic grammatical error correction based on edit operations information", "year": "2018"}, {"id": "78a1a59b10570ad7b62d5f7675fd4f8b4c27dc2d", "title": "Cross-sentence grammatical error correction", "year": "2019"}], "2020.coling-tutorials.7": [{"id": "f4fd250b6e4306e068995b2751d8d292a8d86b09", "title": "ASR for documenting acutely under-resourced indigenous languages", "year": "2018"}, {"id": "f6d6c4dd0115386c234a0b027dd38f7aa9d9df2f", "title": "Endangered languages meet Modern NLP", "year": "2020"}, {"id": "42605c1ee030721cb38a3c225992d63297a6ace0", "title": "A summary of the first workshop on language technology for language documentation and revitalization", "year": "2020"}, {"id": "ccf6a029c1310a8badb999e6b94e62a7f7c0cbef", "title": "Support for endangered and low-resource languages via e-learning, translation and crowd-sourcing", "year": "2018"}, {"id": "79ae74660752d7f6df925201148c38872ae5f603", "title": "Promoting Language Technology for Endangered Languages with Shared Tasks", "year": "2019"}, {"id": "556f4ff1027ba5d13aed421a08b322b166973ecb", "title": "ChrEn: Cherokee-English machine translation for endangered language revitalization", "year": "2020"}, {"id": null, "title": "Open source code and low resource languages", "year": "2018"}, {"id": "6e9514f694ae55a1fbf2747ffb1abbcf839a0821", "title": "Selection criteria for low resource language programs", "year": "2016"}, {"id": "f40fb367e5d559313bbd8936ddebfc9627df9586", "title": "Improving asr output for endangered language documentation", "year": "2018"}, {"id": null, "title": "Best way for collecting data for low-resourced languages", "year": "arim"}, {"id": null, "title": "Under-researched languages: Phonetic results from language archives", "year": "2019"}, {"id": "0d473bfc818f331ee82271621804f5aef42b78a2", "title": "Automatic glossing in a low-resource setting for language documentation", "year": "2018"}, {"id": "5f6eb048a39d64c08f7969b1c28719bc16972add", "title": "Short-term projects, long-term benefits: Four student NLP projects for low-resource languages", "year": "2014"}, {"id": "1ec331a98b752df6298eff2c32c23f026a1eb4dd", "title": "Community-focused language documentation in support of language education and revitalization for St. Lawrence Island Yupik", "year": "2019"}, {"id": "2baa11d06b50fdec15fb8c0ced0d9e15179ff8c8", "title": "Learnings from technological interventions in a low resource language: a case-study on Gondi", "year": "2020"}, {"id": null, "title": "Archiving endangered mund\u0101 languages in a digital library", "year": " Das"}, {"id": "fcc8fc03bff6a152f1f4ee8701ba245f40d45ba9", "title": "Language documentation twenty-five years on", "year": "2018"}, {"id": null, "title": "Under-Researched Languages: Phonetic Results from Language Archives DH Whalen", "year": "ough"}, {"id": "67ee5e9dfe2e009b60438153e005caf771c499df", "title": "Developing technologies for the documentation and description of the low-resource Uralic languages Zyrian Komi and North Saami", "year": "\u00dfler"}, {"id": "a93dd095734eedf76bbd0c0f767eb35eefc19ecd", "title": "Enabling Large-Scale Collaboration in Language Conservation", "year": "nson"}], "2020.emnlp-tutorials.1": [{"id": "6e40c40d26a2504704df6c2968b98fc73ebbc956", "title": "Machine reasoning: Technology, dilemma and future", "year": "2020"}, {"id": "833c4ac0599f4b8c5f1ee6ea948ec675fbe56b15", "title": "Neural-symbolic computing: An effective methodology for principled integration of machine learning and reasoning", "year": "2019"}, {"id": "d7701e78e0bfc92b03a89582e80cfb751ac03f26", "title": "Explaining explanations: An overview of interpretability of machine learning", "year": "2018"}, {"id": "f156ecbbb9243522275490d698c6825f4d2e01af", "title": "Explainable ai: A review of machine learning interpretability methods", "year": "2020"}, {"id": "65fffcaf0f95febb831c56546dcfeb83a5b5b19a", "title": "Explainable AI: a hybrid approach to generate human-interpretable explanation for deep learning prediction", "year": "2020"}, {"id": "23b80b4af1e1045b6bccadcb894450988e0299ee", "title": "Towards explainable neural-symbolic visual reasoning", "year": "2019"}, {"id": "c611b9c82e234b344a232bcbbe5436e06da69f0b", "title": "Explainable neural computation via stack neural module networks", "year": "2018"}, {"id": "2e5ed0c6f7b0daac9985ca985035cbcafba0a417", "title": "Machine reasoning explainability", "year": "2020"}, {"id": "07bc27b5e2f829ae102f31dbd783899993717039", "title": "How Case-Based Reasoning Explains Neural Networks: A Theoretical Analysis of XAI Using Post-Hoc Explanation-by-Example from a Survey of ANN-CBR Twin\u00a0\u2026", "year": "2019"}, {"id": "bc00ff34ec7772080c7039b17f7069a2f7df0889", "title": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead", "year": "2019"}, {"id": "bae1a80920b9c7bafb89c2a4bd6842448a1f4415", "title": "Towards deep machine reasoning: a prototype-based deep neural network with decision tree inference", "year": "2020"}, {"id": "bf9af274a17eea6ca3721acffab14e5c8e9f097a", "title": "Deep learning for case-based reasoning through prototypes: A neural network that explains its predictions", "year": "2018"}, {"id": "cfd7298437398632545aad14dbe80a3515db27d0", "title": "Challenges in interpretability of neural networks for eye movement data", "year": "2020"}, {"id": "41c1fe3e822507c4f1e374f6a35c43a5c72d4899", "title": "Extracting relational explanations from deep neural networks: A survey from a neural-symbolic perspective", "year": "2019"}, {"id": "0cf102da6dd4276115c63cbb6797f24ed450fea1", "title": "Towards robust interpretability with self-explaining neural networks", "year": "2018"}, {"id": "ce10676634b0c8299a27c3303049c60d6ecbf87d", "title": "Interpretability of deep learning models: A survey of results", "year": "2017"}, {"id": "60330217cec15b528e5e1dd7935731e357238914", "title": "Interpretable neural networks based on continuous-valued logic and multicriteria decision operators", "year": "2020"}, {"id": "4fc594c1ced000ea6ae36d28242cf50b4aec502f", "title": "Learning dynamics of attention: Human prior for interpretable machine reasoning", "year": "2019"}, {"id": "bcbf3d3d73f2aef6121b234fa5cf4295d5fcbc50", "title": "Twin-systems to explain artificial neural networks using case-based reasoning: Comparative tests of feature-weighting methods in ANN-CBR twins for XAI", "year": "2019"}, {"id": "9b435ea80b6f90800339b3bffeafab6c990caa88", "title": "Interpretability of machine learning\u2010based prediction models in healthcare", "year": "2020"}], "2020.emnlp-tutorials.2": [{"id": "7d3c2ff37d04914836f9cbd9ce54b6c97aa74a22", "title": "Truth of varying shades: Analyzing language in fake news and political fact-checking", "year": "2017"}, {"id": "605d0635d7921ebb821daab8a5250ba015850d3b", "title": "Fighting and framing fake news", "year": "2019"}, {"id": "0e67312f979a09357da209d8cc1903d1c67a3119", "title": "Fact-checking as defence against propaganda in the Digital age", "year": "2018"}, {"id": "d6bee774b4552d54754d4c2a3ac32c2c5ae61e67", "title": "Media literacy versus fake news: fact checking and verification in the era of fake news and post-truths", "year": "2019"}, {"id": null, "title": "War on Propaganda or PRopaganda War?: A case study of fact-checking and (counter) propaganda in the EEAS project EUvsDisinfo", "year": "orio"}, {"id": "f9ee837d58e3c1a631c167cb51e2a2bba3ee4d80", "title": "Analysis of digital tools and technologies for debunking fake news", "year": "2019"}, {"id": "e5f139839348414315dea18c1d5291016de0d951", "title": "Fake news and propaganda: A critical discourse research perspective", "year": "2019"}, {"id": "043908dd176fd0c2eaf67f92a41fb6249658da0b", "title": "Media literacy and fact checking: part two", "year": "2020"}, {"id": null, "title": "Stopping fake news: The work practices of peer-to-peer counter propaganda", "year": "2018"}, {"id": "ee6cf59fc693f5cb00da29a24b26df0011da7495", "title": "Why is fake news a severe problem for democracy? Combating fake news and checking facts in the internet age", "year": "2018"}, {"id": null, "title": "The function and importance of fact-checking organizations in the era of fake news: Teyit. org, an example from turkey", "year": "2019"}, {"id": "7d3c2ff37d04914836f9cbd9ce54b6c97aa74a22", "title": "Truth of varying shades: On political fact-checking and fake news", "year": "2017"}, {"id": "a8238c9c870c2b64157a7ee60ef947214e0ee42e", "title": "Communicative actions we live by: The problem with fact-checking, tagging or flagging fake news\u2013the case of Facebook", "year": "2020"}, {"id": "d8ca06e03b5d7093ce759a857919ee3a8b9e42d7", "title": "The rise of guardians: Fact-checking url recommendation to combat fake news", "year": "2018"}, {"id": "d148d387601c8c6a4958fa09829d6ba705677219", "title": "Can We Spot the\" Fake News\" Before It Was Even Written?", "year": "2020"}, {"id": null, "title": "Media literacy and fact checking: part one", "year": "2019"}, {"id": null, "title": "A short guide to the history of 'fake news' and disinformation", "year": "2018"}, {"id": "ac459986534ca8b26b062cc012bceb5a0676498c", "title": "F for fake: Propaganda! hoaxing! hacking! partisanship! and activism! in the fake news ecology.", "year": "2018"}, {"id": "aef188277f1bc09aff774b4d4913a5813e8961d3", "title": "'Fake news'\u2013the perfect storm: historical perspectives", "year": "2020"}, {"id": null, "title": "Fact-checking eo controle da propaganda eleitoral", "year": "2015"}], "2020.emnlp-tutorials.3": [{"id": "9b435ea80b6f90800339b3bffeafab6c990caa88", "title": "Interpretability of machine learning\u2010based prediction models in healthcare", "year": "2020"}, {"id": "ce10676634b0c8299a27c3303049c60d6ecbf87d", "title": "Interpretability of deep learning models: A survey of results", "year": "2017"}, {"id": "d7701e78e0bfc92b03a89582e80cfb751ac03f26", "title": "Explaining explanations: An overview of interpretability of machine learning", "year": "2018"}, {"id": "87a3676647d1bd553ceb08cf83439b1833f1036f", "title": "Cxplain: Causal explanations for model interpretation under uncertainty", "year": "2019"}, {"id": "ebfca6a48dde396e2274caa9f15389fdbf08fd12", "title": "Improving interpretability of deep neural networks with semantic information", "year": "2017"}, {"id": "0cf102da6dd4276115c63cbb6797f24ed450fea1", "title": "Towards robust interpretability with self-explaining neural networks", "year": "2018"}, {"id": "442e10a3c6640ded9408622005e3c2a8906ce4c2", "title": "A unified approach to interpreting model predictions", "year": "2017"}, {"id": "b79fc9da244988c7e485772d52a09da248e89303", "title": "Exs: Explainable search using local model agnostic interpretability", "year": "2019"}, {"id": "fdd025e077a36166b10120b448d0c4e4009824a9", "title": "Model-agnostic interpretability of machine learning", "year": "2016"}, {"id": "f156ecbbb9243522275490d698c6825f4d2e01af", "title": "Explainable ai: A review of machine learning interpretability methods", "year": "2020"}, {"id": "9bc9fb325eb6783158065ce3f582e2d69f13f2ca", "title": "On the interpretability of machine learning-based model for predicting hypertension", "year": "2019"}, {"id": "58e0ca33ae3068fee7005f339bf6c444fc17d55f", "title": "Explainable artificial intelligence: Understanding, visualizing and interpreting deep learning models", "year": "2017"}, {"id": "66ef8187b36f58848c3eef52fad9f83bdf077cc1", "title": "An evaluation of the human-interpretability of explanation", "year": "2019"}, {"id": "2ce17f17ab4d9ce280265a5147e0e6f62bebc8a7", "title": "An unexpected unity among methods for interpreting model predictions", "year": "2016"}, {"id": "a9007cf4c4ec7e4fc956bead7008a3605451de49", "title": "Interpretability via model extraction", "year": "2017"}, {"id": "4c281ab9e305c8424d539782705f99125112fb34", "title": "Visual interpretability for deep learning: a survey", "year": "2018"}, {"id": "bc00ff34ec7772080c7039b17f7069a2f7df0889", "title": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead", "year": "2019"}, {"id": "986b8eb774a0b3a2bdbe359d246acb15f0b3581b", "title": "Extract interpretability-accuracy balanced rules from artificial neural networks: A review", "year": "2020"}, {"id": "844edcb9961c4b00f5df9a3fa1935905e5f8a2ad", "title": "Illuminating the black box: interpreting deep neural network models for psychiatric research", "year": "2020"}, {"id": "e4acba889d1fcd7bcf82d4593a9044b9dc119de0", "title": "Interpretable and fine-grained visual explanations for convolutional neural networks", "year": "2019"}], "2020.emnlp-tutorials.5": [{"id": "c7c56ca5453b37e68b3bbc38112fb0306a175037", "title": "Representation, learning and reasoning on spatial language for downstream nlp tasks", "year": "2020"}, {"id": "0905d4a8f93f35f0c3b631388d3f5e9b3e993f1f", "title": "Understanding spatial language in radiology: Representation framework, annotation, and spatial relation extraction from chest X-ray reports using deep\u00a0\u2026", "year": "2020"}, {"id": "8a408f0de8de968782e590704c50bf61ccd03c75", "title": "Enabling robots to understand incomplete natural language instructions using commonsense reasoning", "year": "2020"}, {"id": "b1832b749528755dfcbe462717f4f5afc07243b8", "title": "Commonsense reasoning for natural language understanding: A survey of benchmarks, resources, and approaches", "year": "2019"}, {"id": "316302a916852e674caf85e5e047a9e149f4a720", "title": "Downstream model design of pre-trained language model for relation extraction task", "year": "2020"}, {"id": "2d315208dd88eed245dc4ae1ae398af75aa291f8", "title": "Curriculum learning for natural language understanding", "year": "2020"}, {"id": "5066c41ef26ac9876ba797a7c7f49548cf713f9b", "title": "Coreferential reasoning learning for language representation", "year": "2020"}, {"id": "01400290c7db96c4d665d1c29519c42ba47401e0", "title": "A mathematical exploration of why language models help solve downstream tasks", "year": "2020"}, {"id": "9815264d6b311f5179bb61366719c71d38e0a51b", "title": "Beyond language: Learning commonsense from images for reasoning", "year": "2020"}, {"id": "1cb397bb5bc6bb49b72e5f143eacb4a572bd014b", "title": "Multi-purpose natural language understanding linked to sensorimotor experience in humanoid robots", "year": "2015"}, {"id": "6ba8d0eed7fd3735b6748a5cd0474d0448abafbd", "title": "Integrating multi-purpose natural language understanding, robot's memory, and symbolic planning for task execution in humanoid robots", "year": "2018"}, {"id": "6ce77e08f3ac00e67ac306e27e43e1aa075692d8", "title": "Natural language qa approaches using reasoning with external knowledge", "year": "2020"}, {"id": "5f3c29c1d4eaf50ae72b3d6a23c97faa603b83d6", "title": "A review of spatial reasoning and interaction for real-world robotics", "year": "2017"}, {"id": "58ed1fbaabe027345f7bb3a6312d41c5aac63e22", "title": "Retrieval-augmented generation for knowledge-intensive nlp tasks", "year": "2020"}, {"id": "101d1b1872df566088cb31b95b7e78024a484a64", "title": "Attending to entities for better text understanding", "year": "2020"}, {"id": "00b1e962182c42949822821dc1a929bd132ec082", "title": "Placing language in an integrated understanding system: Next steps toward human-level performance in neural language models", "year": "2020"}, {"id": "25c3b294b9ed2786c4476a25e8b36ebf49fd5b4b", "title": "ERICA: Improving entity and relation understanding for pre-trained language models via contrastive learning", "year": "2020"}, {"id": "874e9318c09c711ecd48a903b3824a3a03e2cd62", "title": "Explain yourself! leveraging language models for commonsense reasoning", "year": "2019"}, {"id": "8710ae72078e2b0cd9b6e7a27d93f39ec82ee747", "title": "CS-NLP Team at SemEval-2020 Task 4: Evaluation of state-of-the-art NLP deep learning architectures on commonsense reasoning task", "year": "2020"}, {"id": "70f2c1567ef94fdf4581e1290bf7667cc9a4dcfc", "title": "Logiqa: A challenge dataset for machine reading comprehension with logical reasoning", "year": "2020"}], "2020.emnlp-tutorials.6": [{"id": "28dcc782d9d626ac1da5b284161609a1ccb5b533", "title": "Simultaneous translation of lectures and speeches", "year": "2007"}, {"id": "bbc03bea6b306d6e8d16855641d73e8c5bafffab", "title": "The ATR multilingual speech-to-speech translation system", "year": "2006"}, {"id": "0ba725ee8299812d0507b1f5fffebe38edc33b01", "title": "Statistical Models of Machine Translation, Speech Recognition and Speech Synthesis for Speech-to-Speech Translation", "year": "moto"}, {"id": "f93b523fe44e2ad2deaa1c6dac2da878a17eeeaf", "title": "Direct speech-to-speech translation with a sequence-to-sequence model", "year": "2019"}, {"id": "999b4b988180b9168d4fd4bdceaf421cd7f17096", "title": "Must-c: a multilingual speech translation corpus", "year": "2019"}, {"id": "8f593c10ab7496d949526119499d39d766c832a2", "title": "Verbmobil: foundations of speech-to-speech translation", "year": "ster"}, {"id": "502586e7ed584ae121fc4a0bed0bb2ad6082e8e0", "title": "Phi DM-Dialog: an experimental speech-to-speech dialog translation system", "year": "1991"}, {"id": null, "title": "Overcoming the language barrier with speech translation technology", "year": "2009"}, {"id": "4e968a446ed75416b2c1583c1a89945a3853e5af", "title": "Interactive translation of conversational speech", "year": "1996"}, {"id": "8f9f7a0714408fb49eeb7060ab16bc1eedb219fd", "title": "Efficient wait-k models for simultaneous machine translation", "year": "2020"}, {"id": "e31646a9b4d61f49d969f8d3e37b03c8d153c16c", "title": "Interacting with computers by voice: automatic speech recognition and synthesis", "year": "2003"}, {"id": "f34366bf2008c9c70ab17f7793ebe2c5bc7cfe59", "title": "Latest trends in hybrid machine translation and its applications", "year": "2015"}, {"id": "c646ccfeaee60487ba1a75f195ce17b8a4ff29bd", "title": "Speech synthesis and recognition", "year": "lmes"}, {"id": "5cc6ba30820e7c3b36d314f4deee990dc5655afb", "title": "Speech recognition by machine, a review", "year": "2010"}, {"id": "d956ca4cd24557b2dc100ff4b57d9714ba44e1b9", "title": "Mobile speech-to-speech translation of spontaneous dialogs: An overview of the final Verbmobil system", "year": "2000"}, {"id": "4e284a9fcd3273ce8a51185300d0af3d15ee152c", "title": "Issues in text-to-speech synthesis", "year": "1998"}, {"id": "b66072f7dd9950d6ed2d53d41cb4656a5d7806c1", "title": "Finite-state speech-to-speech translation", "year": "1997"}, {"id": "5e09e697dfe25abbba637ea7b9461e91d76e6bb6", "title": "Verbmobil: The evolution of a complex large speech-to-speech translation system", "year": "1996"}, {"id": "bf20b9f5dba74f4ca43e5bb450c937a5caf792ca", "title": "Machine translation of cortical activity to text with an encoder\u2013decoder framework", "year": "2020"}, {"id": "1c4630f11b0594cdf56576347e404779ad19ef5f", "title": "Automatic speech recognition", "year": "Deng"}], "2020.emnlp-tutorials.7": [{"id": "08dc4b1f21d90e65be1ec5b94d018e314580aab1", "title": "The amazing world of neural language generation", "year": "2020"}, {"id": "e23cb51f50f749320b9122fb5f75113b4d192c0a", "title": "Evaluation of text generation: A survey", "year": "2020"}, {"id": "edf9476b4a977d6e1505bb9cb4e348f8073e8d42", "title": "Towards content transfer through grounded text generation", "year": "2019"}, {"id": "64da659c0687762359226b4cf455520c78acd165", "title": "Neural language generation: Formulation, methods, and evaluation", "year": "2020"}, {"id": "71bcf9fb09ae5b7191925806ee66186c43c7ba9f", "title": "Multi-Context Dependent Natural Text Generation for More Robust NPC Dialogue", "year": " Dai"}, {"id": "30cdb7747fa82029f57caa51bc0336ed680c33e4", "title": "Few-shot natural language generation by rewriting templates", "year": "2020"}, {"id": "338b34bd5956d20784007400cb50b5d800f38863", "title": "Template guided text generation for task-oriented dialogue", "year": "2020"}, {"id": null, "title": "KGPT: Knowledge-grounded pre-training for data-to-text generation", "year": "2020"}, {"id": "d13bb317e87f3f6da10da11059ebf4350b754814", "title": "Survey of the state of the art in natural language generation: Core tasks, applications and evaluation", "year": "2018"}, {"id": "f83d2439ce294eebee6b8303ab717fb2c0be6386", "title": "Emotional neural language generation grounded in situational contexts", "year": "2019"}, {"id": "4095018e41da90f623af8be7c6f56f597b9cc136", "title": "Few-shot NLG with pre-trained language model", "year": "2019"}, {"id": "37dca804bbb5568af07008c2d9a958b24c4e3f17", "title": "Naver Labs Europe's Systems for the Document-Level Generation and Translation Task at WNGT 2019", "year": "2019"}, {"id": "6b94dcac41325a03956402ff7862fa80936f9ddb", "title": "A survey of natural language generation techniques with a focus on dialogue systems-past, present and future directions", "year": "2019"}, {"id": "e4b3bc794665887c874600b177730286c6527836", "title": "ETC-NLG: End-to-end topic-conditioned natural language generation", "year": "2020"}, {"id": "d9bcd2f3227859a2cc68157da3d69c01b067ee47", "title": "Stylistic transfer in natural language generation systems using recurrent neural networks", "year": "2016"}, {"id": "abaadb4c6affc4d874c4f59bfac60686e851cb5e", "title": "Pre-training text-to-text transformers for concept-centric common sense", "year": "2020"}, {"id": "b1b26858b61a0ca2d885b691064739f87b698f37", "title": "Robust conversational AI with grounded text generation", "year": "2020"}, {"id": "77991dca4fdc99b6622c55f86ca87429a5b8b308", "title": "Deep learning in natural language generation from images", "year": "2018"}, {"id": null, "title": "Neural Question Generation with Transfer Learning and Utilization of External Knowledge", "year": "sheh"}, {"id": "0119a57cf88ef16e6dc291252fae340bb6b3953c", "title": "CommonGen: A constrained text generation challenge for generative commonsense reasoning", "year": "2019"}], "2021.acl-tutorials.1": [{"id": "e18567e845ac91a7d05787e4236a3a9845ffa586", "title": "Why do humans reason? Arguments for an argumentative theory", "year": "2011"}, {"id": "4fcf64e48caea8003a81731825799f3135ff70f4", "title": "Argumentation and learning", "year": "2009"}, {"id": "f9af026c1b89f3671cb1970f6d56d3187cc5b3da", "title": "Arguing the value of virtual worlds: Patterns of discursive sensemaking of an innovative technology", "year": "2011"}, {"id": "82f4a503fdcdd0f866cab71606e09a264ab6b0f2", "title": "Making sense of argumentation and explanation", "year": "2009"}, {"id": "eaee8c2d4c5c8cf2d1122f623f2083ac373e1cdd", "title": "The potential of argument in knowledge building", "year": "2000"}, {"id": "56d6e0e73babe2dc9d6f9a57f5752e091505258e", "title": "Decision by debate", "year": "iede"}, {"id": "ac758105cec63261af415ee4b87b6a4cbbffc35f", "title": "Towards dissolution of the IS research debate: from polarization to polarity", "year": "1998"}, {"id": "25535d54d130acec7c665fa6fd35cf4b1215d4cb", "title": "Argumentation schemes", "year": "agno"}, {"id": "ef0c3b327a0c82507b764b3d338340ee60d8440d", "title": "Chief justice robots", "year": "2018"}, {"id": "90d92109677b84cdde27ab9fac2d2382ed72ada6", "title": "Is telling stories good for democracy? Rhetoric in public deliberation after 9/11", "year": "2006"}, {"id": "cb5bb637f3adbb9e9f8eab8bc2d148ec56a47a15", "title": "Argumentation for learning: Well-trodden paths and unexplored territories", "year": "2016"}, {"id": "205857435e19379270f522a63c429144784cd0d8", "title": "Modularity in cognition: framing the debate.", "year": "2006"}, {"id": "c8d05b24ebca6e2ff50ab693b3a82cab2bbbc09e", "title": "Examining emergent communities and social bots within the polarized online vaccination debate in Twitter", "year": "2019"}, {"id": "d852380b96a80c8cfb1817815be9f2e84affd8bf", "title": "Can computers be fair: How automated and human-powered online dispute resolution affect procedural justice in mediation and arbitration", "year": "2018"}, {"id": "d2c8000f02280b91ea028d8d693ddc10430b468e", "title": "The argument culture: Stopping America's war of words", "year": "nnen"}, {"id": "64152e6b6665c1a36c50e87c797e0a421cbdf6ef", "title": "Teaching and learning argumentative reading and writing: A review of research", "year": "2011"}, {"id": "0e2220e0e4807884392a3c28cb0fbf7f43ec1768", "title": "Human communication as narration: Toward a philosophy of reason, value, and action", "year": "sher"}, {"id": "9b82b48af2e688a228695e43e64b5c4ae249618f", "title": "Persuasive games: The expressive power of videogames", "year": "gost"}, {"id": "206a527de80e2f043c26dd7190d8ecd353819d9f", "title": "A theory of argumentation", "year": "lard"}, {"id": "8ab77233b6556279ee0fb36b590d5035a879379a", "title": "Dialogic argumentation as a vehicle for developing young adolescents' thinking", "year": "2011"}], "2021.acl-tutorials.2": [{"id": "c5262730d8854f88106bdc204860ccf236b3345f", "title": "Open domain event extraction from twitter", "year": "2012"}, {"id": "98a6b07d51261df9418981c1dddf09ad4a9c48e4", "title": "Event extraction via dynamic multi-pooling convolutional neural networks", "year": "2015"}, {"id": "7afc4b1b89081d118700801064e251870d05617b", "title": "Joint event extraction via recurrent neural networks", "year": "2016"}, {"id": "4b0d9255f7fc8a4d9cdf0156e312fc21cb1b6b37", "title": "TimeML: Robust specification of event and temporal expressions in text.", "year": "2003"}, {"id": "30bafa2d2f9dbe9e89c0efae1e4571809d383328", "title": "The interaction of domain knowledge and linguistic structure in natural language processing: interpreting hypernymic propositions in biomedical text", "year": "2003"}, {"id": "74f61af390292fc197659ae698429df4a2de62df", "title": "Unsupervised learning of narrative event chains", "year": "2008"}, {"id": "4f3a17d2921e5bee57794f4cca14a81f59afe42b", "title": "Event structure in perception and conception.", "year": "2001"}, {"id": "b0a8d512169453d92fbe44bc77a96bcc9cb9c85f", "title": "A survey of techniques for event detection in twitter", "year": "2015"}, {"id": "ed57a5b47a16ed1e0d6f0b3d061a4af24dd5675f", "title": "A preferential, pattern-seeking, semantics for natural language inference", "year": "1975"}, {"id": null, "title": "Atomic: An atlas of machine commonsense for if-then reasoning", "year": "2019"}, {"id": "ee3e2a5608033acda22bcc7abc9f767e3e8fc912", "title": "GENIES: a natural-language processing system for the extraction of molecular pathways from journal articles", "year": "2001"}, {"id": "5e214a2af786fadb419e9e169a252c6ca6e7d9f0", "title": "Information extraction: Techniques and challenges", "year": "1997"}, {"id": "048ef48f58156ab9f8eb4c1126e090194459e699", "title": "Event detection and analysis from video streams", "year": "2001"}, {"id": "56edaa1368ff4dfa45388e4be24fdfbded7d88a7", "title": "A primer on neural network models for natural language processing", "year": "2016"}, {"id": "63e5967d88873037bd1dc3485a3ddab20b56859f", "title": "Information extraction", "year": "2008"}, {"id": "3fc44ff7f37ec5585310666c183c65e0a0bb2446", "title": "Head-driven statistical models for natural language parsing", "year": "2003"}, {"id": "58db21ac6f6057254616c40707d6e6485889ad5b", "title": "Probabilistic event calculus for event recognition", "year": "2015"}, {"id": "f668b00ebdf0953a6acafe6dfa44dee16b6f7303", "title": "Discovering models of software processes from event-based data", "year": "1998"}, {"id": "ec43d37aad744150af144d27a08b0b097607e712", "title": "Jumping NLP curves: A review of natural language processing research", "year": "2014"}, {"id": "5e077918a979537f27b9a0820672f23a434a98ee", "title": "Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications", "year": "2010"}], "2021.acl-tutorials.3": [{"id": "c55cc603b74b8ba0cc58dbaa1d8df1af94ab934b", "title": "learn2learn: A library for meta-learning research", "year": "2020"}, {"id": "4241d67f0c37c4efa3f35c740a73174b1c83f61e", "title": "Learning to forget for meta-learning", "year": "2020"}, {"id": "752f6f980540374d7030e90afb8fec9484b546e5", "title": "Meta-learning to improve pre-training", "year": "2021"}, {"id": "4d21334ea3564c89586e1ba176e11382bdd3d394", "title": "Learning to learn how to learn: Self-adaptive visual navigation using meta-learning", "year": "2019"}, {"id": "35ad6ba10006975c2bc67ecefaa9ee6af2453bdc", "title": "Deep meta-learning: Learning to learn in the concept space", "year": "2018"}, {"id": "fc437af6204008647ea49f81058d5fdaddf75ead", "title": "Meta-learning with differentiable convex optimization", "year": "2019"}, {"id": "688f9db8876fbca45d85e3c313294ab217d7f916", "title": "Modeling and optimization trade-off in meta-learning", "year": "2020"}, {"id": "1eee17fd5f7a36a64c771d89dbbb00319935c6a8", "title": "Exploring meta learning: parameterizing the learning-to-learn process for image classification", "year": "2021"}, {"id": "04f739a0c29b75877243731aeead512bf0ed1dff", "title": "Meta-learning with latent embedding optimization", "year": "2018"}, {"id": "020bb2ba5f3923858cd6882ba5c5a44ea8041ab6", "title": "Meta-learning in neural networks: A survey", "year": "2021"}, {"id": "5c717445179991e002333182df3b233fe502e357", "title": "Learning to generalize: Meta-learning for domain generalization", "year": "2018"}, {"id": "339e2610de8487ccb54af05cb59b63854d25f02d", "title": "Meta learning via learned loss", "year": "2021"}, {"id": "105905e42812a88b5060e6f45805aa7889e6218c", "title": "Learning to learn and predict: A meta-learning approach for multi-label classification", "year": "2019"}, {"id": "c18c92a925c4b670b1702c0a674cb6879ebe5e25", "title": "Bridging multi-task learning and meta-learning: Towards efficient training and effective adaptation", "year": "2021"}, {"id": "d4d37dfff71691cda8b4ff2314884b172fb5671b", "title": "How fine-tuning allows for effective meta-learning", "year": "2021"}, {"id": "15561ab20c298e113b0008b7a029486a422e7ca3", "title": "Bilevel programming for hyperparameter optimization and meta-learning", "year": "2018"}, {"id": "7f2304c14ce896624fbdf4580bdad27e2f914333", "title": "Meta-learning with adaptive hyperparameters", "year": "2020"}, {"id": "fd8ffea29a0deef7aed966f6945708c60a2168c2", "title": "Few-shot learning with adaptively initialized task optimizer: a practical meta-learning approach", "year": "2020"}, {"id": "b93317f61c6ed99542da9d1d691ded9732c16c1c", "title": "Unsupervised meta-learning for reinforcement learning", "year": "2018"}, {"id": "642c98fd8266ef3c295b4c5c47d444807daf9621", "title": "Multi-objective meta learning", "year": "2021"}], "2021.acl-tutorials.4": [{"id": "64f94eb97891ca17273464fcb9c507c5a5c7dba7", "title": "Acquiring knowledge from pre-trained model to neural machine translation", "year": "2020"}, {"id": "495da6f19baa09c6db3697d839e10432cdc25934", "title": "Multilingual denoising pre-training for neural machine translation", "year": "2020"}, {"id": "05be5de8c5ff6ca68a592ca9fa5df4098b6c5a0a", "title": "Language model pre-training method in machine translation based on named entity recognition", "year": "2020"}, {"id": "beda4bea4c0bee9d942f7db8b4991712cc707f68", "title": "On the complementarity between pre-training and back-translation for neural machine translation", "year": "2021"}, {"id": "816ea6211b032b83ab67b9e65d351864359bb506", "title": "On the copying behaviors of pre-training for neural machine translation", "year": "2021"}, {"id": "73f3c9aa81fa2771fbe6c10c3c0b2b90a5844697", "title": "CSP: code-switching pre-training for neural machine translation", "year": "2020"}, {"id": "665f654597a1a0f002b1d0dede89c16ded908d41", "title": "Cross-lingual pre-training based transfer for zero-shot neural machine translation", "year": "2020"}, {"id": "7b29f45df975ed1e4c3864b6ab4483f11086aa76", "title": "When and why are pre-trained word embeddings useful for neural machine translation?", "year": "2018"}, {"id": "7a09101ac03b74db501648597fa54e992a0fc84f", "title": "Towards making the most of bert in neural machine translation", "year": "2020"}, {"id": "1180bf7c1f15d5d472123a7b4aa5969baa5d5e7f", "title": "Semface: Pre-training encoder and decoder with a semantic interface for neural machine translation", "year": "2021"}, {"id": "5304392b888f93c4f1730b7d65e66f6a103b3518", "title": "YANMTT: yet another neural machine translation toolkit", "year": "2021"}, {"id": "226a962e9e2e01cafc3803018bb8bf511d549e9f", "title": "Pre-training multilingual neural machine translation by leveraging alignment information", "year": "2020"}, {"id": "cd0cb1121d74a527c57940d86de97fed9ab35276", "title": "Pre-training via leveraging assisting languages for neural machine translation", "year": "2020"}, {"id": "80e949e0e58e06c6f4f75ac4a2d7216b0fa1cfb8", "title": "Recycling a pre-trained BERT encoder for neural machine translation", "year": "2019"}, {"id": "a8492c76ea47b71583a662ec2e791158df9d8995", "title": "Joint training for neural machine translation models with monolingual data", "year": "2018"}, {"id": "0c6b06a0498ad8156af499a3b9b2b612951b3504", "title": "Continual mixed-language pre-training for extremely low-resource neural machine translation", "year": "2021"}, {"id": "c93b2d64fce8737506757bbce51e17b533f9285b", "title": "On the use of BERT for neural machine translation", "year": "2019"}, {"id": "48530f3d6425f2f150f07ccdd61ba951951a0a7d", "title": "Simple, scalable adaptation for neural machine translation", "year": "2019"}, {"id": "53af14897ccca4f8d6c465ee133e859f99ddd7e7", "title": "Shallow-to-deep training for neural machine translation", "year": "2020"}, {"id": "d922481e0d1d069a9d9a5748451f60868db3d64a", "title": "Pre-training Methods for Neural Machine Translation", "year": "2021"}], "2021.acl-tutorials.5": [{"id": "ea20e3a334025f2035a509905709949afa90408c", "title": "Computing prosody: computational models for processing spontaneous speech", "year": "uchi"}, {"id": "57f13c472e13f48827d3c1d1ebea29261720ebf6", "title": "A computational memory and processing model for prosody", "year": "Cahn"}, {"id": "57e77cb567d1cdd1a2b6bb9b7a630befc277ff59", "title": "Computational models of the prosody/syntax mapping for spoken language systems", "year": "leux"}, {"id": "2ef11b5192c8386f133b16d02e17d0ad1d19064c", "title": "Direct modeling of prosody: An overview of applications in automatic speech processing", "year": "2004"}, {"id": "fe86db7bb8137008301b36b826b94d51d1ef9011", "title": "Prosody modeling with soft templates", "year": "2003"}, {"id": "8c5c82433f6e49fc26018331f33393e7adcb60ad", "title": "The computation of prosody", "year": "ardi"}, {"id": "bbd904f2ef2d14cc55a8e9a0d25c178831b4e959", "title": "Prosody, models, and spontaneous speech", "year": "1997"}, {"id": "775b21d744e282b8e9fc6b84712363f92d3c37d9", "title": "Speech prosody: A methodological review", "year": "2011"}, {"id": "fe9e5a243e8fc549208e1dd10ba95134e010ca47", "title": "Recognizing affect from speech prosody using hierarchical graphical models", "year": "2011"}, {"id": "9b6d61491120bdd579f53e8c5f7cbe1e05cbc91e", "title": "Modeling multimodal behaviors from speech prosody", "year": "2013"}, {"id": "03370897046fb555da8b2e4f8613d4ac4fff466d", "title": "Fluent speech prosody: Framework and modeling", "year": "2005"}, {"id": "2321b2cd1359959952ce60fb6c622c405d2c0b58", "title": "Methods in empirical prosody research", "year": "ert\u2026"}, {"id": "8b02562e36db679073b7dfc8705ff5e7fd5764e7", "title": "Experimental and theoretical advances in prosody: A review", "year": "2010"}, {"id": "3c4e5c6eda8231cec5b9995650df3ad8f89ed5d8", "title": "Modeling prosodic differences for speaker recognition", "year": "2007"}, {"id": "0a592a8637b5e75018e7a5540d5b59a4b0b4a220", "title": "Prosody: Models and measurements", "year": "Ladd"}, {"id": "05607f5a0c0a1aeb403d9755ca4e2e3d9df58297", "title": "Prosody-based automatic segmentation of speech into sentences and topics", "year": "2000"}, {"id": "79f2516cde32b26671b605d3e8755001c4a24cbd", "title": "The computational processing of intonational prominence: A functional prosody perspective", "year": "tani"}, {"id": "eac97d7ca65bce11bceb4fbcfa95839b33c97280", "title": "Modeling prosody for language identification on read and spontaneous speech", "year": "2003"}, {"id": "75aee7ad0a97c5b91ebdfe48e9ae9f82f9842905", "title": "Modeling dynamic prosodic variation for speaker verification.", "year": "1998"}, {"id": "743fe7326a8b9f2df8315282db0cced8abbf6269", "title": "Computational models of American speech", "year": "Chen"}], "2021.acl-tutorials.6": [{"id": null, "title": "Logically at Factify 2022: Multimodal fact verification", "year": "2021"}, {"id": "b792296bfe5a3b25c5b15d6dd73f5e68314208de", "title": "Evaluating multimodal representations on visual semantic textual similarity", "year": "2020"}, {"id": "4ec4eeeaa6aff04bed5f93ba150e314c8ce65f56", "title": "Coarse-to-fine semantic alignment for cross-modal moment localization", "year": "2021"}, {"id": "0955252cd57db8503a2ed9e56f195fa44b1bc0d4", "title": "Visual entailment task for visually-grounded language learning", "year": "2018"}, {"id": "d069431c813a92fa70e387ede839d8e049cb4cee", "title": "Entity-oriented multi-modal alignment and fusion network for fake news detection", "year": "2021"}, {"id": "1bc1682df67bf28352a1a4d72b740ed972202740", "title": "Learning semantic sentence representations from visually grounded language without lexical knowledge", "year": "2019"}, {"id": "90476a940ce8ee4e358dc8d4ff5ebc1c6d12e519", "title": "Speech Grammars for Textual Entailment Patterns in Multimodal Question Answering.", "year": "2010"}, {"id": "be38ffead57d01ebd763401d9550f3a3fe0431eb", "title": "Multimodal Document Alignment: Feature-based Validation to Strengthen Thematic Links.", "year": "2010"}, {"id": "3248121914962cf63116ed91cacede86dbb7cc94", "title": "Neural language models for the multilingual, transcultural, and multimodal Semantic Web", "year": "2020"}, {"id": "a0fdacee0f215295e62f172f4cd2cf114c129c2e", "title": "From Synsets to Videos: Enriching ItalWordNet Multimodally.", "year": "2014"}, {"id": "483652e33504ee295b9f21eb455fb3c114a70177", "title": "Explainable video entailment with grounded visual evidence", "year": "2021"}, {"id": "166527ba7cabe6cddf8cd41c7efa5f2b8fa001a9", "title": "Explainable Multimodal Fusion", "year": "Alvi"}, {"id": "ef06ddd84acea3c6dddd5a86eb500f11f828e07a", "title": "Designing multimodal datasets for NLP challenges", "year": "2021"}, {"id": "9c8da385750db215dc0728dc310251b320d319af", "title": "Deep embodiment: grounding semantics in perceptual modalities", "year": "iela"}, {"id": "415efb7b4d9d1e5b64dbaf3fe4229ad462acce71", "title": "Multimodal intelligence: Representation learning, information fusion, and applications", "year": "2020"}, {"id": "9b08d3201af644a638e291755a5e51f6b17a51f3", "title": "Multi-task video captioning with video and entailment generation", "year": "2017"}, {"id": "b9779ddeb6a8a9de0f7e104d8742728aa14578d6", "title": "Interbert: Vision-and-language interaction for multi-modal pretraining", "year": "2020"}, {"id": "34b0ce6daca8fb1a95b568e1b6d573377e736e24", "title": "Learning joint visual semantic matching embeddings for language-guided retrieval", "year": "2020"}, {"id": "dcc03cce582910458ea6ed58745952b020cf3893", "title": "Unsupervised natural language inference via decoupled multimodal contrastive learning", "year": "2020"}, {"id": "232230b89552c1f88b858478bcd1d48a557a07ab", "title": "Deep Multimodal Learning for Joint Textual and Visual Reasoning", "year": "rdes"}], "2021.eacl-tutorials.1": [{"id": "b14ad759a3496f81fdc177105dbc1e062752a449", "title": "Unsupervised semantic parsing", "year": "2009"}, {"id": "1989a01b107a69143da2283337cea7210a5160e8", "title": "Exploiting the semantic web for unsupervised natural language semantic parsing", "year": "2012"}, {"id": "0b76ec0d0b9c4e318fc11bc2e70b117c8f5de282", "title": "The unsupervised learning of natural language structure", "year": "lein"}, {"id": "2ea908df1b26853f98cc324937fdde6621c0bd05", "title": "Unsupervised neural dependency parsing", "year": "2016"}, {"id": "dd78a271722fb9e0eaade4208860398de1d80b7f", "title": "Grounded unsupervised semantic parsing", "year": "2013"}, {"id": "9f834ee11902ada79b874e7fe5072159d72a0f9f", "title": "Unsupervised learning of the morphology of a natural language", "year": "2001"}, {"id": "a7de6485f1e0ed9a1b37137ae262d5110311d9e1", "title": "Unsupervised parsing with U-DOP", "year": "2006"}, {"id": "4bc9d6596069c9277b57a7ee1e1127d231f28663", "title": "Unsupervised parsing with S-DIORA: Single tree encoding for deep inside-outside recursive autoencoders", "year": "2020"}, {"id": "7150472d17a6353aa2e0af513be91cf9406729e1", "title": "A critical analysis of biased parsers in unsupervised parsing", "year": "2019"}, {"id": "d7add86884b03ded456bd0fd09fa28030f3d64d9", "title": "Confidence driven unsupervised semantic parsing", "year": "2011"}, {"id": "0bfb508fd350cc988e8880f37215e10f02c835cd", "title": "Unsupervised dual paraphrasing for two-stage semantic parsing", "year": "2020"}, {"id": "ed9a3200d6d0850fc2404d7205f5cc1b458d06f8", "title": "Fast unsupervised incremental parsing", "year": "2007"}, {"id": "e509e885ea98ad0762a78fad1369201ae240c301", "title": "Unsupervised dependency parsing without gold part-of-speech tags", "year": "2011"}, {"id": "a4174ba47e08c596922cafcda6a9149e83f7e086", "title": "Punctuation: Making a point in unsupervised dependency parsing", "year": "2011"}, {"id": "bfe947a04e9716fb6a581d9609f448aa5daa50f1", "title": "Viterbi training improves unsupervised dependency parsing", "year": "2010"}, {"id": "71d114b58379b99cb96f01fbb9d1667d970ed53c", "title": "Unsupervised semantic parsing of video collections", "year": "2015"}, {"id": "05a6e3156d5c87c23425e17531131b40954e7623", "title": "Unsupervised learning of natural languages", "year": "2005"}, {"id": "59cecfb2ba6a527bd410ec2c256401b1ed15ed3f", "title": "Cross-lingual transfer for unsupervised dependency parsing without parallel data", "year": "2015"}, {"id": "6fa38ef70e64f592ca67d0c4e35abda72996a613", "title": "Novel estimation methods for unsupervised discovery of latent structure in natural language text", "year": "mith"}, {"id": "069e0d896da7c79faeee4cf057548d5da7ce885e", "title": "Flaubert: Unsupervised language model pre-training for french", "year": "2019"}], "2021.eacl-tutorials.2": [{"id": "7bd94d45c26686d5e679aa669341ba1033fd5cbc", "title": "Aggregating and learning from multiple annotators", "year": "2021"}, {"id": "f049a909e5023f304a64f956d15e46273ae2afb8", "title": "Learning from multiple annotators with varying expertise", "year": "2014"}, {"id": "4b3f872229c0fffd9cc9f52b4bb911e7bfea16e5", "title": "Integration of multiple annotators by aggregating experts and filtering novices", "year": "2012"}, {"id": "766912db878d4ca14680600e982faff44e508a8d", "title": "On releasing annotator-level labels and information in datasets", "year": "2021"}, {"id": "6341545215fff2c9d20bd916323cd0a50301e3f7", "title": "Aggregating semantic annotators", "year": "2013"}, {"id": "a898c3000df8e9bd30f69d77f965e698c440ad71", "title": "Modeling and aggregation of complex annotations via annotation distances", "year": "2020"}, {"id": null, "title": "Learning from multi-annotator data: A noise-aware classification framework", "year": "2019"}, {"id": "cb062c3af24bb104697d3018796acb3ee383a40f", "title": "Learning by aggregating experts and filtering novices: a solution to crowdsourcing problems in bioinformatics", "year": "2013"}, {"id": "f66115e951bfb7f7c415d731e6db6fb4c5751d86", "title": "Finding patterns in noisy crowds: Regression-based annotation aggregation for crowdsourced data", "year": "2017"}, {"id": "b0fcfd62e1ddf4daacfca74ad86de2e369eb9b7e", "title": "Validation methodology for expert-annotated datasets: Event annotation case study", "year": "2019"}, {"id": "c33a74fdc4034043dda87ef1e06a58c5062f3877", "title": "Axiomatic analysis of aggregation methods for collective annotation", "year": "Qing"}, {"id": "732ea0433c4673dd0255ffb67d2314c98bbe93b2", "title": "Selection and aggregation techniques for crowdsourced semantic annotation task", "year": "2015"}, {"id": "93bd8aeebe891ffac9b782e197bc2e06b4d175cd", "title": "A conceptual probabilistic framework for annotation aggregation of citizen science data", "year": "2021"}, {"id": "f83bb3ca54b2454a0c896ece43ef7b387eeb76f3", "title": "Image annotation: the effects of content, lexicon and annotation method", "year": "2020"}, {"id": "789736e4402bc28719725fa5acf81d3e55870bb1", "title": "Hierarchical annotation of medical images", "year": "2011"}, {"id": "6230072ce8a985cc25cfd7dc481fcc0d650317f5", "title": "What is the ground truth? reliability of multi-annotator data for audio tagging", "year": "2021"}, {"id": "4a749f461a4194f1d42d06bdd3071dd19b03ac26", "title": "Data quality from crowdsourcing: a study of annotation selection criteria", "year": "2009"}, {"id": "52433be42b646bde7787268d55916041407dacab", "title": "Crowdsourcing disagreement for collecting semantic annotation", "year": "2015"}, {"id": "0165568bcc1a819c18564567f2ec15d859be2519", "title": "Cheap and fast\u2013but is it good? evaluating non-expert annotations for natural language tasks", "year": "2008"}, {"id": "9036dac5b885de7147788b546d5b12bdf3e23248", "title": "Parting crowds: Characterizing divergent interpretations in crowdsourced annotation tasks", "year": "2016"}], "2021.eacl-tutorials.3": [{"id": "da73ba565d979742cac70cf224fad16fa785745b", "title": "Must-c: A multilingual corpus for end-to-end speech translation", "year": "2021"}, {"id": "8b231737e0048a400527d89aa56c712e8b9bc690", "title": "Multilingual end-to-end speech translation", "year": "2019"}, {"id": "e4d99f390901df5caac0b587ff685f9cde100342", "title": "End-to-end speech translation with knowledge distillation", "year": "2019"}, {"id": "740bc22ee3cf40eb85bc801bc51377991604fd9d", "title": "A comparative study on end-to-end speech to text translation", "year": "2019"}, {"id": "4c4fe2bfacc6db6b446401f164a406c48b642e86", "title": "End-to-end automatic speech translation of audiobooks", "year": "2018"}, {"id": "c95a9010bb05d77e334e280fb6dd987aaf053098", "title": "Listen and translate: A proof of concept for end-to-end speech-to-text translation", "year": "2016"}, {"id": "6974f61a445cc138ec2764e97208e1a84a785e61", "title": "One-to-many multilingual end-to-end speech translation", "year": "2019"}, {"id": "52533e5ffc2f9b635fa21259f9749609b1f9dfa1", "title": "End-to-End Speech Translation with the Transformer.", "year": "2018"}, {"id": "902531f2a9db31de63663641d502cab517f5ff6a", "title": "Bridging the gap between pre-training and fine-tuning for end-to-end speech translation", "year": "2020"}, {"id": "b57a537ae33092b7acf83dbd0470c6c03752fc79", "title": "Speech translation and the end-to-end promise: Taking stock of where we are", "year": "2020"}, {"id": "5dab371fecc43904c0b785a50136d20cee43a99a", "title": "Attention-passing models for robust and data-efficient end-to-end speech translation", "year": "2019"}, {"id": "f0dfe7f0528eded4096a741a751aea4b1f707e82", "title": "SimulSpeech: End-to-end simultaneous speech to text translation", "year": "2020"}, {"id": "099524cb3765e02090e0c07369bb418a03095781", "title": "Curriculum pre-training for end-to-end speech translation", "year": "2020"}, {"id": "af54c890ffce96bae303310182be2ca301f2f97e", "title": "On using specaugment for end-to-end speech translation", "year": "2019"}, {"id": "156f761af850802ac5b67e56df136284980117c9", "title": "End-to-end speech translation via cross-modal progressive training", "year": "2021"}, {"id": "8aa61bb041dce5f5bdcdfa26bb99040e435d5d5b", "title": "Enhancing transformer for end-to-end speech-to-text translation", "year": "2019"}, {"id": "2d3182458ea6173d8897f0e53695c768c684bef6", "title": "Self-training for end-to-end speech translation", "year": "2020"}, {"id": "b6222ad8acdf327368b45fb7fa5f4cf374d6da80", "title": "Leveraging weakly supervised data to improve end-to-end speech-to-text translation", "year": "2019"}, {"id": "940016df38b80c5f3fd9db411e722f58a9d7e227", "title": "Parrotron: An end-to-end speech-to-speech conversion model and its applications to hearing-impaired speech and speech separation", "year": "2019"}, {"id": "d0a313a557bd43a7cacb3e5479cd7c491f7faa5c", "title": "Adapting transformer to end-to-end spoken language translation", "year": "2019"}], "2021.eacl-tutorials.4": [{"id": "ec43d37aad744150af144d27a08b0b097607e712", "title": "Jumping NLP curves: A review of natural language processing research", "year": "2014"}, {"id": "db528269ef800727245c0fcb35b692d29c1ccdc9", "title": "Natural language processing (NLP) in management research: A literature review", "year": "2020"}, {"id": "b1737764f4406ee2d94934afcf769ccd6022b636", "title": "Thirty-five years of research on neuro-linguistic programming. NLP research data base. State of the art or pseudoscientific decoration?", "year": "2010"}, {"id": "655d8c5ea0287f1cf703b1582a0c7dd81e33f367", "title": "Natural language processing in oncology: a review", "year": "2016"}, {"id": "744569e1ff6377ba0b7e3a8e2bcd88ac94d9a02d", "title": "Natural language processing: a historical review", "year": "1994"}, {"id": "a2d2a482ccd62a705c8fafeb5f93bca33a4d796d", "title": "Deep learning in clinical natural language processing: a methodical review", "year": "2020"}, {"id": "020fa07f2dd6958e63e610a6829bb423daba39fa", "title": "Using clinical natural language processing for health outcomes research: overview and actionable suggestions for future advances", "year": "2018"}, {"id": "53854f2216dde4e87e7c872b032ec031cd16f944", "title": "A review of natural language processing techniques for opinion mining systems", "year": "2017"}, {"id": "3410e91c55ec78e4ec94b6a56897945e136d7cd8", "title": "Progress in neural NLP: modeling, learning, and reasoning", "year": "2020"}, {"id": "33d0a96abf0b2cd10c0d440c6c2acd0e7d51cb5f", "title": "Improving the reliability of deep neural networks in NLP: A review", "year": "2020"}, {"id": "53489041a08ef1a6cd19b4c95ce092a148283b6b", "title": "A dataset of peer reviews (PeerRead): Collection, insights and NLP applications", "year": "2018"}, {"id": "abd0d4ed53a86f7af4674b838d590edff6edf9a4", "title": "Natural language processing: an introduction", "year": "2011"}, {"id": "ca6a8f7304e7481ecae8fd369aa16b0d38a8f62d", "title": "Natural language processing technologies in radiology research and clinical applications", "year": "2016"}, {"id": "80d8f048ec3d5ab8595ae58cc9105eaafbc57f14", "title": "Natural language processing in radiology: a systematic review", "year": "2016"}, {"id": "be9c7be2f8e28db3b4c485d589f41732f482abf6", "title": "Deep learning for natural language processing in radiology\u2014fundamentals and a systematic review", "year": "2020"}, {"id": "e2a734d360af3c3b4a650196b2f1d83a82f7765c", "title": "Natural language processing of clinical notes on chronic diseases: systematic review", "year": "2019"}, {"id": "35751e6410682b4629ec79250f96cd7474196a27", "title": "Natural language processing", "year": "2020"}, {"id": "453fdb3f8630f9b71e1e174ca087fe9180b09274", "title": "Observations concerning research literature on neuro-linguistic programming.", "year": "1985"}, {"id": "d47a682723f710395454687319bb55635e653105", "title": "Language (technology) is power: A critical survey of\" bias\" in nlp", "year": "2020"}, {"id": "a687eba9ff84ed2a8d7afb2e6017a8cf5b30e44b", "title": "Natural language processing algorithms for mapping clinical text fragments onto ontology concepts: a systematic review and recommendations for future studies", "year": "2020"}], "2021.eacl-tutorials.5": [{"id": "778c4283106852ff4bd95a5b7c4dc34db3d6ad2b", "title": "Unsupervised neural machine translation initialized by unsupervised statistical machine translation", "year": "2018"}, {"id": "c56dc7c5b42749a63712374cac62ea154d0f9280", "title": "Unsupervised neural machine translation for similar and distant language pairs: An empirical study", "year": "2021"}, {"id": "e7f12eb6a1276a3bce6b03e7a7ade3797e19c9e5", "title": "Reference language based unsupervised neural machine translation", "year": "2020"}, {"id": "6e0d8e47c76cc1f7c28908a1e4b8e01288f0d445", "title": "Unsupervised multi-modal neural machine translation", "year": "2019"}, {"id": "58aff08ffa4db37f0a965b9f0e33c7c24cf34c16", "title": "Unsupervised bilingual word embedding agreement for unsupervised neural machine translation", "year": "2019"}, {"id": "1b856b7dd486d0db7565031720db4e051420ec3b", "title": "Knowledge distillation for multilingual unsupervised neural machine translation", "year": "2020"}, {"id": "1c99e76a9446d311f4a70c808b7825b5f22df1a6", "title": "Unsupervised neural machine translation for english and manipuri", "year": "2020"}, {"id": "c98c2b700d59c6a09fa005156d0580369ca313d4", "title": "Unsupervised neural machine translation with cross-lingual language representation agreement", "year": "2020"}, {"id": "368ba3d484c93d60408352eef87358790d2cef94", "title": "Improving the lexical ability of pretrained language models for unsupervised neural machine translation", "year": "2021"}, {"id": "99b12d0df2b93e800207a5e4618a353912f3dff8", "title": "Multilingual unsupervised neural machine translation with denoising adapters", "year": "2021"}, {"id": "7a9348b148a01b13a24cde828cfbaf81438e7e17", "title": "Unsupervised neural machine translation for low-resource domains via meta-learning", "year": "2020"}, {"id": "067906c924810e8ffc595ff8c9c4b0b2906cca85", "title": "SJTU-NICT's Supervised and Unsupervised Neural Machine Translation Systems for the WMT20 News Translation Task", "year": "2020"}, {"id": "d802623e75b44b227acf33aec26a1607da2898b6", "title": "NICT's unsupervised neural and statistical machine translation systems for the WMT19 news translation task", "year": "2019"}, {"id": "f5c92d1ddef237503001dff55ec36cc755c57b1d", "title": "Integrating unsupervised data generation into self-supervised neural machine translation for low-resource languages", "year": "2021"}, {"id": "7fb364a70a185c7e32bdd8844b7d789b09958464", "title": "Exploiting curriculum learning in unsupervised neural machine translation", "year": "2021"}, {"id": "92efdb1a4634d53c4b2011b1abddd87f5dffcec8", "title": "A multilingual view of unsupervised machine translation", "year": "2020"}, {"id": "ff8ffa75104d869c6b24dbb475a0b1f6fb8754d6", "title": "Chinese-Japanese unsupervised neural machine translation using sub-character level information", "year": "2019"}, {"id": "60264a55c720642ab74da1eca9075c2bb8614b14", "title": "Unsupervised neural machine translation with universal grammar", "year": "2021"}, {"id": "2d1d9d6c5ed68e92f4b08789e0ba136dd4368e36", "title": "Robust unsupervised neural machine translation with adversarial denoising training", "year": "2020"}, {"id": "3277e13821617580534fb25dd2d041bf75f0bceb", "title": "Self-training for unsupervised neural machine translation in unbalanced training data scenarios", "year": "2020"}], "2021.emnlp-tutorials.1": [{"id": "46ecb43d240c025c3c8e20f59effc4afc977209f", "title": "Practice of efficient data collection via crowdsourcing at large-scale", "year": "2019"}, {"id": "1e546d536f230efd4b24beb222d7d8e2fcd21633", "title": "Crowdsourcing beyond annotation: Case studies in benchmark data collection", "year": "2021"}, {"id": "d7dc257883aaf61fce867c40af978585b9700b59", "title": "Crowdsourced data management: Overview and challenges", "year": "2017"}, {"id": "9a1c90b418eff787f3ad81341b6f3f4e086b64e9", "title": "Opportunities and challenges of using crowdsourced measurements for mobile network benchmarking a case study on RTR open data", "year": "2016"}, {"id": "f7ae1ced153477d972f700ee1bc55220d6d9fbe4", "title": "Crowdsourcing reliable local data", "year": "2020"}, {"id": "e018fbbf00656da45ce9e925145731fadb3f7737", "title": "Crowdsourcing a normative natural language dataset: A comparison of Amazon Mechanical Turk and in-lab data collection", "year": "2013"}, {"id": "7d9a3b94f78827952b078c664b0da1c02e1c2ee3", "title": "What ingredients make for an effective crowdsourcing protocol for difficult NLU data collection tasks?", "year": "2021"}, {"id": "4aa9cae6872c26b7dfd870d29b8de5d663a264e7", "title": "Crowdsourcing research: data collection with Amazon's Mechanical Turk", "year": "2018"}, {"id": "21334d1aac5422da88780f8e24e181bfa15ef0e1", "title": "Hollywood in homes: Crowdsourcing data collection for activity understanding", "year": "2016"}, {"id": "9a784a8608a9f3755d7c54a85833d41d6b21355c", "title": "Crowdsourced data management: A survey", "year": "2016"}, {"id": "689aceafcff25a70a1f6752a8ff57dab6f0ffa6b", "title": "Reconceptualizing measuring, benchmarking for improving interoperability in smart ecosystems: The effect of ubiquitous data and crowdsourcing", "year": "2014"}, {"id": "512138dd1f9dd06767246f58d0b523df2ceb4875", "title": "Crowdsourcing database systems: Overview and challenges", "year": "2019"}, {"id": "457ee315aef10019b51a040f5e9f9c16ae402721", "title": "Crowdsourced data collection of facial responses", "year": "2011"}, {"id": null, "title": "Crowdspeech and voxdiy: Benchmark datasets for crowdsourced audio transcription", "year": "2021"}, {"id": "f82c6c6ed5307e042342be52d5f148612edb21ed", "title": "Brief survey of crowdsourcing for data mining", "year": "2014"}, {"id": "a0c52a5cca698636b5a516b24f824d23f506f6e8", "title": "Easy, reproducible and quality-controlled data collection with CROWDAQ", "year": "2020"}, {"id": "5a4a3f1bc971ec2e97158a1e6e2d4740ecd45d54", "title": "The community and the crowd: Multimedia benchmark dataset development", "year": "2012"}, {"id": "92eb95cfca38c97e4a7cac2813191a48a4c0d127", "title": "Spatial crowdsourcing: Challenges, techniques, and applications", "year": "2017"}, {"id": "034564fbfe6b9c4669dd02cd69986536384b51a3", "title": "RSI-CB: A large-scale remote sensing image classification benchmark using crowdsourced data", "year": "2020"}, {"id": "84c95a8db377c25d4280f188e9477569ab57281b", "title": "Crowdsourcing in computer vision", "year": "2016"}], "2021.emnlp-tutorials.2": [{"id": "b05fdba8f447b37d7fa6fdd63d23c70b2f4ee01b", "title": "Aspect extraction for opinion mining with a deep convolutional neural network", "year": "2016"}, {"id": "297d01ff6731c3bd917ede3d378c94cb84650e8f", "title": "Opinion mining and sentiment analysis", "year": "2008"}, {"id": "bab568d3bf93c02cfdd56a046feaef654af51c1e", "title": "Text mining for market prediction: A systematic review", "year": "2014"}, {"id": "a193fe7531246291ac0bf9188aada25314304133", "title": "Topic-dependent sentiment analysis of financial blogs", "year": "2009"}, {"id": "cca6a90c6b0d2607b7c12fa22fd71a005970e6ca", "title": "Data mining in finance: advances in relational and hybrid methods", "year": "yaev"}, {"id": "daee8a2a437ad4857b98217bc0532617f604aa5b", "title": "Sentiment analysis: Mining opinions, sentiments, and emotions", "year": " Liu"}, {"id": "fc9b02a1c48f7f0578cc45cdd8a00ae91854aba4", "title": "New avenues in opinion mining and sentiment analysis", "year": "2013"}, {"id": "7102bb3fe73bd057ff161d9db5214a267c1ef312", "title": "Finbert: Financial sentiment analysis with pre-trained language models", "year": "2019"}, {"id": "02b655252f9c6b80aba9efdab970d6e28f8db6bb", "title": "More than words: Social networks' text mining for consumer brand sentiments", "year": "2013"}, {"id": "338a891907dce447da9a0fa2f27221bd35164163", "title": "Mining the peanut gallery: Opinion extraction and semantic classification of product reviews", "year": "2003"}, {"id": "1d26ea648df63a7ded8457539e8ff4f1aa68b740", "title": "Exploring determinants of voting for the \u201chelpfulness\u201d of online user reviews: A text mining approach", "year": "2011"}, {"id": "b98e75acc8935d7cba76cdf78f3a05c0610dccc4", "title": "Financial News Mining:-Extracting useful Information from Continuous Streams of Text", "year": "ndal"}, {"id": "e98ab6eb7fad7b9e8c4473fb92e4fe61cc450659", "title": "Survey on mining subjective data on the web", "year": "2012"}, {"id": "99d67902a1c92f0feeda0e70c97a3f6136894a49", "title": "Collective opinion spam detection: Bridging review networks and metadata", "year": "2015"}, {"id": "81464e70f33b362351c552efef4ef9f87bd97341", "title": "An efficient approach for opinion mining from skewed twitter corpus using over sampled imbalance data learning", "year": "2017"}, {"id": "5328e5dc801d1cf0f997621519f6b31d79021006", "title": "Sentiment analysis using product review data", "year": "2015"}, {"id": "186ee8fc9995eee179063e54d5632fc0b8a4ad63", "title": "Hospitality and tourism online reviews: Recent trends and future directions", "year": "2015"}, {"id": "d385f52c9ffbf4bb1d689406cebc5075f5ad4d6a", "title": "Affective computing and sentiment analysis", "year": "2017"}, {"id": "3c88d3ee328398d9cdd12f0ef6c8dad46e06ece3", "title": "Mining and mapping halal food consumers: A geo-located Twitter opinion polarity analysis", "year": "2018"}, {"id": "ae5aad6cb0d73e2745a90798e77cd1879fda57e6", "title": "A comprehensive survey on sentiment analysis: Approaches, challenges and trends", "year": "2021"}], "2021.emnlp-tutorials.3": [{"id": "ef01bfad9b319c4c7941b95eadd60a77d9ca914b", "title": "Knowledge-enriched natural language generation", "year": "2021"}, {"id": "2148250fd5b0c1f532ff6ee46143236c7f98783b", "title": "Knowledge-enriched, type-constrained and grammar-guided question generation over knowledge bases", "year": "2020"}, {"id": "3ca320cb73c962cd29b8211cb4fd8074c5e8c9b8", "title": "Contextualized representations using textual encyclopedic knowledge", "year": "2020"}, {"id": "a3e95c1fbc78a6962e8977a5e10beb84f533b11a", "title": "Lifelong knowledge-enriched social event representation learning", "year": "2021"}, {"id": "d198c9667c38db589e92e1280e08e2ac226c7063", "title": "Incorporating external knowledge into machine reading for generative question answering", "year": "2019"}, {"id": "7e8457393ff1b40ddd099f195af9d3b14c5a934f", "title": "Language generation with multi-hop reasoning on commonsense knowledge graph", "year": "2020"}, {"id": "e24d0ed38b08b5542d8a0ca5cee3ebdfdcad31d2", "title": "Towards knowledge enhanced language model for machine reading comprehension", "year": "2020"}, {"id": "3bc0095232c098e737be3be5dd8110ab6b2936a9", "title": "Knowledge-enriched event causality identification via latent structure induction networks", "year": "2021"}, {"id": "4cfe344e88d2ae5dbd18507025527bd9a27991ba", "title": "Commonsense knowledge aware concept selection for diverse and informative visual storytelling", "year": "2021"}, {"id": "85f36ce346e8e77eb85fba288078632809666729", "title": "Automatic text summarisation using linguistic knowledge-based semantics", "year": "amed"}, {"id": "dd8b8005ca4ebcd972e6a9b29cca36db0450a668", "title": "Incorporating relation knowledge into commonsense reading comprehension with multi-task learning", "year": "2019"}, {"id": "149579f1cde4321645ce62a16f4623d5998b3bc4", "title": "Kecrs: Towards knowledge-enriched conversational recommendation system", "year": "2021"}, {"id": "9cccf796f574b996a1bc464f8596513b9ae38397", "title": "Conditional text generation for harmonious human-machine interaction", "year": "2021"}, {"id": "7912b8bb86a6d32ed355651d05ff0cbf37e9504e", "title": "Kvl-bert: Knowledge enhanced visual-and-linguistic bert for visual commonsense reasoning", "year": "2021"}, {"id": "209e0af76a6eb58dd08fa28e578202d80b1e1a8e", "title": "Learning to copy coherent knowledge for response generation", "year": "2021"}, {"id": "8384387a3739280b15d38f39429aadb7c9bd620f", "title": "Knowledge-aware multimodal dialogue systems", "year": "2018"}, {"id": "46ebeb609012b0cc6b56ee05feedb54c523abeba", "title": "Visual storytelling with hierarchical bert semantic guidance", "year": "2021"}, {"id": null, "title": "Combining Text Embedding with Additional Knowledge for Information Extraction", "year": " Roy"}, {"id": "e9e4992bdddc11bde818188c1353fcde650c59b2", "title": "Modeling human motives and emotions from personal narratives using external knowledge and entity tracking", "year": "2021"}, {"id": "71df52fb42995a0c58a873e20beb8f3b9363554a", "title": "Adapting to context-aware knowledge in natural conversation for multi-turn response selection", "year": "2021"}], "2021.emnlp-tutorials.6": [{"id": "b38a82616dd35618b3d0b60e990b97c25efc93fb", "title": "Character-level models versus morphology in semantic role labeling", "year": "2018"}, {"id": "77b91d7607518994d04f75119db4138b23e2eb87", "title": "Natural language processing advancements by deep learning: A survey", "year": "2020"}, {"id": "32e6096f66dd368768c18bd200a5d8607270d5bc", "title": "Towards Semantic Role Labelling of Hindi-English Code-Mixed Data", "year": " Pal"}, {"id": "15023f3b9b082beba929ecc75e3f16c4532845d9", "title": "Human translation quality estimation: feature-based and deep learning-based", "year": "Yuan"}, {"id": "b467b3479125597f3be43aebd9a5b2ef64879982", "title": "Adversarial learning for multi-task sequence labeling with attention mechanism", "year": "2020"}, {"id": "0593e4d52d0adb8220edc484b4bcbcec1cf4da42", "title": "Integrating source-language context into phrase-based statistical machine translation", "year": "2011"}, {"id": "bb2887dfd9dd54b83d5b4b49ea047998d6409c32", "title": "Learning Algorithms for Broad-Coverage Semantic Parsing", "year": "ipta"}, {"id": "bab243c504d8c58701213f5fab736bde3171636d", "title": "A transformer-based neural machine translation model for Arabic dialects that utilizes subword units", "year": "2021"}, {"id": "4632d398cc474049dd79470141a24ced0babd5ea", "title": "Decompositional Semantics for Events, Participants, and Scripts in Text", "year": "nger"}, {"id": "1dd153a8dd7770251d3cab5354c9b65fed56d2ae", "title": "Leveraging Semantic Similarity in Parallel Corpora for Natural Language Processing", "year": "S Wu"}, {"id": "f33559c3fbeddc353cd32c3ed2e8851727d86685", "title": "Error propagation", "year": "N L\u00ea"}, {"id": "059f0134e2a277954ab7d401c0950d3d478babb7", "title": "An NLP framework for non-topical text analysis in Urdu\u2013A resource poor language", "year": "kund"}, {"id": "c38c60f256f07066042e19638c7a2275bf614522", "title": "Hy-NLI: a Hybrid system for state-of-the-art Natural Language Inference", "year": "ouli"}, {"id": "fe88ab6ecad3398ce2ec84cbd9cc8f668b219f84", "title": "Expanding the semantic knowledge of wordnet through semantic types and ufo", "year": "Le\u00e3o"}, {"id": "1551899bc495b987e24ba86e4e9402ea720c2714", "title": "A framework for enriching lexical semantic resources with distributional semantics", "year": "2018"}, {"id": "95a0e96e8e601c680be5503c7be0928b81188e8e", "title": "Using complex networks and Deep Learning to model and learn context", "year": "nior"}, {"id": null, "title": "Enriching models of natural language with auxiliary data", "year": "maud"}, {"id": "20e568c7c88ce7abfb977de300ffae0f838e0e53", "title": "Language-driven video understanding", "year": "Zhou"}, {"id": "f3d0cf605002372f1e502ff957111957db4eaa8d", "title": "Existing evaluation and validation of LRs. FLaReNet Deliverable D5. 1", "year": "oral"}, {"id": "b9ac1725362c5ed9899b0706b7ecd82686066fbe", "title": "A flexible compositional approach to word sense disambiguation", "year": "rros"}], "2021.naacl-tutorials.2": [{"id": "e4acba889d1fcd7bcf82d4593a9044b9dc119de0", "title": "Interpretable and fine-grained visual explanations for convolutional neural networks", "year": "2019"}, {"id": "6e16ec34dbcfa9f82715c6d21f69b6095a9be433", "title": "Fine-grained causality extraction from natural language requirements using recursive neural tensor networks", "year": "2021"}, {"id": "d55705658df55e13709518a1e65247224349ffb9", "title": "Explaining the black-box model: A survey of local interpretation methods for deep neural networks", "year": "2021"}, {"id": "07bc27b5e2f829ae102f31dbd783899993717039", "title": "How Case-Based Reasoning Explains Neural Networks: A Theoretical Analysis of XAI Using Post-Hoc Explanation-by-Example from a Survey of ANN-CBR Twin\u00a0\u2026", "year": "2019"}, {"id": "0c30438e316043c6f7288851fea7b663dcbf8638", "title": "Sequential interpretability: methods, applications, and future direction for understanding deep learning models in the context of sequential data", "year": "2020"}, {"id": null, "title": "Understandable aI and explanation usability: a fine-grained analysis of the state of art of explainable aI visualisations from aI novices perspective", "year": "lino"}, {"id": "785964444715fca13abca787cc98a4f058d02a86", "title": "Generative causal explanations of black-box classifiers", "year": "2020"}, {"id": "267bf71c7ed5e2ad895b9815dfff73658aa9f93e", "title": "Causal learning and explanation of deep neural networks via autoencoded activations", "year": "2018"}, {"id": "e4380ba16a55ef7c2bbeef2218410927ea8c8e00", "title": "Determining the relevance of features for deep neural networks", "year": "2020"}, {"id": "3a4d6671db9ebab7375962383029757ca7220bcd", "title": "Explaining Deep Learning using examples: Optimal feature weighting methods for twin systems using post-hoc, explanation-by-example in XAI", "year": "2021"}, {"id": "03db82055bf039503c8111e997757f122aa5438d", "title": "A survey on neural network interpretability", "year": "2021"}, {"id": "6bda005a727969356a012e177cd600e7fdf80c96", "title": "A review on explainability in multimodal deep neural nets", "year": "2021"}, {"id": "08d442b8e484cc6c335078f1c591e3d029bcaa7b", "title": "Conceptual explanations of neural network prediction for time series", "year": "2020"}, {"id": "d7701e78e0bfc92b03a89582e80cfb751ac03f26", "title": "Explaining explanations: An overview of interpretability of machine learning", "year": "2018"}, {"id": "a75824d49a19295611a6058797453795e08ebabd", "title": "Contrastive explanations in neural networks", "year": "2020"}, {"id": "f25edfa0e26c9e4be4b10eed9c7b5db095335cda", "title": "Replication Study of \u201cGenerative Causal Explanations of Black-Box classifiers\u201d", "year": "ge\u00a0\u2026"}, {"id": "2f4cb3286d532094d8c36af778b23979e1054d61", "title": "Fairness in decision-making\u2014the causal explanation formula", "year": "2018"}, {"id": "3541aecfaafe9a25c7607b243eacd0124bd126f1", "title": "Towards a Taxonomy for the Opacity of AI Systems", "year": "2021"}, {"id": "d5784fd3ac7e06ec030abb8f7787faa9279c1a50", "title": "Interpreting deep learning models in natural language processing: A review", "year": "2021"}, {"id": "782f80c6c38daab48e7682e42df66f462f0592ba", "title": "Review study of interpretation methods for future interpretable machine learning", "year": "2020"}], "2021.naacl-tutorials.3": [{"id": "81a4fd3004df0eb05d6c1cef96ad33d5407820df", "title": "A comprehensive survey on graph neural networks", "year": "2020"}, {"id": "ea5dd6a3d8f210d05e53a7b6fa5e16f1b115f693", "title": "Graph neural networks: A review of methods and applications", "year": "2020"}, {"id": "5583528147b2bef03595d2a730a153a559bfa57d", "title": "Graphs, convolutions, and neural networks: From graph filters to graph neural networks", "year": "2020"}, {"id": "62ed9bf1d83c8db1f9cbf92ea2f57ea90ef683d9", "title": "How powerful are graph neural networks?", "year": "2018"}, {"id": "19fd00f8540a5728a21593b2e62e4f9a8abf74d6", "title": "Graph neural networks and their current applications in bioinformatics", "year": "2021"}, {"id": "00358a3f17821476d93461192b9229fe7d92bb3f", "title": "Gnnexplainer: Generating explanations for graph neural networks", "year": "2019"}, {"id": "cf30fb61a5943781144c8442563e3ef9c38df871", "title": "Training graph neural networks with 1000 layers", "year": "2021"}, {"id": "6b010e07618eb36abe6def23d94488b2c81ecbf7", "title": "Position-aware graph neural networks", "year": "2019"}, {"id": "33b75e9094968c060238d54f1026dbc3c8ab66f7", "title": "Graph neural networks with heterophily", "year": "2021"}, {"id": "c2d40522eaa5523d67a0de5e4098e7031fdccb3d", "title": "Pitfalls of graph neural network evaluation", "year": "2018"}, {"id": "775a6e0f9104b282ed867871d743e3afd1e66d96", "title": "Nested graph neural networks", "year": "2021"}, {"id": "44b9f16ba417b90e2e7c42f9074378dd06415809", "title": "Identity-aware graph neural networks", "year": "2021"}, {"id": "140f168d8f4e5d110416eb23bf53be7ac4d090cd", "title": "Elastic graph neural networks", "year": "2021"}, {"id": "2fb6672c9f296507885b98dc4675f9f6758b983e", "title": "Graph neural networks: Architectures, stability, and transferability", "year": "2021"}, {"id": "75c8466a0c1c3b9fe595efc83671984ef95bd679", "title": "Xgnn: Towards model-level explanations of graph neural networks", "year": "2020"}, {"id": "398d6f4432e6aa7acf21c0bbaaebac48998faad3", "title": "Graph neural networks for social recommendation", "year": "2019"}, {"id": "3328a42bdc552fbfba5dbd5b6c16b8aff26fea18", "title": "Robustness of graph neural networks at scale", "year": "2021"}, {"id": "6b989b8327db3a7212141c59c1569f0219775058", "title": "How neural networks extrapolate: From feedforward to graph neural networks", "year": "2020"}, {"id": "0a69c8815536a657668e089e3281ff2e963d947a", "title": "Design space for graph neural networks", "year": "2020"}, {"id": "3bfa808ce20b2736708c3fc0b9443635e3f133a7", "title": "On the bottleneck of graph neural networks and its practical implications", "year": "2020"}], "2021.naacl-tutorials.5": [{"id": "a3e4ceb42cbcd2c807d53aff90a8cb1f5ee3f031", "title": "Specter: Document-level representation learning using citation-informed transformers", "year": "2020"}, {"id": "1d21a50118657e94b9a76330ddbe2e807dea68de", "title": "Contrastive document representation learning with graph attention networks", "year": "2021"}, {"id": "dcb28c8ba94434eb8a06e81eb55bfdbc343d2340", "title": "Document-Level -ary Relation Extraction with Multiscale Representation Learning", "year": "2019"}, {"id": "9204d5b82652ee69859b6de56eb9a189a458c97c", "title": "Representation learning for text-level discourse parsing", "year": "2014"}, {"id": "ba69c46c62b525941e91d0788d20b6ef91847cc4", "title": "Language model pre-training for hierarchical document representations", "year": "2019"}, {"id": "6ef94216e9845b0031cdbd81084e613acd673578", "title": "Modeling document-level context for event detection via important context selection", "year": "2021"}, {"id": "5b871b73e52ce2a88a260a1d43df83300a54e288", "title": "Effective collaborative representation learning for multilabel text categorization", "year": "2021"}, {"id": "05c5b7f1fce91edaaa6d36e362e29d167aeb0447", "title": "TEND: A target-dependent representation learning framework for news document", "year": "2019"}, {"id": "f742890eabee9d1c33ac8c85209b1d230a73719f", "title": "Learning document representation via topic-enhanced LSTM model", "year": "2019"}, {"id": "4267112ddb9959252cf25bb4b7692858434393a7", "title": "Representation learning for electronic health records", "year": "2019"}, {"id": "77dbebb3ebf48b3e6bf1e420e4da55c95320a521", "title": "Hierarchical heterogeneous graph representation learning for short text classification", "year": "2021"}, {"id": "e32a12b14e212506115cc6804667b3d8297917e1", "title": "Poolingformer: Long document modeling with pooling attention", "year": "2021"}, {"id": "2c86f451f6b0c3218e08a12dc82e09dc4a818508", "title": "Coreference Aware Representation Learning for Neural Named Entity Recognition.", "year": "2019"}, {"id": "55ab6e655df68d2a3f1fcbc477560db05a996258", "title": "Hierarchical neural representation for document classification", "year": "2019"}, {"id": "7a84376dd2c61e0e01a95c252f2aa5c6bf20dedb", "title": "Inductive document representation learning for short text clustering", "year": "2021"}, {"id": "17a43e798ede87cadf71793fd29bb12b92ca71d4", "title": "Beyond 512 tokens: Siamese multi-depth transformer-based hierarchical encoder for long-form document matching", "year": "2020"}, {"id": "57a07372e2a620d6ae920f74877eee5f61753a96", "title": "SparTerm: Learning term-based sparse representation for fast text retrieval", "year": "2020"}, {"id": "afad10da0a3b83a4f2a94e8c16c84ac64338e9fe", "title": "ERNIE-Doc: A retrospective long-document modeling transformer", "year": "2020"}, {"id": "f54eb942cb470e732e8e111a447de992f502b43a", "title": "Multilevel text alignment with cross-document attention", "year": "2020"}, {"id": "a833db6a27527fe5b85a3b161fc4317397e6b065", "title": "Multi-timescale representation learning in lstm language models", "year": "2020"}], "2021.naacl-tutorials.6": [{"id": "86651e768096dedf1e0fc19f48123c4ddc603139", "title": "Efficient crowdsourcing for multi-class labeling", "year": "2013"}, {"id": "2133beaf0ae719eaa0b03401b3de55968f6bbb76", "title": "Learning from crowdsourced labeled data: a survey", "year": "2016"}, {"id": "05f39431776d2b8858132b2118b68a6a68bf4f14", "title": "Revolt: Collaborative crowdsourcing for labeling machine learning datasets", "year": "2017"}, {"id": "6e02f36239b77df32512de331d037afd9bfbdb82", "title": "Cost-effective data annotation using game-based crowdsourcing", "year": "2018"}, {"id": "a9b13dd58ef54e0f7b54b26020f454b41766cfa3", "title": "Crowdsourcing label quality: a theoretical analysis.", "year": "2015"}, {"id": "24aac90b012ec6d22e65a0dca92636e1b4edcd7a", "title": "Improving crowdsourced label quality using noise correction", "year": "2017"}, {"id": "e3c9b317f7eb5730e3137f42472e014e0043d245", "title": "Scaling up crowd-sourcing to very large datasets: a case for active learning", "year": "2014"}, {"id": "1d3ce667c7d6d66f98dd5676c80405fcb43a290d", "title": "Active learning for crowdsourcing using knowledge transfer", "year": "2014"}, {"id": "23a7d71726abbdccdea368bc6e43aecb3c970620", "title": "Crowdsourcing multi-label classification for taxonomy creation", "year": "2013"}, {"id": "526ece284aacc3ab8e3d4e839a9512dbbd27867b", "title": "Online crowdsourcing: rating annotators and obtaining cost-effective labels", "year": "2010"}, {"id": "fa35ff678afbd3fc15111c9a8cd5ddaf6e841614", "title": "Machine learning with crowdsourcing: A brief summary of the past research and future directions", "year": "2019"}, {"id": "bf4540beb38eab763f29a2ab5ba2b353635eb3c4", "title": "Active learning with confidence-based answers for crowdsourcing labeling tasks", "year": "2018"}, {"id": "27438a32772e25f25947edc5c56c4d5b37737e18", "title": "Crowdsourcing high quality labels with a tight budget", "year": "2016"}, {"id": "3486f1ba32097b101618ffe94a64f0a67c9ec1f5", "title": "Multi-label inference for crowdsourcing", "year": "2018"}, {"id": "0017aaade2234507dd5508a249f501ae6cb2b61b", "title": "Cost-effective quality assurance in crowd labeling", "year": "2017"}, {"id": "48b56dcee2caecf21377a3ef5d62d1665fa2fce3", "title": "Separate or joint? Estimation of multiple labels from crowdsourced annotations", "year": "2014"}, {"id": "64c8c1cc7bba40c2d4beda35e74f4f9a4a6c56aa", "title": "Noise filtering to improve data and model quality for crowdsourcing", "year": "2016"}, {"id": "6b0960e4c66debc2d7e3e6f39572bb2ed434f506", "title": "Bayesian bias mitigation for crowdsourcing", "year": "2011"}, {"id": "d7dc257883aaf61fce867c40af978585b9700b59", "title": "Crowdsourced data management: Overview and challenges", "year": "2017"}, {"id": "369ffb29f15b1f0ddb9b7245247b7419a6e9afdc", "title": "Crowdsourced label aggregation using bilayer collaborative clustering", "year": "2019"}], "2022.aacl-tutorials.1": [{"id": "f14ea74a40c40cad10c32fccf5a410144735d683", "title": "Efficient and robust knowledge graph construction", "year": "2022"}, {"id": "3de571104ab29bc65d7dc0b27ffb7d7683abe91c", "title": "Adpl: Adversarial prompt-based domain adaptation for dialogue summarization with knowledge disentanglement", "year": "2022"}, {"id": "f2eb62c997cc8334ec734abdbc4586666f012d48", "title": "Relation extraction as open-book examination: Retrieval-enhanced prompt tuning", "year": "2022"}, {"id": "d331de3b6bebb0f9af1fddf1b730ec057a7026d4", "title": "Relational world knowledge representation in contextual language models: A review", "year": "2021"}, {"id": "a3184d40d390793232c99c89b57b8f65c16320b2", "title": "Ernie 3.0 titan: Exploring larger-scale knowledge enhanced pre-training for language understanding and generation", "year": "2021"}, {"id": "812013492d86adaa5e6043e9ef30a7123f25ead8", "title": "Improving adversarial robustness of deep neural networks by using semantic information", "year": "2021"}, {"id": "75e9a66746748a10a412dbed8ad1299c7ec860d2", "title": "Robust and Efficient Deep Learning for Misinformation Prevention", "year": "ster"}, {"id": "573be704e6fb0c851556bb06be9a4bb17366f009", "title": "DeepEC: Adversarial attacks against graph structure prediction models", "year": "2021"}, {"id": "31852f9fc732c0868af12d631c72693702d80521", "title": "Text data augmentation for deep learning", "year": "2021"}, {"id": "a361b203fb2485bfbc092d65625e25a1df22c4c1", "title": "Exploring the limits of domain-adaptive training for detoxifying large-scale language models", "year": "2022"}, {"id": null, "title": "Augmenting Structure with Text for Improved Graph Learning", "year": "favi"}, {"id": "a6e39438f766a4df502d6922c7f253398af60c14", "title": "Pre-trained language models and their applications", "year": "2022"}, {"id": "4d9a59d4253cd54fda6090d11867a7c048e0d4ca", "title": "Collaboration of pre-trained models makes better few-shot learner", "year": "2022"}, {"id": "cea361288e519ba06ed3f6b8298a5b91597b89e2", "title": "Understanding Natural Language with Commonsense Knowledge Representation, Reasoning, and Simulation", "year": "elut"}, {"id": null, "title": "Text Generation with Efficient (Soft) -Learning", "year": "Z Hu"}, {"id": "43250eafc113dd90fd24d1371b43e2fe1e53b868", "title": "Improving and diagnosing knowledge-based visual question answering via entity enhanced knowledge injection", "year": "2022"}, {"id": "4a4caae1aea4910704463f1ea1125ca039e52e5c", "title": "PEINet: joint prompt and evidence inference network via language family policy for zero-shot multilingual fact checking", "year": "2022"}, {"id": null, "title": "Incorporating and Eliciting Knowledge in Neural Language Models", "year": "ogan"}, {"id": "c080f98ee5debd9c026254329ed22a4a89daa707", "title": "CrowdGraph: A crowdsourcing multi-modal knowledge graph approach to explainable fauxtography detection", "year": "2022"}, {"id": "da18398274bec87d3568acfd6aba6977be7ba6b8", "title": "Transferability in deep learning: A survey", "year": "2022"}], "2022.aacl-tutorials.2": [{"id": "15b0d15a1ef487a14d24544d76f6da1271a4f7ec", "title": "Recent advances in pre-trained language models: Why do they work and how do they work", "year": "2022"}, {"id": "8c62277dada489904a63de4dd87336c27c68fb5e", "title": "Delta tuning: A comprehensive study of parameter efficient methods for pre-trained language models", "year": "2022"}, {"id": "a2c44f0b729740c5e0aadff833f8031919cf75a8", "title": "A study of pre-trained language models in natural language processing", "year": "2020"}, {"id": "616e0ed02ca024a8c1d4b86167f7486ea92a13d9", "title": "Visualgpt: Data-efficient adaptation of pretrained language models for image captioning", "year": "2022"}, {"id": "981995fd64611f475179b280f4e9c241051ac185", "title": "Knowledge inheritance for pre-trained language models", "year": "2021"}, {"id": "25ecc4cce21ec05093664b63a0189a4685ded316", "title": "Integrating task specific information into pretrained language models for low resource fine tuning", "year": "2020"}, {"id": "7f84d56fb8feb4e50cd6c3da3e3fd4ff6c4772cf", "title": "Eliteplm: an empirical study on general language ability evaluation of pretrained language models", "year": "2022"}, {"id": "e77c8f93bf92bc9198c3b8b981d223bf56aa707f", "title": "BanglaBERT: Language model pretraining and benchmarks for low-resource language understanding evaluation in Bangla", "year": "2021"}, {"id": "512899134fcfacdfbc53b5cfb10290fa1b81fc63", "title": "St-bert: Cross-modal language model pre-training for end-to-end spoken language understanding", "year": "2021"}, {"id": "e4f82c0a13cae6739239ae0c25a554b6daff35af", "title": "Compression of generative pre-trained language models via quantization", "year": "2022"}, {"id": "a40df30bf2a10aa7fa2b9278d72f8764a94f22ab", "title": "Adapter-based fine-tuning of pre-trained multilingual language models for code-mixed and code-switched text classification", "year": "2022"}, {"id": "b9e8856c46bb12afe71bd569a208b8f6c90b24a9", "title": "Can pre-trained language models interpret similes as smart as human?", "year": "2022"}, {"id": null, "title": "Enhancing zero-shot and few-shot text classification using pre-trained language models", "year": "Chen"}, {"id": "33560c52a5a90e1074a9c341b752bd9e8ac86f7d", "title": "Actune: Uncertainty-based active self-training for active fine-tuning of pretrained language models", "year": "2022"}, {"id": "353818c78b27b920e56a494ee2201eb76b55a90c", "title": "Information Extraction in Low-Resource Scenarios: Survey and Perspective", "year": "2022"}, {"id": "64e38581e5ac8f1e669018deed22b71814dcab9e", "title": "Adapting Pre-trained Language Models to Rumor Detection on Twitter.", "year": "2021"}, {"id": "ca8f25b6c49c7f34380a7c6623e74f63f3a48771", "title": "Incorporating explicit knowledge in pre-trained language models for passage re-ranking", "year": "2022"}, {"id": "449072493a6311370060f1a1f5ed650f02334762", "title": "Framework for deep learning-based language models using multi-task learning in natural language understanding: A systematic literature review and future directions", "year": "2022"}, {"id": "d9a520cd000ef1ccd38f9bb5c1cb851fe5cd3cab", "title": "Comparative analysis of current approaches to quality estimation for neural machine translation", "year": "2021"}, {"id": "82e8bf3668450a9bf8f7bf8b187f37568160ae3d", "title": "P3 ranker: Mitigating the gaps between pre-training and ranking fine-tuning with prompt-based learning and pre-finetuning", "year": "2022"}], "2022.aacl-tutorials.3": [{"id": "0a410973a43ea8d87eca14e90e40b4e3381c8265", "title": "When cantonese NLP meets pre-training: progress and challenges", "year": "2022"}, {"id": "c3f16e36a741abbe7fe6e2dfa55912d3d2fbca68", "title": "Low-resource neural machine translation: A case study of Cantonese", "year": "2022"}, {"id": "c934f29ec6ad1087d7a1b085e8cbdb4b19c9db27", "title": "Natural language processing for resource-poor languages", "year": "2017"}, {"id": "aa45ce08c49d3a4dedb4a93eb9abde5e2c85efca", "title": "Multilingual techniques for low resource automatic speech recognition", "year": "nich"}, {"id": "779c7200f8bea3c97ac7adfc4404ebf20aa8e89d", "title": "Cantonese automatic speech recognition using transfer learning from mandarin", "year": "2019"}, {"id": "76e69e67d50092a01cd7e8320b82ee861d01de66", "title": "Natural language processing for similar languages, varieties, and dialects: A survey", "year": "2020"}, {"id": "8a120b6a1d688c52abecdb0f4123d059de14b2d5", "title": "Words. hk: a comprehensive cantonese dictionary dataset with definitions, translations and transliterated examples", "year": "2022"}, {"id": "f26a801e946d6e7f72a3b92986bf01e88b780508", "title": "Explicit tone transcription improves ASR performance in extremely low-resource languages: A case study in Bribri", "year": "2021"}, {"id": "37a79051d7909dae470422f4591d0d8d1a92f4cb", "title": "Handling long-term dependencies and rare words in low-resource language modelling", "year": "ingh"}, {"id": "2eafcaf2e2508c7a41d6ad14f7bc932c7679cab9", "title": "Multilingual byte2speech models for scalable low-resource speech synthesis", "year": "2021"}, {"id": "218956012927bbc0dbbfd94354a56e16a6f38489", "title": "CINO: A Chinese minority pre-trained language model", "year": "2022"}, {"id": "750205cca39e14ad6dfe3531dbbf2a70bd5d85fc", "title": "WordNet gloss translation for under-resourced languages using multilingual neural machine translation", "year": "2019"}, {"id": "24860bf1869724e4c4b626b2a3d7f25d607496f9", "title": "Aphasia detection for cantonese-speaking and mandarin-speaking patients using pre-trained language models", "year": "2022"}, {"id": "26fbe57d1ca5ff62a334448f2f02bf7641a5a377", "title": "Abui Wordnet: Using a Toolbox Dictionary to develop a wordnet for a low-resource language", "year": "2022"}, {"id": null, "title": "Linguistic knowledge in data-driven natural language processing", "year": "2016"}, {"id": "e777f6fdcd0127331672cb1daf5b1cd23df26d1a", "title": "Opportunities and challenges of automatic speech recognition systems for low-resource language speakers", "year": "2022"}, {"id": "82b8c7ec981030b7f5727e9d5a22ff37afefea1b", "title": "Cantonese neural speech synthesis from found newscasting video data and its speaker adaptation", "year": "2022"}, {"id": "41c32495af5294b5e622d9a3e2047c9132f29494", "title": "Building natural language processing tools for Runyakitara", "year": "2021"}, {"id": "755d8825f1a599c0190a3c05e806027685118e48", "title": "Automatic language identification in code-switched Hindi-English social media text", "year": "2021"}, {"id": "072573de2cdadb8025c47eae58b33235ee3ec9b2", "title": "Proceedings of the 34th Pacific Asia Conference on Language, Information and Computation", "year": "2020"}], "2022.aacl-tutorials.4": [{"id": "cf5a7785443eeda5f3c916f531e76515603091b2", "title": "Challenges and opportunities for grounding cognition", "year": "2020"}, {"id": "516dc7097bc5c8a58214d320f381d79d9222836b", "title": "Grounded cognition", "year": "2008"}, {"id": "5d62f5cabc23856e4a179c1c600266253f18360f", "title": "Abstract concepts: Sensory-motor grounding, metaphors, and beyond", "year": "2011"}, {"id": null, "title": "Grounding categories", "year": "2007"}, {"id": "1223daf8790d95306897f866abebb510936cb630", "title": "Grounded understanding of abstract concepts: The case of STEM learning", "year": "2017"}, {"id": "1b96788121593fc234ccf91ef2283abaaedabc93", "title": "Embodied cognition as grounding for situatedness and context in mathematics education", "year": "1999"}, {"id": "19555faa1486a6eddb3183d4ed66735396ae6402", "title": "On staying grounded and avoiding quixotic dead ends", "year": "2016"}, {"id": "7e2ee5bd0cfaabe512980ddb16cb8f7058c12815", "title": "An embodied cognition perspective on symbols, gesture, and grounding instruction", "year": "2008"}, {"id": "3f5e922ce20efe7da64c115e5346481cfc618b79", "title": "Grounding conceptual knowledge in modality-specific systems", "year": "2003"}, {"id": "f9c55c03c22e819776ead469ea8f94f551fc67bc", "title": "Situating concepts", "year": "2008"}, {"id": "8d88fee4918280cab5e1d260bc915adca6316704", "title": "The situated nature of concepts", "year": "2006"}, {"id": "21877b086959aff22d8efaca6857f75a99a2bc5b", "title": "Embodied grounding: Social, cognitive, affective, and neuroscientific approaches", "year": "mith"}, {"id": "4e1b56627a4213db40828ad180400a290d77507f", "title": "Symbol grounding and meaning: A comparison of high-dimensional and embodied theories of meaning", "year": "2000"}, {"id": "a814d88c0e9476b2114dece94685cb9625adce55", "title": "Conceptual Scaffolding: A spatially founded meaning representation for metaphor comprehension", "year": "1992"}, {"id": "979910ccca236b47892e1b910bc6153ea9059d13", "title": "Coordinating visualizations of polysemous action: Values added for grounding proportion", "year": "2014"}, {"id": "873cef14ee2a6b4e0a77cf0e60539992f6fff05f", "title": "Ontology-based context representation and reasoning for object tracking and scene interpretation in video", "year": "2011"}, {"id": "ad27b3b51c3e8cd8acc992df8e83a5364500c080", "title": "The effects of idealized and grounded materials on learning, transfer, and interest: An organizing framework for categorizing external knowledge representations", "year": "2014"}, {"id": "d5e5d4b70bec7c108cd73f1cfef5a760e7a9ad5b", "title": "Situated conceptualization", "year": "2005"}, {"id": "b4cecb3ffb2594468e9243d45cb8c9f5f077dd13", "title": "The role of grounding in collaborative learning tasks", "year": "1999"}, {"id": "a7c5fce05b676cba2af8c489e7c7691cf6c1997b", "title": "Grounding emotion in situated conceptualization", "year": "2011"}], "2022.aacl-tutorials.5": [{"id": "9cbcb4b206e138c8a3fda1f51da21e37e83fbd9a", "title": "Influence of Fake News Exposure on Perceived Media Bias: The Moderating Role of Party Identity", "year": "2022"}, {"id": "05fc363cb2dcfce97b0e3c171f035ce788353180", "title": "The disaster of misinformation: a review of research in social media", "year": "2022"}, {"id": "2d4a616b11237f259672714b2bf81d37cc591614", "title": "You are fake news: political bias in perceptions of fake news", "year": "2020"}, {"id": "6ce27e8ceb8e7aa4e40d99312b6c98ac3f5260fb", "title": "Media bias and reputation", "year": "2006"}, {"id": "ee409021960573baf01e82d0b663ac6df6948030", "title": "Automated identification of media bias in news articles: an interdisciplinary literature review", "year": "2019"}, {"id": "7ece7d9e8dcee5fe66265a5c38388426e18dc08b", "title": "Media bias by the numbers: Challenges and opportunities in the empirical study of partisan news", "year": "2013"}, {"id": "a6aeff7bb06befe1775fa86f60179db2e793795d", "title": "What to believe? Social media commentary and belief in misinformation", "year": "2020"}, {"id": "134b65656d5e061c8c98332227503c407592aed6", "title": "Predicting factuality of reporting and bias of news media sources", "year": "2018"}, {"id": "14f8b9729b22fedcc0998fe655cd64a161c36388", "title": "Media bias monitor: Quantifying biases of social media news outlets at large-scale", "year": "2018"}, {"id": "629608f9fa7120cf60e1633241aa7948345ea86b", "title": "The prevalence, consequence, and remedy of misinformation in mass media systems", "year": "2015"}, {"id": "4b83afe6ba9f5ae808b6ddc183d213939a62f968", "title": "Birds of a feather are persuaded together: Perceived source credibility mediates the effect of political bias on misinformation susceptibility", "year": "2022"}, {"id": "db8afc1dd44eec875d8cbf0a850a498cf984463e", "title": "There is no liberal media bias in which news stories political journalists choose to cover", "year": "2020"}, {"id": "4c2a11b732584717c79c882fc1a5738e46d8680d", "title": "A minimalistic model of bias, polarization and misinformation in social networks", "year": "2020"}, {"id": "3e8f31e6ffce4cca3d6094a1691506a731f1a6d3", "title": "Emphasizing publishers does not effectively reduce susceptibility to misinformation on social media", "year": "Rand"}, {"id": "2457679e46cf6efa93f2fa42f03dd8a14f4c5096", "title": "The paradox of participation versus misinformation: Social media, political engagement, and the spread of misinformation", "year": "2019"}, {"id": "1dad69f1fd4403aed4d3d709ab794113291d625c", "title": "Fake news: spread of misinformation about urological conditions on social media", "year": "2020"}, {"id": "2c86c79c92d0c24e82eccea0b705c92a89d6c515", "title": "One bias fits all? Three types of media bias and their effects on party preferences", "year": "2017"}, {"id": "4fec6940d82a2ea9be4614f7561cf53408fbae79", "title": "Theories of media bias", "year": "2017"}, {"id": "e4fa93b6e9f0a6f5d8414340c9d90712364c4878", "title": "Emotions, partisanship, and misperceptions: How anger and anxiety moderate the effect of partisan bias on susceptibility to political misinformation", "year": "2015"}, {"id": "8a9e1b165df5bef22385a633647835c456b78e28", "title": "Digital media and misinformation: An outlook on multidisciplinary strategies against manipulation", "year": "2022"}], "2022.aacl-tutorials.6": [{"id": "8baae43106b43e52e26bbc7970f19f798ba7cfd2", "title": "A tour of explicit multilingual semantics: Word sense disambiguation, semantic role labeling and semantic parsing", "year": "2022"}, {"id": "b5b7870f1e565eaba21c056e64fcf4a279b4265b", "title": "XL-WSD: An extra-large and cross-lingual evaluation framework for word sense disambiguation", "year": "2021"}, {"id": "aa8774e0fd42c718f69ed46b9c1fa6dd79c32dc9", "title": "Semantic role labeling for knowledge graph extraction from text", "year": "2021"}, {"id": "ff627c5945b88cf723dbe0195b3f94c39d06298f", "title": "Cross-lingual word sense disambiguation using multilingual co-occurrence graphs", "year": "2022"}, {"id": "2d5192f1bce547ab4a90990d891fd231791dfc96", "title": "Train-o-matic: Supervised word sense disambiguation with no (manual) effort", "year": "2020"}, {"id": "9f673694e25c78baefe06a83177e7e70fd183a22", "title": "A Review of Algorithms, Datasets, and Criteria in Word Sense Disambiguation With a View to its Use in Islamic Texts", "year": "2020"}, {"id": "47434e86d2e32c307beebab6f5902ae9d060c824", "title": "Wikipedia-based WSD for multilingual frame annotation", "year": "2013"}, {"id": "d8354ae6babdc23f9c18471802f3f56cd8165adc", "title": "Word sense disambiguation based on context selection using knowledge-based word similarity", "year": "2021"}, {"id": "b4fad631c06f5f7172c41fe1a1af680e0869fef3", "title": "Wordnet and wiktionary-based approach for word sense disambiguation", "year": "2018"}, {"id": "b60f124d231253fcc8bccd95ab2912c2ff2000bf", "title": "Universal semantic annotator: the first unified API for WSD, SRL and semantic parsing", "year": "2022"}, {"id": "a2338507c437c34e4ed794099f72bed28d7be4ef", "title": "Knowledge-based word sense disambiguation using topic models", "year": "2018"}, {"id": "c7f496711c9473cde4a8cf19ead6526f55d71ef3", "title": "An overview on xml semantic disambiguation from unstructured text to semi-structured data: Background, applications, and ongoing challenges", "year": "2016"}, {"id": "fdd2aa4832e8a9f26746be13754bdd17871ada9e", "title": "Semantically-enriched parsing for natural language understanding", "year": "ratz"}, {"id": "c7f496711c9473cde4a8cf19ead6526f55d71ef3", "title": "An Overview on XML Semantic Disambiguation from Unstructured Text to Semi\u2010", "year": "data"}, {"id": null, "title": "KNOW: Developing large-scale multilingual technologies for language understanding TIN2006-15049-C03", "year": "ll\u00f3n"}, {"id": "f0d627125d0eb18e1eee21217e54550ad08e4e96", "title": "An integration model of semantic annotation based on synergetic neural network", "year": "2016"}, {"id": "2fe7c6c1bb727a8a71af2d2b4c328937c6ba0e1f", "title": "A survey of Thai knowledge extraction for the semantic web research and tools", "year": "2018"}, {"id": null, "title": "ROBUST SEMANTIC ROLE LABELING USING PARSING VARIATIONS AND SEMANTIC CLASSES Szu-ting Yi", "year": "lmer"}, {"id": "5279148d2182c3e091203afa200acdd8da1020f6", "title": "Combining semantic annotation of word sense & semantic roles: A novel annotation scheme for VerbNet roles on German language data", "year": "2016"}, {"id": "fe88ab6ecad3398ce2ec84cbd9cc8f668b219f84", "title": "Expanding the semantic knowledge of wordnet through semantic types and ufo", "year": "Le\u00e3o"}], "2022.acl-tutorials.2": [{"id": "be5bc3c7db79e7acc1fcc24b50d1dee887591296", "title": "Towards reproducible machine learning research in natural language processing", "year": "2022"}, {"id": "bb50e8c44e783ec626351ca7471e1ede6ea37600", "title": "Can reproducibility be improved in clinical natural language processing? A study of 7 clinical NLP suites", "year": "2021"}, {"id": "59e7ed6132ce9992a6790a0a179b9eed73959780", "title": "A systematic review of reproducibility research in natural language processing", "year": "2021"}, {"id": "7c9975fedb81929f0115f1fb1f7b7535121f8c4e", "title": "Reproducibility in computational linguistics: Is source code enough?", "year": "2022"}, {"id": "d4d0917b77242660b1d285e20a636e4e8acc8a64", "title": "Three dimensions of reproducibility in natural language processing", "year": "2018"}, {"id": "5f9e9abc7bb0292ba136e7d07620b1587622426c", "title": "Replicability of research in biomedical natural language processing: a pilot evaluation for a coding task", "year": "2016"}, {"id": "f0136661ccaceede73c5b8f8021a72a085e19269", "title": "A Metrological Perspective on Reproducibility in                         NLP*", "year": "2022"}, {"id": "bf65b40bfed6855101ab65d130209c8e79360c8b", "title": "Reproducibility in natural language processing: a case study of two R libraries for mining PubMed/MEDLINE", "year": "2016"}, {"id": "ecf189b8871403a3a4f646debe5139656c2a0f4c", "title": "Replicability analysis for natural language processing: Testing significance with multiple datasets", "year": "2017"}, {"id": "3cf13e7e55c833276f90ba7a1023667698e39784", "title": "Reproducibility in computational linguistics: Are we willing to share?", "year": "2018"}, {"id": "83c550e602a7cbabbdf8a157b6014458c1f8bc5a", "title": "Community perspective on replicability in natural language processing", "year": "2019"}, {"id": "833486871956be5812d81daddcbb7b1ed7c87154", "title": "Vision, status, and research topics of Natural Language Processing", "year": "2022"}, {"id": "a687eba9ff84ed2a8d7afb2e6017a8cf5b30e44b", "title": "Natural language processing algorithms for mapping clinical text fragments onto ontology concepts: a systematic review and recommendations for future studies", "year": "2020"}, {"id": null, "title": "NLP Community Perspectives on Replicability.", "year": "2019"}, {"id": "f628a947995d43b3e6e51a06bcd33badded0d22b", "title": "A systematic review of natural language processing applied to radiology reports", "year": "2021"}, {"id": "69ca13b8a7386f6e03a8d200d24a66509a16e6f7", "title": "Quantifying reproducibility in NLP and ML", "year": "2021"}, {"id": "22d59771dae574309fa74e98446b6df50472a107", "title": "Reproducibility issues for bert-based evaluation metrics", "year": "2022"}, {"id": null, "title": "ACL Tutorial Proposal: Towards Reproducible Machine Learning Research in Natural Language Processing", "year": "nha\u2026"}, {"id": "71162451372bdf01ece51d5a1c8a0c900c4fab62", "title": "Towards Efficient and Reproducible Natural Language Processing", "year": "odge"}, {"id": "11dc4afd054777c5308f374d952e4c3947db4bf1", "title": "Bringing replication and reproduction together with generalisability in NLP: Three reproduction studies for target dependent sentiment analysis", "year": "2018"}], "2022.acl-tutorials.4": [{"id": "38ecf2897db59134250923805cbdf9fb5948965b", "title": "Non-autoregressive sequence generation", "year": "2022"}, {"id": "bed87e8fb3e7e9bc87e1c2ee459ae405a35d3267", "title": "A study of non-autoregressive model for sequence generation", "year": "2020"}, {"id": "75fe6c3ffdea2608794b4f21119c5a4dec07663a", "title": "Flowseq: Non-autoregressive conditional sequence generation with generative flow", "year": "2019"}, {"id": "3dd6ceabc36725fa8f8debdaa4a87ec4e35e8c22", "title": "An em approach to non-autoregressive conditional sequence generation", "year": "2020"}, {"id": "626526868a9e9de5857112a2962d0b91ccd003eb", "title": "From Autoregressive to Non-Autoregressive: Studies on Text Generation in Neural Sequence Models", "year": "aidi"}, {"id": "d02d402cabe6d19649d823c4582028faf5667459", "title": "Non-autoregressive neural dialogue generation", "year": "2020"}, {"id": "399dd1ba62228d4723e16fcc70338e0ccee37665", "title": "Bang: Bridging autoregressive and non-autoregressive generation with large scale pretraining", "year": "2021"}, {"id": "f41739647288725831048998aee9d708851e9652", "title": "Non-autoregressive models for fast sequence generation", "year": "2022"}, {"id": "3e8f037d1b2c893f4df37deda1da3dcc577a8bac", "title": "Non-autoregressive text generation with pre-trained language models", "year": "2021"}, {"id": "7ac4227d0b4d38b16da27ed55bd53ce240a32404", "title": "A comparative study on non-autoregressive modelings for speech-to-text generation", "year": "2021"}, {"id": "7b52f0602dd67b93b865a4898ec22bfb500bc5bf", "title": "Improving non-autoregressive generation with mixup training", "year": "2021"}, {"id": "5ec0956ae95ccca151cda461411c29c08fa41f5c", "title": "Naomi: Non-autoregressive multiresolution sequence imputation", "year": "2019"}, {"id": "e89de16512d72d4e911e3b58ee08c73c62cb0d70", "title": "JANUS: Joint autoregressive and non-autoregressive training with auxiliary loss for sequence generation", "year": "2022"}, {"id": "128b6540b23cb8316edc496a2c532ea194dbf10e", "title": "Sequence-level training for non-autoregressive neural machine translation", "year": "2021"}, {"id": "3a25583c170d7b3eef568890ccffd8a500ac9b3e", "title": "POS-constrained parallel decoding for non-autoregressive generation", "year": "2021"}, {"id": "f6127bbe33d7e5776d3c313304b35d27e1051459", "title": "Non-autoregressive machine translation with latent alignments", "year": "2020"}, {"id": "8e23606793d4ce455302b110f50033c6e241d9aa", "title": "Non-autoregressive translation by learning target categorical codes", "year": "2021"}, {"id": "24a1767f6731abaeb21f8fa745b7e02fd4bbf39f", "title": "Understanding and improving lexical choice in non-autoregressive translation", "year": "2020"}, {"id": "2eaf36dc40fd9a61f8f0fad14a6d3c9594b1c2be", "title": "An effective non-autoregressive model for spoken language understanding", "year": "2021"}, {"id": "2b68036936596af716d529a8752a5b42edbf7251", "title": "Retrieving sequential information for non-autoregressive neural machine translation", "year": "2019"}], "2022.acl-tutorials.5": [{"id": "28e30b4b5cd511f64b3bb3d7d0f57e067b3977be", "title": "Data augmentation and semi-supervised learning for deep neural networks-based text classifier", "year": "2020"}, {"id": "b4cc976bd6fd45aa8ad91859a962d4b90ba580c3", "title": "On data-augmentation and consistency-based semi-supervised learning", "year": "2021"}, {"id": "147146e2d1ef03b41097ffc4a8589654de4379fb", "title": "Semi-supervised learning with data augmentation for end-to-end ASR", "year": "2020"}, {"id": "ae2c03cbe6162dadf65edd2ff7dfc5333524dca5", "title": "Mixtext: Linguistically-informed interpolation of hidden space for semi-supervised text classification", "year": "2020"}, {"id": "b19ccd9f37cad2933f8181f1aab02a3d074e6786", "title": "Semi-supervised models via data augmentationfor classifying interactive affective responses", "year": "2020"}, {"id": "f54316d6f112723d28e5bb1f98e5686345d8a0dc", "title": "Snippext: Semi-supervised opinion mining with augmented data", "year": "2020"}, {"id": "6d78ad8f84d486a27c6d1501803408fbfa276bd6", "title": "Classmix: Segmentation-based data augmentation for semi-supervised learning", "year": "2021"}, {"id": "0feea94f89d395436bf41bd10c797447eecbc128", "title": "Unsupervised data augmentation for consistency training", "year": "2020"}, {"id": "225cead7856726ab0c1143dbe480fc14f9b3dde4", "title": "A multi-stage semi-supervised learning approach for intelligent fault diagnosis of rolling bearing using data augmentation and metric learning", "year": "2021"}, {"id": "e603ee43573b14b9c228207637be9080b619a2fe", "title": "Local additivity based data augmentation for semi-supervised NER", "year": "2020"}, {"id": "31852f9fc732c0868af12d631c72693702d80521", "title": "Text data augmentation for deep learning", "year": "2021"}, {"id": "932d96bd28c3407576073943ce88dd1656e765ac", "title": "Semi-supervised text classification via self-pretraining", "year": "2021"}, {"id": "3b4fd630260685b500c50e40fd801b6689dca570", "title": "Featmatch: Feature-based augmentation for semi-supervised learning", "year": "2020"}, {"id": "068eb2019cbb91421b7746af38da5e4c82f5e89c", "title": "Remixmatch: Semi-supervised learning with distribution alignment and augmentation anchoring", "year": "2019"}, {"id": "988e9760019f2fdbf711453e235b58c6476a5c43", "title": "Semi-supervised learning and data augmentation in wearable-based momentary stress detection in the wild", "year": "2022"}, {"id": "46f9827024c3537b0b05dfdf4bbb14be82563d27", "title": "Toward text data augmentation for sentiment analysis", "year": "2021"}, {"id": "2a9e4ba46fbfc9221a388c12ca7a193304ee2d27", "title": "Improving short text classification through global augmentation methods", "year": "2020"}, {"id": "3778a925b682661df0e0d0e8ec7dfdcb80783bc5", "title": "Semi-supervised task-driven data augmentation for medical image segmentation", "year": "2021"}, {"id": "eb23e9a05943f4713bff1640f35ed3c821c93954", "title": "Salnet: Semi-supervised few-shot text classification with attention-based lexicon construction", "year": "2021"}, {"id": "0feea94f89d395436bf41bd10c797447eecbc128", "title": "Unsupervised data augmentation", "year": "2019"}], "2022.acl-tutorials.6": [{"id": "bcd1c612e340f1270fdaf0c0e3a6a499105ed682", "title": "Long-tail zero and few-shot learning via contrastive pretraining on and for small data", "year": "2022"}, {"id": "4e2db0bebbf82e1da4663ab6a12b7279c1132ac2", "title": "Review and analysis of zero, one and few shot learning approaches", "year": "2020"}, {"id": "91dc75f94da13452a54ad5c03fab2c5fda87e9ba", "title": "Uni-perceiver: Pre-training unified architecture for generic perception for zero-shot and few-shot tasks", "year": "2022"}, {"id": "be74c3871430bb749c6970d563dc40d1afa4b4ce", "title": "A unified approach for conventional zero-shot, generalized zero-shot, and few-shot learning", "year": "2018"}, {"id": "037110f8e99488f9b8f6e962da0a912d927695e5", "title": "Zero-and few-shot nlp with pretrained language models", "year": "2022"}, {"id": "e9ba6d5a95e1e51fa1e6110a9859ba63190d487a", "title": "Learning from Limited Labeled Data-Zero-Shot and Few-Shot Learning", "year": "Xian"}, {"id": "0ab41d455d676542b37ca1499bb19ea6a5d1cf79", "title": "Yuan 1.0: Large-scale pre-trained language model in zero-shot and few-shot learning", "year": "2021"}, {"id": "23c265ba884b92ecbd9d18641078d964697e4590", "title": "Generating training data with language models: Towards zero-shot language understanding", "year": "2022"}, {"id": "6c15605b4b77f970975757a875d349ba240f4caf", "title": "Scaling asr improves zero and few shot learning", "year": "2021"}, {"id": "29c19d1a93fdf47f5b5698a136496a324a25b629", "title": "A zero-shot learning approach to classifying requirements: A preliminary study", "year": "2022"}, {"id": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned language models are zero-shot learners", "year": "2021"}, {"id": "723ef11269253c3be978fbb4f4adaf46ef60099a", "title": "Few-shot zero-shot learning: Knowledge transfer with less supervision", "year": "2020"}, {"id": "528dc51f9c2bb4c771e886427b16cfc40cfa2ecc", "title": "Revisiting self-training for few-shot learning of language model", "year": "2021"}, {"id": "667995308dd238e75770b53affbc0591611a3b09", "title": "Learning from few examples: A summary of approaches to few-shot learning", "year": "2022"}, {"id": "2145fcceeb69385e108bf1796d52f974854d4c0b", "title": "Zerogen: Efficient zero-shot learning via dataset generation", "year": "2022"}, {"id": "ad10d6dec0b5855c3c3e71d334161647d6d4ed9e", "title": "Few-shot and zero-shot multi-label learning for structured label spaces", "year": "2018"}, {"id": "4b0ec90dc10e51c1fc983edcd57bb86636d7b3ca", "title": "Adapting language models for zero-shot learning by meta-tuning on dataset and prompt collections", "year": "2021"}, {"id": "b58d8579ece27a60432e667bfbdb750590fa65d9", "title": "True few-shot learning with language models", "year": "2021"}, {"id": null, "title": "Self-supervised contrastive zero to few-shot learning from small, long-tailed text data", "year": "tein"}, {"id": "3e56a9b6c6aced2cb14f9cd7f89d145851c44113", "title": "Zero and few shot learning with semantic feature synthesis and competitive learning", "year": "2020"}], "2022.acl-tutorials.8": [{"id": "f4d0476bd0c20dd1bd7dabcf457e3a8775adfa93", "title": "Natural language processing for multilingual task-oriented dialogue", "year": "2022"}, {"id": "22c8444eb4da5ae8d43829b127d5e7ee9950b151", "title": "Crossing the conversational chasm: A primer on multilingual task-oriented dialogue systems", "year": "2021"}, {"id": "d581a99af33b0faa37f2578a49a57451b8b444db", "title": "Cross-Lingual Transfer Learning for Arabic Task-Oriented Dialogue Systems Using Multilingual Transformer Model mT5", "year": "2022"}, {"id": "d29036946152bddf950fec7a08c2828a8a8f902e", "title": "Crossing the conversational chasm: A primer on natural language processing for multilingual task-oriented dialogue systems", "year": "2022"}, {"id": "9d296005633ee031b7252ff7a63ecb2303afcb04", "title": "Attention-informed mixed-language training for zero-shot cross-lingual task-oriented dialogue systems", "year": "2020"}, {"id": "c644956d5cfdb7ad7ea24a420608b9b58c148e3d", "title": "Cross-lingual transfer learning for multilingual task oriented dialog", "year": "2018"}, {"id": "5137fd738f1ccaee032db073427f17eec42c4a4c", "title": "GlobalWoZ: Globalizing MultiWoZ to develop multilingual task-oriented dialogue systems", "year": "2021"}, {"id": "88e5c6d4112953b5075043f0a44246fea3d4e3d5", "title": "Viwoz: A multi-domain task-oriented dialogue systems dataset for low-resource language", "year": "2022"}, {"id": "65723388e5efbfa2fa9431bb905e0e29e3851283", "title": "Low-Resource Natural Language Understanding in Task-Oriented Dialogue", "year": "uvan"}, {"id": "49c46839bdfa433c84a8e4158b9344d79bc1dc49", "title": "Zero-shot cross-lingual dialogue systems with transferable latent variables", "year": "2019"}, {"id": "cbe411a0684233f525da5bb91ce427324c652c1b", "title": "AllWOZ: Towards multilingual task-oriented dialog systems for all", "year": "2021"}, {"id": "a1e24034405bc927982e6bf44c950e8cdb5dd067", "title": "AraConv: Developing an Arabic task-oriented dialogue system using multi-lingual transformer model mT5", "year": "2022"}, {"id": "6f5545084dbed93ef65a19cfa116f43ddeb3fbea", "title": "Task-oriented dialog systems for dravidian languages", "year": "2021"}, {"id": "54ff60be70b36286e288f6d62bc1feb054e95b7e", "title": "Contextual semantic parsing for multilingual task-oriented dialogues", "year": "2021"}, {"id": "2c5dc70fda65c1a52208041120883f5abce0d205", "title": "Bitod: A bilingual multi-domain dataset for task-oriented dialogue modeling", "year": "2021"}, {"id": "a8a168d53e01b0c35d626cfced103656e22b8343", "title": "MTOP: A comprehensive multilingual task-oriented semantic parsing benchmark", "year": "2020"}, {"id": "c9ec368b5814eb68d125240fb1cdc809f65a9584", "title": "Building a Task-oriented Dialog System for languages with no training data: the Case for Basque", "year": "2020"}, {"id": "2274334d300c619b95258fa599a0e630a073ae52", "title": "Mdia: A benchmark for multilingual dialogue generation in 46 languages", "year": "2022"}, {"id": "fa349e881c72825a8082a1c80e85583dba6d2840", "title": "Cross-lingual intermediate fine-tuning improves dialogue state tracking", "year": "2021"}, {"id": "5423ca2e003575bd277fb1a878d5bcfd26aa1463", "title": "Survey on dialogue systems including slavic languages", "year": "2022"}], "2022.emnlp-tutorials.1": [{"id": "35751e6410682b4629ec79250f96cd7474196a27", "title": "Natural language processing", "year": "2020"}, {"id": "d9dc7d27ad31e977dec4f703bc75f699ae456f76", "title": "From discourse to logic: Introduction to modeltheoretic semantics of natural language, formal logic and discourse representation theory", "year": "eyle"}, {"id": "2a4e915fda85287f6165c04769dcc9ce92cdac98", "title": "Mental spaces: Aspects of meaning construction in natural language", "year": "nier"}, {"id": "de4961a6431b9553d9f13319236570a9f033fcab", "title": "Understanding natural language", "year": "1972"}, {"id": "b58e206b25ffac9acdf4a9a045d6c6775fc34feb", "title": "A computational approach to fuzzy quantifiers in natural languages", "year": "1983"}, {"id": "26be1ec883c0e67f641931451f3fb68b90f9b501", "title": "Meaning and mental representation", "year": "mins"}, {"id": "e72e5ee5de14fd463ab58ce830474157258e3578", "title": "Abstract meaning representation for sembanking", "year": "2013"}, {"id": "708cd8b44d99198f902371383951965ce27a109b", "title": "Natural language understanding", "year": "llen"}, {"id": "9961401655f8e235ef01deb9c19528de300e8840", "title": "The Basic Variety (or: Couldn't natural languages be much simpler?)", "year": "1997"}, {"id": "2932a16f87dd9bad2cc59145a8263239c6a9cfcc", "title": "Conceptual dependency: A theory of natural language understanding", "year": "1972"}, {"id": "abd0d4ed53a86f7af4674b838d590edff6edf9a4", "title": "Natural language processing: an introduction", "year": "2011"}, {"id": "745b14e17bd4e065e14a951452523f0b2dcee008", "title": "Bilateral brain processes for comprehending natural language", "year": "2005"}, {"id": "c6f913bd5bdea4e14994e848504a67128f2838c8", "title": "A survey of category types in natural language", "year": "2014"}, {"id": "39e53f9a52ffc9745102e6774f204f067ecae852", "title": "Languages and language", "year": "ewis"}, {"id": "dbe79abbbc1fc7df6ce90d263a363d99fabd3489", "title": "Natural language and natural selection", "year": "1990"}, {"id": "8862c1760476de1cf859e2a59998231e18e33317", "title": "Generalized quantifiers and natural language", "year": "1981"}, {"id": "7c508a74436d9a790b0473dece6501f1a0266ca4", "title": "Logics and languages", "year": "well"}, {"id": "72fbcf197491a7dc45f9a1d6bcc8fbcc772745ff", "title": "Representation and reality", "year": "tnam"}, {"id": "b724783ffa9d9baea948107421baf9ba16e5bbd0", "title": "Pragmatics and natural language understanding", "year": "reen"}, {"id": "58daf6d9444631708e7328689396d0480056eeed", "title": "An overview of KRL, a knowledge representation language", "year": "1977"}], "2022.emnlp-tutorials.4": [{"id": "130d432ccbc836380a212bea618f84ff094a6a52", "title": "Causal inference in natural language processing: Estimation, prediction, interpretation and beyond", "year": "2022"}, {"id": "2ed86532195c068d02c4e3bdcbcd6e249d4d72dd", "title": "Extracting health-related causality from twitter messages using natural language processing", "year": "2019"}, {"id": "cd9e1e325d0666c0621300d8b70333f9b856e57b", "title": "Identifying causality and contributory factors of pipeline incidents by employing natural language processing and text mining techniques", "year": "2021"}, {"id": "26d59f05c74e1888ab73f6a139cd23391fae6bf7", "title": "Identification of Causal Dependencies by using Natural Language Processing: A Survey.", "year": "2019"}, {"id": "0b031700fd4fb450ee7fabbd2120900e73c95c54", "title": "CausalNLP tutorial: An introduction to causality for natural language processing", "year": "2022"}, {"id": "71efcaaa2ab0e99b4e1d1df43f71b043138e1288", "title": "Using natural language processing to extract health-related causality from Twitter messages", "year": "2018"}, {"id": "dc551a804c50cc9f1952926ae4a6365db61d8fc4", "title": "A survey on extraction of causal relations from natural language text", "year": "2022"}, {"id": "6c029de0269a32947ac7368ba13e2dad41afb85f", "title": "Causality mining in natural languages using machine and deep learning techniques: A survey", "year": "2021"}, {"id": "e15c7538417486417cf1e8408cc06073d8b76f27", "title": "Causal BERT: Language models for causality detection between events expressed in text", "year": "2020"}, {"id": "19cb6142ba2e2cc252c6440928c39a7057beb79b", "title": "Causal knowledge extraction by natural language processing in material science: a case study in chemical vapor deposition", "year": "2006"}, {"id": "35751e6410682b4629ec79250f96cd7474196a27", "title": "Natural language processing", "year": "2020"}, {"id": "508ff1a8d87011ee35ffde1b8c37301b777a6e20", "title": "Cebab: Estimating the causal effects of real-world concepts on nlp model behavior", "year": "2022"}, {"id": "42d3c15db60277114572c6003220f07737cec8ee", "title": "Knowledge-oriented convolutional neural network for causal relation extraction from natural language texts", "year": "2019"}, {"id": "24b09c4ec25f5ee72301cce909e9b13eed88fa37", "title": "Extracting causal claims from information systems papers with natural language processing for theory ontology learning", "year": "mann"}, {"id": "abdcbc579a9b63d19bda86569e220a54e4dad1ba", "title": "Causal direction of data collection matters: Implications of causal and anticausal learning for NLP", "year": "2021"}, {"id": "e115ec4c138cc5157ab24a6e462f1fc74902d53f", "title": "Automatic extraction of causal relations from natural language texts: a comprehensive survey", "year": "2016"}, {"id": "e15c7538417486417cf1e8408cc06073d8b76f27", "title": "Causal bert: Language models for causality detection between events expressed in text", "year": "2022"}, {"id": "ba896474f2e2ca3384f20595ea56da2afb03254d", "title": "A survey of the extraction and applications of causal relations", "year": "2022"}, {"id": "3d55559e93a54c5ae5ce8bd780559dd152205746", "title": "Towards causality extraction from requirements", "year": "2020"}, {"id": "33af8451a46a9592689d5aa1270ec73b7779c954", "title": "Challenges of using text classifiers for causal inference", "year": "2018"}], "2022.emnlp-tutorials.6": [{"id": "f41739647288725831048998aee9d708851e9652", "title": "Non-autoregressive models for fast sequence generation", "year": "2022"}, {"id": "bed87e8fb3e7e9bc87e1c2ee459ae405a35d3267", "title": "A study of non-autoregressive model for sequence generation", "year": "2020"}, {"id": "38ecf2897db59134250923805cbdf9fb5948965b", "title": "Non-autoregressive sequence generation", "year": "2022"}, {"id": "3dd6ceabc36725fa8f8debdaa4a87ec4e35e8c22", "title": "An em approach to non-autoregressive conditional sequence generation", "year": "2020"}, {"id": "399dd1ba62228d4723e16fcc70338e0ccee37665", "title": "Bang: Bridging autoregressive and non-autoregressive generation with large scale pretraining", "year": "2021"}, {"id": "75fe6c3ffdea2608794b4f21119c5a4dec07663a", "title": "Flowseq: Non-autoregressive conditional sequence generation with generative flow", "year": "2019"}, {"id": "7ac4227d0b4d38b16da27ed55bd53ce240a32404", "title": "A comparative study on non-autoregressive modelings for speech-to-text generation", "year": "2021"}, {"id": "7b52f0602dd67b93b865a4898ec22bfb500bc5bf", "title": "Improving non-autoregressive generation with mixup training", "year": "2021"}, {"id": "fe2f254923c72958fb65e025adf38ec6403dd6f8", "title": "Fast structured decoding for sequence models", "year": "2019"}, {"id": "a2b00396b893740c445fdad3c62eeb645817611c", "title": "Thinking clearly, talking fast: Concept-guided non-autoregressive generation for open-domain dialogue systems", "year": "2021"}, {"id": "3e8f037d1b2c893f4df37deda1da3dcc577a8bac", "title": "Non-autoregressive text generation with pre-trained language models", "year": "2021"}, {"id": "e89de16512d72d4e911e3b58ee08c73c62cb0d70", "title": "JANUS: Joint autoregressive and non-autoregressive training with auxiliary loss for sequence generation", "year": "2022"}, {"id": "56f8d65c1ac506ea6d3f6d14e0de2915db9660e0", "title": "Non-autoregressive model for full-line code completion", "year": "2022"}, {"id": "1af8aa333d7b64417240e7697f15034a3457d86c", "title": "FastLR: Non-autoregressive lipreading model with integrate-and-fire", "year": "2020"}, {"id": "fef3306cde15db70f9f852f2bb7d1020059a6363", "title": "Non-autoregressive sequence-to-sequence voice conversion", "year": "2021"}, {"id": null, "title": "Non-autoregressive transformer-based end-to-end ASR using BERT", "year": "2021"}, {"id": "451e0631157aaa37fa3f5b5ef4c87c929c68f255", "title": "VAENAR-TTS: Variational auto-encoder based non-autoregressive text-to-speech synthesis", "year": "2021"}, {"id": "5850c94c9826bbc4e54bcaaee8a9b9109c76cac4", "title": "Learning non-autoregressive models from search for unsupervised sentence summarization", "year": "2022"}, {"id": "fc8419011623f2eb371b07ba8f4cf9c7b34dbcd6", "title": "Fasts2s-vc: Streaming non-autoregressive sequence-to-sequence voice conversion", "year": "2021"}, {"id": "ca4ba244fc83b664902f7dd3fe6a7d429ba50f28", "title": "Non-autoregressive vs autoregressive neural networks for system identification", "year": "2021"}], "2022.naacl-tutorials.1": [{"id": "fe35bf433202b4e130709d042aae09dbf4d76232", "title": "Text generation with text-editing models", "year": "2022"}, {"id": "8c881df7a42e6798bf69b6ecb26b9d0792a378e7", "title": "FELIX: Flexible text editing through tagging and insertion", "year": "2020"}, {"id": "aac0751b772b9472b316544ead106caf93f89761", "title": "An imitation learning curriculum for text editing with non-autoregressive models", "year": "2022"}, {"id": "626526868a9e9de5857112a2962d0b91ccd003eb", "title": "From Autoregressive to Non-Autoregressive: Studies on Text Generation in Neural Sequence Models", "year": "aidi"}, {"id": "fd90d2d2853c5b550eab7db203db9f4e7e5a2aaa", "title": "LEWIS: Levenshtein editing for unsupervised text style transfer", "year": "2021"}, {"id": "1f95641726dc6875a7f6a89c1d8b0ee414bd4b52", "title": "Recurrent inference in text editing", "year": "2020"}, {"id": null, "title": "Text Summarization Beyond Seq2Seq Models for Salience, Faithfulness, and Factuality", "year": "Dong"}, {"id": "4f985c255a4a0cf76e7bc3c4bd91f16eda0ee9c3", "title": "Copy that! editing sequences by copying spans", "year": "2021"}, {"id": "60bff5a4527141599d8e05904baf96410541f8a9", "title": "Learning to model editing processes", "year": "2022"}, {"id": "1e411c5e2fe44529a4033a2121adeecc60a7b409", "title": "Xl-editor: Post-editing sentences with xlnet", "year": "2019"}, {"id": "1a5cc4e66d50a21289799373876334385456b9fa", "title": "Response generation by context-aware prototype editing", "year": "2019"}, {"id": "35d41884d23a177d09352941bc075b53740ddfad", "title": "Deep interactive text prediction and quality estimation in translation interfaces", "year": "kamp"}, {"id": "2da2a44f78e1bd9735d94fee3bd944d47d45742b", "title": "Step-unrolled denoising autoencoders for text generation", "year": "2021"}, {"id": "f823cec3fe16ee2567d452c1437a545e326f789d", "title": "Text2Video: automatic video generation based on text scripts", "year": "2021"}, {"id": "38ecf2897db59134250923805cbdf9fb5948965b", "title": "Non-autoregressive sequence generation", "year": "2022"}, {"id": null, "title": "Innovations in neural data-to-text generation: A Survey", "year": "2022"}, {"id": "492567fd5599d36be6d2eb496860c7de8ce9a014", "title": "Improving grammatical error correction models with purpose-built adversarial examples", "year": "2020"}, {"id": null, "title": "Blank Language Model: flexible sequence modeling by any-order generation", "year": "uach"}, {"id": "72024eef4198f88130ba3b8823bdbda9168cc493", "title": "Controlling text edition by changing answers of specific questions", "year": "2021"}, {"id": "e492e2f6e54982fddc4e8d5448362ce890d57c31", "title": "Heterogeneous recycle generation for Chinese grammatical error correction", "year": "2020"}], "2022.naacl-tutorials.2": [{"id": "0799a165b7cdb0209fee1456664806e2f266584c", "title": "Self-supervised representation learning for speech processing", "year": "2022"}, {"id": "b257038ef379092509b1dd1d66a351f47363d6eb", "title": "Lebenchmark: A reproducible framework for assessing self-supervised representation learning from speech", "year": "2021"}, {"id": "f76a5b176f3435214eb87dd105f730f0b53672c3", "title": "Self-supervised speech representation learning: A review", "year": "2022"}, {"id": "aa62d5e43cb151cd574e4df058b4c6a509d62644", "title": "Self-supervised representation learning: Introduction, advances, and challenges", "year": "2022"}, {"id": "b5002aa334f8d0c0e1a4dedad79580e10a928c30", "title": "Combining spectral and self-supervised features for low resource speech recognition and translation", "year": "2022"}, {"id": "25ceeabb654050668caffa77a3586de13d8ecb97", "title": "The effectiveness of self-supervised representation learning in zero-resource subword modeling", "year": "2021"}, {"id": "b5cf5453769ae9cf6c7d9d961325f61feeb7c6a7", "title": "Pretext tasks selection for multitask self-supervised audio representation learning", "year": "2022"}, {"id": null, "title": "Promises and Limitations of Self-supervised Learning for Automatic Speech Processing", "year": "2022"}, {"id": "a7d61ab4a3442fd2382f6c11f991421c0d98674a", "title": "Layer-wise analysis of a self-supervised speech representation model", "year": "2021"}, {"id": "8ff49158f72786e1be1e803d7a6a81022a1bc7c3", "title": "Semi-supervised transfer learning for language expansion of end-to-end speech recognition models to low-resource languages", "year": "2021"}, {"id": "69585ea1d23cf9ac32a56aa45f70371e6e069414", "title": "Task agnostic and task specific self-supervised learning from speech with lebenchmark", "year": "2021"}, {"id": "7113b75c9921b0696e8a0c09622d07071ec04ae2", "title": "Delores: Decorrelating latent spaces for low-resource audio representation learning", "year": "2022"}, {"id": "7f361bd386aa2f259f1ffcbd59709398b71c9549", "title": "ScoutWav: Two-step fine-tuning on self-supervised automatic speech recognition for low-resource environments", "year": "lmaz"}, {"id": "4efd37bd63626f2408b4c118be6bb38a509b4a88", "title": "An Experimental Comparison between Low-Resource Semi-Supervised and High-Resource Supervised Automatic Speech Recognition Models", "year": "2022"}, {"id": "eb3bc9488ab2cb553bd55ed6955a0ae82e639cfd", "title": "Self-supervised learning with segmental masking for speech representation", "year": "2022"}, {"id": "2eba956d63835c474955767ea458b3729472ade4", "title": "Improving self-supervised learning for speech recognition with intermediate layer supervision", "year": "2022"}, {"id": "eae79ce95fa5b5d84ee0a1234b4776829683d267", "title": "Self-supervised pre-trained speech representation based end-to-end mispronunciation detection and diagnosis of Mandarin", "year": "2022"}, {"id": "c7072213e06f41bbbba82769df7bdadeb80a3def", "title": "Deploying self-supervised learning in the wild for hybrid automatic speech recognition", "year": "2022"}, {"id": null, "title": "II proposes a general SSL framework. Section III describes the proposed methods for better improving low-resource ASR tasks with SSL pretrained models\u00a0\u2026", "year": "2022"}, {"id": null, "title": "Dutch dysarthric speech recognition: Applying self-supervised learning to overcome the data scarcity issue", "year": "hima"}], "2022.naacl-tutorials.3": [{"id": "0eb35b498e3e9d5b51e5d7f9435206b99ce22505", "title": "An analytical study of information extraction from unstructured and multidimensional big data", "year": "2019"}, {"id": "b389f649ce9e1a967841b2cf8e6dbe81fe10cfaa", "title": "Information extraction", "year": "2008"}, {"id": "b7d51663983b3910ec4007a38ee397431bd44730", "title": "Limitations of information extraction methods and techniques for heterogeneous unstructured big data", "year": "2019"}, {"id": "b3a558bcb1dafb26d2c4a02fd3b29ff4f6774ced", "title": "Information extraction: Past, present and future", "year": "2013"}, {"id": "63e5967d88873037bd1dc3485a3ddab20b56859f", "title": "Information extraction", "year": "1996"}, {"id": "5ccd0c109a3ae9c35e8a1ced364f75d340992996", "title": "Automatic spatiotemporal and semantic information extraction from unstructured geoscience reports using text mining techniques", "year": "2020"}, {"id": "41a441ce0081c8a829a982dc19c60131bfbde046", "title": "Mining knowledge from text using information extraction", "year": "2005"}, {"id": "ef76646912d675c987af5c0fe6bd06f40886ff0d", "title": "Adaptive information extraction", "year": "2006"}, {"id": "ef33f662563b094fcd258168d93c898c93de5613", "title": "Domain analysis of information extraction techniques", "year": "2018"}, {"id": "f84fc762a3229f436f2a472bd90ef5070b5d31fb", "title": "Clinical information extraction applications: a literature review", "year": "2018"}, {"id": "ae8c331e091ba27e2671cdc63c44982b9fe66e98", "title": "Information extraction meets the semantic web: a survey", "year": "2020"}, {"id": "fc4672da234dd8ffcba0b6b88fcab9853def266c", "title": "Information extraction from scientific articles: a survey", "year": "2018"}, {"id": "98bb75dcb7dfe8e675781fe2008170e8f00a5dee", "title": "Feverous: Fact extraction and verification over unstructured and structured information", "year": "2021"}, {"id": "8a9e25a9946efc09ec61f9d77a0f7e94630f015c", "title": "Learning to extract information from semi-structured text using a discriminative context free grammar", "year": "2005"}, {"id": "b389f649ce9e1a967841b2cf8e6dbe81fe10cfaa", "title": "Information extraction", "year": "2009"}, {"id": "88ddea93a98bae235af462d2b93ad6e6a703f742", "title": "EliIE: An open-source information extraction system for clinical trial eligibility criteria", "year": "2017"}, {"id": "0578dfb2a28b77abde19b32de777e0365df3020e", "title": "Data-driven materials research enabled by natural language processing and information extraction", "year": "2020"}, {"id": "c98aa28295c3ee30e73e261285ee9b557aa742f6", "title": "Information extraction: Methodologies and applications", "year": "2008"}, {"id": "15a8f2b51b5a8db739818c63a2d54c18abda92b0", "title": "Rule-Based Information Extraction for Structured Data Acquisition using TextMarker.", "year": "2008"}, {"id": "2f84d8f7afbd5d0b47bada8f595785c2331022d5", "title": "Using wikipedia to bootstrap open information extraction", "year": "2009"}], "2022.naacl-tutorials.5": [{"id": "6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91", "title": "Multimodal machine learning: A survey and taxonomy", "year": "2018"}, {"id": "63f93a6d9c38d656933706acfc720684470bc108", "title": "Foundations and Trends in Multimodal Machine Learning: Principles, Challenges, and Open Questions", "year": "2022"}, {"id": "d034042170ec11588b293512ee5e5bc2eaf5e82d", "title": "Multi-source heterogeneous data fusion", "year": "2018"}, {"id": "c49eab0a53473568098b12f0ffdc4469bcf19339", "title": "Multimodal deep learning for biomedical data fusion: a review", "year": "2022"}, {"id": "9dc1b06836ef20c3ae6775b70664422849f3dd13", "title": "Estimation of missing values in heterogeneous traffic data: Application of multimodal deep learning model", "year": "2020"}, {"id": "ab8fa3a8de5440c3a6d1043c83028314197c7803", "title": "Multimodal machine learning in precision health: A scoping review", "year": "2022"}, {"id": "a0022ee86e99981f0cde48fb4258b8ae21b96c6e", "title": "Harnessing multimodal data integration to advance precision oncology", "year": "2022"}, {"id": "4b8f5c922932377dd21d804183c2a870b6d628bc", "title": "Multimodal co-learning: Challenges, applications with datasets, recent advances and future directions", "year": "2022"}, {"id": "4c7c70760029e813ef76ea5a578174d2d3ec1490", "title": "A survey on deep learning for multimodal data fusion", "year": "2020"}, {"id": "3935f33c56070dd92dcbc009817699f425d165d6", "title": "Multimodal data integration using machine learning improves risk stratification of high-grade serous ovarian cancer", "year": "2022"}, {"id": "2dabebdca6b3211c3950be2c4a8c9b39b8637ece", "title": "Deep learning in multimodal remote sensing data fusion: A comprehensive review", "year": "2022"}, {"id": "2a9b33f66ccc3806af58bdab2319559f4f9d2c5e", "title": "A survey on deep multimodal learning for computer vision: advances, trends, applications, and datasets", "year": "2022"}, {"id": "64bfeb1ddd35838706e4fffc469234cc2f215631", "title": "Improved multimodal deep learning with variation of information", "year": "2014"}, {"id": "c192c7d1d94e7a64de7e18e2f2fdffbf2909fcff", "title": "Deep multimodal representation learning: A survey", "year": "2019"}, {"id": "3829607559475bbf15c66850810a497eac1a26e1", "title": "Learn to combine modalities in multimodal deep learning", "year": "2018"}, {"id": "cb5bf23d57d56e9029b42cfdd5ca8786b3c4ef00", "title": "Heterogeneous feature selection with multi-modal deep neural networks and sparse group lasso", "year": "2015"}, {"id": "6ad9a621cbe1bcf2bcf3fa7d60943feb05a185b3", "title": "Multimodal data as a means to understand the learning experience", "year": "2019"}, {"id": "034f1c5589644a6b42f50bf61b1628a1c5607fd9", "title": "Learning factorized multimodal representations", "year": "2018"}, {"id": "dc28434a6d10ae9b151dce1fed9591ddfcaf2b81", "title": "Artificial intelligence for multimodal data integration in oncology", "year": "2022"}, {"id": "e5822c78e94e53fb56094fc443bb1c650168d014", "title": "Emotion recognition using multi-modal data and machine learning techniques: A tutorial and review", "year": "2020"}], "2022.naacl-tutorials.6": [{"id": "fc2f16d2f1b0552524bd533de54779da9c9cab66", "title": "Contrastive data and learning for natural language processing", "year": "2022"}, {"id": "4d1ab60f309629241a00b71190d338ab27c40170", "title": "Supporting clustering with contrastive learning", "year": "2021"}, {"id": "ff5c0e3e23a79fbcca95aa6dba1ec7ba71baf204", "title": "Unsupervised sentence representation via contrastive learning with mixing negatives", "year": "2022"}, {"id": "021bbcefc993c389bad6c1daefd8ff92d0fc2441", "title": "Contrastive code representation learning", "year": "2020"}, {"id": "efbc94690cf2ebd935ef7a13cd2e378758aedb12", "title": "Auto-mlm: Improved contrastive learning for self-supervised multi-lingual knowledge retrieval", "year": "2022"}, {"id": "4b2af8e5da894a72f6236ab9347753760cfea7fd", "title": "Sequence level contrastive learning for text summarization", "year": "2022"}, {"id": "bcd1c612e340f1270fdaf0c0e3a6a499105ed682", "title": "Long-tail zero and few-shot learning via contrastive pretraining on and for small data", "year": "2022"}, {"id": "7b00dcca92337be90a4c4c100a5704dc1932c303", "title": "Contrastive learning with adversarial perturbations for conditional text generation", "year": "2020"}, {"id": "18fa0ef4dab744853f501977cbccee5d76823b9b", "title": "Uctopic: Unsupervised contrastive learning for phrase representations and topic mining", "year": "2022"}, {"id": "a8c48ecd6aac3130f300345cb451c6ed68d2cc50", "title": "Pretraining with contrastive sentence objectives improves discourse performance of language models", "year": "2020"}, {"id": "52ff1df0a516aa91864903fbc544c04132f3731f", "title": "Surrogate-and invariance-boosted contrastive learning for data-scarce applications in science", "year": "2022"}, {"id": "cc11842d0a979d3616c3423d20d287b04626dc50", "title": "Unsupervised contrastive learning based transformer for lung nodule detection", "year": "2022"}, {"id": "0abb08c4ec5feab4cdd82c471866dd4395c573ce", "title": "Contrastive distillation on intermediate representations for language model compression", "year": "2020"}, {"id": "0dd7f3a8c650fd90408b24af73886440ee6fdd75", "title": "ConOffense: Multi-modal multitask Contrastive learning for offensive content identification", "year": "2021"}, {"id": "35aafcd14ba110c1b6c42e2096a7f8da1a59564d", "title": "C4: Contrastive cross-language code clone detection", "year": "2022"}, {"id": "dcaf0e8a45a674212be769c3944cb7f7c1fc3843", "title": "Contrastive self-supervised sequential recommendation with robust augmentation", "year": "2021"}, {"id": "038cfae98e75be6f4a94a08284e519c619c7d81d", "title": "Supervised contrastive learning for game-play frustration detection from speech", "year": "2021"}, {"id": "a99f26f191dc3d93ad611c84db5ce8d272595355", "title": "CLASSIC: Continual and contrastive learning of aspect sentiment classification tasks", "year": "2021"}, {"id": null, "title": "Contrastive pre-training for zero-shot information retrieval", "year": "del\u2026"}, {"id": "cd2f3398727bf3d5ccef42b33ad9097aeb1c44f1", "title": "xMoCo: Cross momentum contrastive learning for open-domain question answering", "year": "2021"}], "2023.acl-tutorials.1": [{"id": "ae0ea06b05a19e11f5a85bdb1eb5553b8580ad96", "title": "Conversational ai: The science behind the alexa prize", "year": "2018"}, {"id": "6ebfbc954b9975d2f2651f380b9bdf46ae963178", "title": "PLATO: Pre-trained dialogue generation model with discrete latent variable", "year": "2019"}, {"id": "1298dae5751fb06184f6b067d1503bde8037bdb7", "title": "Deep reinforcement learning for dialogue generation", "year": "2016"}, {"id": "74fba846ff1733cdc05375af73e6c8cb434264fd", "title": "A survey on conversational agents/chatbots classification and design techniques", "year": "2019"}, {"id": "087c1449483d2e8a784f2acbd3847690403352fc", "title": "Augmenting end-to-end dialogue systems with commonsense knowledge", "year": "2018"}, {"id": "8384387a3739280b15d38f39429aadb7c9bd620f", "title": "Knowledge-aware multimodal dialogue systems", "year": "2018"}, {"id": "176f1d608b918eec8dc4b75e7b6e0acaba84a447", "title": "Adversarial learning for neural dialogue generation", "year": "2017"}, {"id": "14597394f68463424c52fbb565c61b096434b3e1", "title": "Survey on evaluation methods for dialogue systems", "year": "2021"}, {"id": "ba49d3823d43515e447296ca4e1e55d3f1fd8c4d", "title": "Neural responding machine for short-text conversation", "year": "2015"}, {"id": "a6401e102c03a441992b3e45f7b63eec09d4b89d", "title": "A survey on dialogue systems: Recent advances and new frontiers", "year": "2017"}, {"id": "0d3c68c207fc83fb402b7217811af22066300fc9", "title": "Opendialkg: Explainable conversational reasoning with attention-based walks over knowledge graphs", "year": "2019"}, {"id": "cab5fbb2b1c245e1d99542e8ef54e4faf846e3da", "title": "Conversational query understanding using sequence to sequence modeling", "year": "2018"}, {"id": "677aadb8171bd0633f465abe86ee3121abf407aa", "title": "Towards deep conversational recommendations", "year": "2018"}, {"id": "01ec011977fc6cda03e8b447e1b5eb0551f1c961", "title": "A simple language model for task-oriented dialogue", "year": "2020"}, {"id": null, "title": "Spoken dialogue technology: enabling the conversational user interface", "year": "2002"}, {"id": "674b6321ae1d12c83f28ade1850a27256c20f0d4", "title": "Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset", "year": "2020"}, {"id": "89e65078d37d076627818d9dba2c8ca9bf8f66bc", "title": "Challenges in building intelligent open-domain dialog systems", "year": "2020"}, {"id": "28e49f28ea5202990cce701332fc3099507d8404", "title": "A knowledge-grounded neural conversation model", "year": "2018"}, {"id": "ab8c725e04fc25dc03e96332e4490573cd87abd8", "title": "Evaluating natural language understanding services for conversational question answering systems", "year": "2017"}, {"id": "c91b4b3a20a7637ecbb7e0179ac3108f3cf11880", "title": "Multi-turn response selection for chatbots with deep attention matching network", "year": "2018"}], "2023.acl-tutorials.2": [{"id": "c23d9d44e8bc68408cea9f305d1f24d915bc0d0d", "title": "Recent advances in natural language processing via large pre-trained language models: A survey", "year": "2023"}, {"id": "290867638c5ca520de5c48aa4336f196d426c226", "title": "Knowledge enhanced pretrained language models: A compreshensive survey", "year": "2021"}, {"id": "a26623d52d24e03044a158cddad931ec5ab7304c", "title": "A survey of knowledge enhanced pre-trained language models", "year": "2023"}, {"id": "a2c44f0b729740c5e0aadff833f8031919cf75a8", "title": "A study of pre-trained language models in natural language processing", "year": "2020"}, {"id": "6c761cfdb031701072582e434d8f64d436255da6", "title": "Ammus: A survey of transformer-based pretrained models in natural language processing", "year": "2021"}, {"id": "a6e39438f766a4df502d6922c7f253398af60c14", "title": "Pre-trained language models and their applications", "year": "2022"}, {"id": "019fdc56ee141db759049f7f5db513615f7342cb", "title": "A survey of pretrained language models", "year": "2022"}, {"id": "b5148f8324570a845a7ae9a5843102d0693d006f", "title": "A survey of knowledge enhanced pre-trained models", "year": "2021"}, {"id": "6b80f9576423ee99242374f185b914065dd99429", "title": "Large language models versus natural language understanding and generation", "year": "2023"}, {"id": "02033e83ff310f35e4623bd339982c52d926f2d5", "title": "Chatgpt is not enough: Enhancing large language models with knowledge graphs for fact-aware language modeling", "year": "2023"}, {"id": "11c3c9004c30faed9e2b8d5b5794157785f5337f", "title": "On the effectiveness of pre-trained language models for legal natural language processing: An empirical study", "year": "2022"}, {"id": "7f84d56fb8feb4e50cd6c3da3e3fd4ff6c4772cf", "title": "Eliteplm: an empirical study on general language ability evaluation of pretrained language models", "year": "2022"}, {"id": "2fab75cfd8394de70bca365572bc5bb04a1b1eb5", "title": "DKPLM: decomposable knowledge-enhanced pre-trained language model for natural language understanding", "year": "2022"}, {"id": "349a080b4649e6ea8440178cde6e72b448fcc951", "title": "Foundation models for natural language processing: Pre-trained language models integrating media", "year": "bach"}, {"id": "2c5460afa19ad6fc2568b7e210115acacc14a40c", "title": "An overview on language models: Recent developments and outlook", "year": "2023"}, {"id": "f5d1dbdaa6c8a44f388f3f7fe538403baefc1252", "title": "Large pre-trained language models contain human-like biases of what is right and wrong to do", "year": "2022"}, {"id": "5eab810cc5d90de1c52127d1a5824f0817f46c30", "title": "Natural language reasoning, a survey", "year": "2023"}, {"id": "a35d5aeba08cccdc5cdf26bc094ccd71d06bdc99", "title": "Exploring generalization ability of pretrained language models on arithmetic and logical reasoning", "year": "2021"}, {"id": "b15469d0ab3dc3a9dec037d761817b3fe546bed6", "title": "Pre-trained language models in biomedical domain: A systematic survey", "year": "2023"}, {"id": "cd31ce657fba5dcdd74c557170bbd9ef0636cb13", "title": "Jiuzhang: A chinese pre-trained language model for mathematical problem understanding", "year": "2022"}], "2023.acl-tutorials.5": [{"id": "e77414ee96012fd9f0098b9f257fb2128502d0a3", "title": "Indirectly supervised natural language processing", "year": "2023"}, {"id": "ef25f1586cf6630f4a30d41ee5a2848b064dede3", "title": "Ultra-fine entity typing with indirect supervision from natural language inference", "year": "2022"}, {"id": "3ce79b5bf3834121a1b996a85ed2d9cbbe32dcff", "title": "Task definition, annotated dataset, and supervised natural language processing models for symptom extraction from unstructured clinical notes", "year": "2020"}, {"id": "f42c23d57a5d0cffc83feb200866999d54fc6b59", "title": "Deep probabilistic logic: A unifying framework for indirect supervision", "year": "2018"}, {"id": "bc1022b031dc6c7019696492e8116598097a8c12", "title": "Natural language processing (almost) from scratch", "year": "2011"}, {"id": "d1cbb4331d4983a23ad19943405fe087d488823c", "title": "World knowledge as indirect supervision for document clustering", "year": "2016"}, {"id": "981b30dc063d1ebd1929d417d883258328e03876", "title": "Self-supervised contextual data augmentation for natural language processing", "year": "2019"}, {"id": "98aeec328d89f78a8abd2e82faa9e406a8048370", "title": "Learning lenient parsing & typing via indirect supervision", "year": "2021"}, {"id": "abe732613f71e640e1561514f6102333511f0bb9", "title": "Machine learning for natural language processing", "year": "2007"}, {"id": "f17ee5b9d3120960eddd2bdb9af2f4f689cebb3a", "title": "Indirect supervision for relation extraction using question-answer pairs", "year": "2018"}, {"id": "f5f31d2a177a7e3dd1b11b90098608554b94b38f", "title": "Semi-supervised learning and domain adaptation in natural language processing", "year": "aard"}, {"id": "35751e6410682b4629ec79250f96cd7474196a27", "title": "Natural language processing", "year": "2011"}, {"id": "5754448c0f26e2bfb1ce9ca96d2914c0c0a9eabc", "title": "Concept and entity grounding using indirect supervision", "year": "Tsai"}, {"id": "53854f2216dde4e87e7c872b032ec031cd16f944", "title": "A review of natural language processing techniques for opinion mining systems", "year": "2017"}, {"id": "4f0415c22e35bbf760cda3a6262e1383784caaad", "title": "Natural language processing for smart construction: Current status and future directions", "year": "2022"}, {"id": "0b76ec0d0b9c4e318fc11bc2e70b117c8f5de282", "title": "The unsupervised learning of natural language structure", "year": "lein"}, {"id": null, "title": "Pretrained domain-specific language model for natural language processing tasks in the AEC domain", "year": "2022"}, {"id": "dc7a97da9d46e3f4a087ce404a19b8af03109bde", "title": "Improving distantly supervised relation extraction by natural language inference", "year": "2023"}, {"id": "cfdd423c8672a7b178ea85d56079328df4eea647", "title": "Natural language processing with Python: analyzing text with the natural language toolkit", "year": "oper"}, {"id": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning transferable visual models from natural language supervision", "year": "2021"}], "2023.acl-tutorials.6": [{"id": "277dd00ab02f122133bf56b485dfb7c730acdcde", "title": "Retrieval-based language models and applications", "year": "2023"}, {"id": "0b220041eb83c23b7b10d32a5d08c0309d528071", "title": "Large language models for information retrieval: A survey", "year": "2023"}, {"id": "d0e152aa3e6f13f5fa8ff56b4c4ac9ff397c80a3", "title": "Privacy implications of retrieval-based language models", "year": "2023"}, {"id": null, "title": "Tutorial Proposal: Retrieval-based Language Models and Applications", "year": "2023"}, {"id": "cd471b5ef162906ef3d9a84398b3f98e9ee4bf56", "title": "A review on language models as knowledge bases", "year": "2022"}, {"id": "dfcc9b3cc801d24c752b3edbfbd363dcd99739d5", "title": "Enhancing LMS experience through AIML base and retrieval base chatbot using R language", "year": "2019"}, {"id": "d331de3b6bebb0f9af1fddf1b730ec057a7026d4", "title": "Relational world knowledge representation in contextual language models: A review", "year": "2021"}, {"id": "de42a6d04470c53f7d4307917ed650ad41c28fdc", "title": "Retrieval-based language model adaptation for handwritten Chinese text recognition", "year": "2023"}, {"id": "3eb419ca9b1760222178605787057561685791c7", "title": "LM-CORE: Language models with contextually relevant external knowledge", "year": "2022"}, {"id": "1c11b0739beafd9350885960609e9799738a83c7", "title": "Long-span language models for query-focused unsupervised extractive text summarization", "year": "2018"}, {"id": "9b42a65c0d3eefdba56c43091af8eb248438ba3d", "title": "Modeling query-document dependencies with topic language models for information retrieval", "year": "2015"}, {"id": "3b8b2d43e38eb4d48d97b14a8f981e96a6c60df0", "title": "Standing on the shoulders of giant frozen language models", "year": "2022"}, {"id": "0fe1b1bfd634ee42846afbd64cef1c682e02e5e7", "title": "Retrieval-based knowledge augmented vision language pre-training", "year": "2023"}, {"id": "33422275fbb9958f55419620697faf531482699b", "title": "How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering", "year": "2021"}, {"id": "66242baf48b0f6b828e7547ac39ffaa5e1b2cb3e", "title": "Rarr: Researching and revising what language models say, using language models", "year": "2022"}, {"id": "9be23c6546a9be23d0eb3085294c6e63facec040", "title": "Inferential language models for information retrieval", "year": "2006"}, {"id": "08706687b02ae65e2303011d0013e96b79007d2c", "title": "Retrieving-to-answer: Zero-shot video question answering with frozen large language models", "year": "2023"}, {"id": "2c24944861d30eb70c04168191c2baf813ae0ae1", "title": "Retrieval-augmented large language models for adolescent idiopathic scoliosis patients in shared decision-making", "year": "2023"}, {"id": "3a30fba8f6abd80d0aac0fa2f5da66ab468b737c", "title": "Clusters, language models, and ad hoc information retrieval", "year": "2009"}, {"id": "c70eb74e09c41e8fcc71dd59e3b4d631f657f7cd", "title": "Internet-augmented language models through few-shot prompting for open-domain question answering", "year": "2022"}], "2023.eacl-tutorials.1": [{"id": "5460ca5fc6f2a0f820f5ed97e4d02be0be906a46", "title": "Processing natural language argumentation", "year": "2018"}, {"id": "dcb0b23685c9c116d8d53fe47e5157753659d3bd", "title": "Towards argument mining for social good: A survey", "year": "2021"}, {"id": "162cf89c9fb0c59577cd9164b2326b528522b90a", "title": "Nlp workflows for computational social science: Understanding triggers of state-led mass killings", "year": "2020"}, {"id": "ebe7c37c60024330bc8e90f7057961f9b849ff8d", "title": "Rhetoric, logic, and dialectic: Advancing theory-based argument quality assessment in natural language processing", "year": "2020"}, {"id": "54394f1639563225b8448d11cba1e7dc5082727c", "title": "Natural language arguments: A combined approach", "year": "2012"}, {"id": "b8c49b169bbcc2efff8e4e56408dc52ddd6b4f3f", "title": "Identifying reproductive behavior arguments in social media content users' opinions through natural language processing techniques", "year": "2023"}, {"id": "16d16b8a37c5313fa8c8430fddc011f2a98d20c5", "title": "A natural language bipolar argumentation approach to support users in online debate interactions", "year": "2013"}, {"id": "f166cb6856908e5df480b964fc6db0432433e8af", "title": "Using argumentation to improve classification in natural language problems", "year": "2017"}, {"id": "1d37460baded22f488085e82985419178679dce0", "title": "The climate change debate and natural language processing", "year": "2021"}, {"id": null, "title": "Language representations for computational argumentation", "year": "cher"}, {"id": "a3a62ad19cf9760536d77dc427993ae42e410091", "title": "The evolution of argumentation mining: From models to social media and emerging tools", "year": "2019"}, {"id": null, "title": "Computational approaches to argumentation in natural language text", "year": "2016"}, {"id": "66f0f7368e9ea960132563d50ec4b51cade8e9d7", "title": "Enhancing argumentative writing with automated feedback and social comparison nudging", "year": "2022"}, {"id": "22c889f90126154a062cab357146fd9f450580f3", "title": "Fair and argumentative language modeling for computational argumentation", "year": "2022"}, {"id": "ba805d34f762df65f499183f2010647829351def", "title": "Scientia potentia Est\u2014on the role of knowledge in computational argumentation", "year": "2022"}, {"id": "272de2ce32a7c10b745a4da54e56e1257a237ea6", "title": "A scoping review on the use of natural language processing in research on political polarization: trends and research prospects", "year": "2023"}, {"id": "4d261a30b141c1565abcf62c0ecc5e2d532310ec", "title": "Three gaps in computational text analysis methods for social sciences: A research agenda", "year": "2022"}, {"id": "f0c6fb5d5f632aed414fa2354fc240685b52783b", "title": "Text mining for social science\u2013The state and the future of computational text analysis in sociology", "year": "2022"}, {"id": "2f05d0dac7b083ff78e64b8bfcc13c9e9240dbf2", "title": "Natural language processing and computational linguistics 2: semantics, discourse and applications", "year": "urdi"}, {"id": "669022031c275cc67d1c95fa54f490ceab68a156", "title": "Argumentation mining in scientific literature: From computational linguistics to biomedicine", "year": "2021"}], "2023.eacl-tutorials.2": [{"id": "31edae2a7810324c82a53a86904090406d5505e9", "title": "Social functions of emotions at four levels of analysis", "year": "1999"}, {"id": "05a7815534eb03a915802591a83796ee0e75eed7", "title": "Social, emotional, ethical, and academic education: Creating a climate for learning, participation in democracy, and well-being", "year": "2006"}, {"id": "117b0d0f4b6364aa89f5fe44bf8a1ee36abec168", "title": "The emotional construction of morals", "year": "rinz"}, {"id": "446fcb5e8d947dc1916a273915e4969c9ec42f78", "title": "Trust, emotion, sex, politics, and science: Surveying the risk-assessment battlefield", "year": "1999"}, {"id": "43ee4080a320b616a3549a76a4545b7ae31ebdef", "title": "Behavioral, social, and emotional assessment of children and adolescents", "year": "comb"}, {"id": "652928a96caa4eace8c36e3ec05ffaff5a7ae6b3", "title": "Moral emotions and moral behavior", "year": "2007"}, {"id": "daee8a2a437ad4857b98217bc0532617f604aa5b", "title": "Sentiment analysis: Mining opinions, sentiments, and emotions", "year": " Liu"}, {"id": "bbfccff8e5787c90ddc29813cc83355e10beb38a", "title": "Safety, ethical considerations, and application guidelines for the use of transcranial magnetic stimulation in clinical practice and research", "year": "2009"}, {"id": "f2b573be79f677fbb79ac89c19a30fea9a1d3d14", "title": "On understanding emotion", "year": "nzin"}, {"id": "07fda4358342e6a89d0d080ec5ad799e47aa601f", "title": "Social research: Issues, methods and process", "year": "erry"}, {"id": "c6dc849c7cbb84fc67ca435dcc740797f309a0ae", "title": "The impact of COVID-19 epidemic declaration on psychological consequences: a study on active Weibo users", "year": "2020"}, {"id": null, "title": "Ethical Considerations in Management 5.0: Balancing Technological Advancements with Human Values Globally.", "year": "hmad"}, {"id": "538b21803b23b3d870beab87440e79c4fed84e67", "title": "Toward machine emotional intelligence: Analysis of affective physiological state", "year": "2001"}, {"id": "24152e4dc02f50bfa5832258f3c409e5761db138", "title": "Real virtuality: A code of ethical conduct. Recommendations for good scientific practice and the consumers of VR-technology", "year": "2016"}, {"id": "de848ba8aaccf209fe88f757718d1eee6c4bdaee", "title": "Working with ethical symmetry in social research with children", "year": "2002"}, {"id": "2d2eb1c91f984d516c831aa22dbbb844bcbbea71", "title": "Psychiatric assessment of children and families in immigration detention\u2013clinical, administrative and ethical issues", "year": "2004"}, {"id": "960aa7d903f666cf9b3dd3c56b7cdbbdefb305a3", "title": "Why things matter to people: Social science, values and ethical life", "year": "ayer"}, {"id": "cb3e773fdfd500971b059950352dfc5f607b84ad", "title": "Ethical leadership and decision making in education: Applying theoretical perspectives to complex dilemmas", "year": "vich"}, {"id": "b74e8da297574fd071d4b48b7aa94ea16861aea6", "title": "The emotional dog and its rational tail: a social intuitionist approach to moral judgment.", "year": "2001"}, {"id": "6d77a03fbf6341674a52d9bf95c9e49f02ef1a74", "title": "The ethics of algorithms: Mapping the debate", "year": "2016"}], "2023.eacl-tutorials.3": [{"id": "0934d7cac5a86b02fc49852334051bde540b34bd", "title": "DialogSum: A real-life scenario dialogue summarization dataset", "year": "2021"}, {"id": "4a2e0029452575f88ad7db49b7cf743f78508119", "title": "Automatic summarization", "year": "2011"}, {"id": "04e4ef19431f76d6fa41f22933e8fc444e564dc5", "title": "Recent automatic text summarization techniques: a survey", "year": "2017"}, {"id": "8fa08a8e9250df4c274877e391bbe91025749a93", "title": "Domain state tracking for a simplified dialogue system", "year": "2021"}, {"id": "90d8ead7f537c4a44af5371768152d179d3cc1f2", "title": "The theory and practice of discourse parsing and summarization", "year": "arcu"}, {"id": "1298dae5751fb06184f6b067d1503bde8037bdb7", "title": "Deep reinforcement learning for dialogue generation", "year": "2016"}, {"id": "916441619914101258c71669b5ccc36424b54a6c", "title": "The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems", "year": "2015"}, {"id": "bb130a418bf9c38114e82ab8816b8176c7901f82", "title": "A copy-augmented sequence-to-sequence architecture gives good performance on task-oriented dialogue", "year": "2017"}, {"id": null, "title": "Spoken dialogue technology: enabling the conversational user interface", "year": "2002"}, {"id": "0a22389bd99b7efe3627ec6fc77ddaf3ff5e2faa", "title": "A network-based end-to-end trainable task-oriented dialogue system", "year": "2016"}, {"id": "22d45dadde6b5837eff11dc031045754bc5901c3", "title": "Dialogue act modeling for automatic tagging and recognition of conversational speech", "year": "2000"}, {"id": "f4a5503783487eba5c5e34b1d02c09016b244b1d", "title": "Multiwoz--a large-scale multi-domain wizard-of-oz dataset for task-oriented dialogue modelling", "year": "2018"}, {"id": "4b7dcca3de306591b54b6cba36cd4a4982860630", "title": "An application of reinforcement learning to dialogue strategy selection in a spoken dialogue system for email", "year": "2000"}, {"id": "17f5c7411eeeeedf25b0db99a9130aa353aee4ba", "title": "Building end-to-end dialogue systems using generative hierarchical neural network models", "year": "2016"}, {"id": "3a7895b17db0cda7bbf86bcda52c46a3e03b6ded", "title": "Dialoguernn: An attentive rnn for emotion detection in conversations", "year": "2019"}, {"id": "2b79e85bfc1b5543e50e86ee8b21aea48cb6d470", "title": "Task-oriented dialog systems that consider multiple appropriate responses under the same context", "year": "2020"}, {"id": "356770d13ad2e7b60961e5bc7368ffd3b9a2bcd9", "title": "Learning to summarize with human feedback", "year": "2020"}, {"id": "3def68bd0f856886d34272840a7f81588f2bc082", "title": "Survey of hallucination in natural language generation", "year": "2023"}, {"id": "690f52ca9b882db3fcef7eecc3d3903ac345c15a", "title": "The role of dialogue in providing scaffolded instruction", "year": "1986"}, {"id": "bf8491bef353df126e2306ad2fe4b898697b906a", "title": "A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity", "year": "2023"}], "2023.emnlp-tutorial.2": [{"id": "aa83437007d3fd6b79f11180f0c5b640d0c48cb3", "title": "Backdoor attacks and countermeasures in natural language processing models: A comprehensive security review", "year": "2023"}, {"id": "c586f3a69102fffdff178ca79b0be767d384da43", "title": "Hidden backdoors in human-centric language models", "year": "2021"}, {"id": "9459bdac15a6b0912ba0ada977e795538a879a9c", "title": "A survey on backdoor attack and defense in natural language processing", "year": "2022"}, {"id": "84a33d6966cbb2cf8f5192087b286122e806a242", "title": "Hidden trigger backdoor attack on {NLP} models via linguistic style manipulation", "year": "2022"}, {"id": "3ae488cc40794aa8106c34f7a6f538a8fceb6a38", "title": "The triggers that open the NLP model backdoors are hidden in the adversarial samples", "year": "2022"}, {"id": "c4cdf2e0d89aadb13bf9c61654ff9e17be2b01b9", "title": "Badnl: Backdoor attacks against nlp models with semantic-preserving improvements", "year": "2021"}, {"id": "69dd1b9e8391430a667214a9ca6c0bc94560deb2", "title": "Backdoor attacks and countermeasures on deep learning: A comprehensive review", "year": "2020"}, {"id": "5e31fa4e69d1a3587230f5d134c0b7e2ed84a742", "title": "Be careful about poisoned word embeddings: Exploring the vulnerability of the embedding layers in NLP models", "year": "2021"}, {"id": "763ed9da1a38b2ee985ac9fb8aad8009a1f25e97", "title": "Bddr: An effective defense against textual backdoor attacks", "year": "2021"}, {"id": "f182ccbc90c1d20d358e3d197b340691f277428f", "title": "A backdoor attack against lstm-based text classification systems", "year": "2019"}, {"id": "08aaaf7ae3d61875e7bcf5c1bb0df4f17066e300", "title": "Piccolo: Exposing complex backdoors in nlp transformer models", "year": "2022"}, {"id": "3fa0959ed06206b81f6d2125c19e1a5958250e6d", "title": "Threats to pre-trained language models: Survey and taxonomy", "year": "2022"}, {"id": "f73ffa21fca68890cb42cd8977c2166d75e05caf", "title": "Artificial intelligence security: Threats and countermeasures", "year": "2021"}, {"id": "04659ccb232c5ecbe42ef8a522bbb55f41f7a7aa", "title": "Security and privacy for artificial intelligence: Opportunities and challenges", "year": "2021"}, {"id": "2a46eb47e8742be29b16a5b83dc1a38616b24ce6", "title": "A targeted attack on black-box neural machine translation with parallel data poisoning", "year": "2021"}, {"id": "0b6a1ae1ac3a64311ce2d6776b0570caa5d9565f", "title": "An Adaptive Black-box Defense against Trojan Attacks on Text Data", "year": "2021"}, {"id": "947e990357c77e2adb791b1d6f082158b287a642", "title": "Generative models for security: Attacks, defenses, and opportunities", "year": "2021"}, {"id": "94fec3a214e91e3a395c3f202cd8de06fe7231ec", "title": "Chatgpt as an attack tool: Stealthy textual backdoor attack via blackbox generative model trigger", "year": "2023"}, {"id": "c89a1c5629899e4463f194b396ca92847ce7c156", "title": "Binary black-box evasion attacks against deep learning-based static malware detectors with adversarial byte-level language model", "year": "2020"}, {"id": "ca115a9eb54e2875b9d4c4c3d5ed8adcb399dbf8", "title": "Rap: Robustness-aware perturbations for defending against backdoor attacks on nlp models", "year": "2021"}], "2023.emnlp-tutorial.3": [{"id": "abafb5f34c288fd23370c4ebcc9f7b098df626c9", "title": "Designing, Evaluating, and Learning from Humans Interacting with NLP Models", "year": "2023"}, {"id": "220d4d0425afbe422f1c0b8c5a2e80bff6e36677", "title": "ReadingQuizMaker: a human-NLP collaborative system that supports instructors to design high-quality reading quiz questions", "year": "2023"}, {"id": "39391ebdc03485b7cc85852ddc999b0da6324da2", "title": "What happens if you treat ordinal ratings as interval data? human evaluations in NLP are even more under-powered than you think", "year": "2021"}, {"id": "a35a1fdc3c8f43b4c97f2902a9b8801eded9f87c", "title": "Nlp-based approach for predicting hmi state sequences towards monitoring operator situational awareness", "year": "2020"}, {"id": null, "title": "Question generation for language caf\u00e9 interaction between robot and human: NLP applied in a robot", "year": "ston"}, {"id": "329b6b4a8a1a8a2572ae4402f982483cd187302a", "title": "Towards process-oriented, modular, and versatile question generation that meets educational needs", "year": "2022"}, {"id": "b2afd64af25e14e0bb29e9f2756c41f3b83e6a51", "title": "Exploring NLP-Based Methods for Generating Engineering Ethics Assessment Qualitative Codebooks", "year": "2023"}, {"id": "dd7656d398073ffbe6533f65974da3a9959c7b11", "title": "Natural language processing for theoretical framework selection in engineering education research", "year": "2020"}, {"id": "f7061d7d11e9b19a2b40a3ba5b7ba261d0010fd3", "title": "Natural Language Processing (NLP) and Its Impact across Industries\u2013Unlocking the True Potential of Digital Healthcare (A Case Study Approach)", "year": "2021"}, {"id": "509c26ab71e36a6cff575359a412bab3843e59aa", "title": "Analyzing the impact of natural language processing over feature location in models", "year": "2017"}, {"id": "1d69e8a253f7a56c7643e5676552a54f7232adb1", "title": "Automating the process of identifying the preferred representational system in Neuro Linguistic Programming using Natural Language Processing", "year": "2019"}, {"id": null, "title": "Advances in natural language processing\u2013a survey of current research trends, development tools and industry applications", "year": "2019"}, {"id": "e242e5c6b2f81ed2bb747c1823ca0fcc415ccb0b", "title": "Revolutionizing customer interactions: Insights and challenges in deploying chatgpt and generative chatbots for faqs", "year": "2023"}, {"id": "ebba66a40aad94e4c20000f2a79bb1bce86f6a4d", "title": "Centrosomal Nlp is an oncogenic protein that is gene-amplified in human tumors and causes spontaneous tumorigenesis in transgenic mice", "year": "2010"}, {"id": "b186ef9e81a22322a4ebf2790f9bd218384d9a3d", "title": "Polo-like kinase 1 regulates Nlp, a centrosome protein involved in microtubule nucleation", "year": "2003"}, {"id": "46f61be29a395a826a9f04a9597a10d6b00000e4", "title": "Database, features, and machine learning model to identify thermally driven metal\u2013insulator transition compounds", "year": "2021"}, {"id": "89716742f439a311f2da5cda00dfa6ec120fc0cd", "title": "Intelligent question answering system based on artificial neural network", "year": "2016"}, {"id": "15d40d36dca1a8c6e5fc64dde11cbb3978800af6", "title": "The role of centrosomal Nlp in the control of mitotic progression and tumourigenesis", "year": "2011"}, {"id": "6f2bc7c519600a0099fd9455e710c8a936bb2058", "title": "Coordinate regulation of the mother centriole component nlp by nek2 and plk1 protein kinases", "year": "2005"}, {"id": "36afa1fdc20ae3c90c1552d02fae172bfe4bd06c", "title": "Speech-based virtual assistant for treatment of Alzheimer disease patient using virtual reality environment (VRE)", "year": "2022"}], "2023.emnlp-tutorial.4": [{"id": "f0950a3f27c0fefffba60ae1c9a8ee360d5eb55f", "title": "Instruction tuning for large language models: A survey", "year": "2023"}, {"id": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback", "year": "2022"}, {"id": "ac771182d1780c863954243809d1e144433919f9", "title": "Aligning large language models with human: A survey", "year": "2023"}, {"id": "7ce0c89a452e3c2917b63847495533865697c79c", "title": "Can large language models truly understand prompts? a case study with negated prompts", "year": "2023"}, {"id": "0383e049e98c9eedbc61be728d4ef037300bbedf", "title": "Recommendation as instruction following: A large language model empowered recommendation approach", "year": "2023"}, {"id": "88ca4ee548d07263386ca8e4effc4a001bb2716f", "title": "Improving text embeddings with large language models", "year": "2023"}, {"id": null, "title": "Large language models still can't plan (a benchmark for llms on planning and reasoning about change)", "year": "2022"}, {"id": "8ee45aeb7c97e3346cc62f216f673b91277ac718", "title": "Llm-planner: Few-shot grounded planning for embodied agents with large language models", "year": "2023"}, {"id": "e7ad08848d5d7c5c47673ffe0da06af443643bda", "title": "Large language models are zero-shot reasoners", "year": "2022"}, {"id": "131f499e4d3503da93022d07fcf804a18483bea9", "title": "Wizardlm: Empowering large language models to follow complex instructions", "year": "2023"}, {"id": "2392b6d3a5cad9e5cf349169eaeee848266adf6a", "title": "Llmlingua: Compressing prompts for accelerated inference of large language models", "year": "2023"}, {"id": "0b220041eb83c23b7b10d32a5d08c0309d528071", "title": "Large language models for information retrieval: A survey", "year": "2023"}, {"id": "9a9b296a639c4f29ada085082df9fe75471bba9e", "title": "Visit-bench: A dynamic benchmark for evaluating instruction-following vision-and-language models", "year": "2023"}, {"id": "454c8fef2957aa2fb13eb2c7a454393a2ee83805", "title": "Wizardcoder: Empowering code large language models with evol-instruct", "year": "2023"}, {"id": "6052486bc9144dc1730c12bf35323af3792a1fd0", "title": "Large language models encode clinical knowledge", "year": "2023"}, {"id": "4fdca2c47c4fb7cd635bc27fe1ed964ec16c53ee", "title": "A survey of large language models", "year": "2023"}, {"id": "dedfe929d182cc3537a9ed765d589b4735ce062a", "title": "On the planning abilities of large language models-a critical investigation", "year": "2023"}, {"id": "94ce1d5924e05e8d75e43ce70044293ddcef850a", "title": "Large language models in medicine", "year": "2023"}, {"id": "3e2734025037fc626873c56e05ddb43ccccd3858", "title": "A survey on large language models: Applications, challenges, limitations, and practical usage", "year": "2023"}, {"id": "4d57eedb21d57d3fc8ec19a4a9ba47624b1d1539", "title": "Creation and adoption of large language models in medicine", "year": "2023"}], "2023.ijcnlp-tutorials.2": [{"id": "8faf5920ee49d5411cd92304a78394b6b3e8c6a6", "title": "Current Status of NLP in South East Asia with Insights from Multilingualism and Language Diversity", "year": "2023"}, {"id": "a747e8f2659df479c0092301b9658fc582423df1", "title": "One country, 700+ languages: NLP challenges for underrepresented languages and dialects in Indonesia", "year": "2022"}, {"id": "7ae45b728cdbbda20c1a1d207f6523de82138171", "title": "Asian language processing: current state-of-the-art", "year": "2006"}, {"id": "aa605f1d6000aee0b5e955cf1d9cf79523faf8cd", "title": "Computational historical linguistics and language diversity in South Asia", "year": "2022"}, {"id": "fbfcd7b6b22eeaacd437d1b4ce7829920dbe72ea", "title": "Multilingual natural language processing applications: from theory to practice", "year": "ouni"}, {"id": null, "title": "IndoLib: A Natural Language Processing Toolkit for Low-Resource South Asian Languages", "year": "sina"}, {"id": "b9acc34d3133648016232d61e7694be7105aadb8", "title": "37 Language policy and planning in Mainland Southeast Asia", "year": "st\u00a0\u2026"}, {"id": "9af31c93f9f0aa6cb878604ddf66dbf22c3c00b1", "title": "Scoping natural language processing in Indonesian and Malay for education applications", "year": "2022"}, {"id": "9d52e4feff8de707e22cea78044593b7e4197159", "title": "Applications of natural language processing in bilingual language teaching: An Indonesian-English case study", "year": "2020"}, {"id": "76e69e67d50092a01cd7e8320b82ee861d01de66", "title": "Natural language processing for similar languages, varieties, and dialects: A survey", "year": "2020"}, {"id": "c934f29ec6ad1087d7a1b085e8cbdb4b19c9db27", "title": "Natural language processing for resource-poor languages", "year": "2017"}, {"id": "11f64ec047782cada21d50efea1e0dc5843675f6", "title": "NusaX: Multilingual parallel sentiment dataset for 10 Indonesian local languages", "year": "2022"}, {"id": "0e09e8c08b9d0a8720768b054371945e4bbba862", "title": "Bhasa: A holistic southeast asian linguistic and cultural evaluation suite for large language models", "year": "2023"}, {"id": "31133c1964c7dfd696e6c3651e0b6653f873c750", "title": "A survey on NLP resources, tools, and techniques for Marathi language processing", "year": "2022"}, {"id": "be5074a85ef8166fc173cb51971a2e3f79685134", "title": "Multilingual speech processing", "year": "hoff"}, {"id": "9963b0e1215d66e0c5af0ad5a7a48a9b3a9c7c23", "title": "Hard Numbers: Language Exclusion in Computational Linguistics and Natural Language Processing", "year": "2018"}, {"id": "7625e596f3c6fba28e57afabf70dcf6e6bed7718", "title": "Survey on Thai NLP language resources and tools", "year": "2022"}, {"id": null, "title": "Disrupting Digital Monolingualism: A report on multilingualism in digital theory and practice", "year": "ence"}, {"id": "df2b5751e29e858db27adc9481d8242c50863652", "title": "A comprehensive survey on Indian regional language processing", "year": "2020"}, {"id": "7ab0976f5b60842eb00e3702a92fd1720aaef369", "title": "SeaLLMs--Large Language Models for Southeast Asia", "year": "2023"}], "2023.ijcnlp-tutorials.4": [{"id": "6d4bacb69923e1e94fb4de468b939ce6db32fb51", "title": "Large language models cannot self-correct reasoning yet", "year": "2023"}, {"id": "668faca09fcefd18a46ab5ce4eab765c065e1d5e", "title": "Using large language models to enhance programming error messages", "year": "2023"}, {"id": "e08c1e013681c82a65dd971bfd86d5ae4b48318f", "title": "Grammargpt: Exploring open-source llms for native chinese grammatical error correction with supervised fine-tuning", "year": "2023"}, {"id": "9cac09098aa611bd9a94d080d2401840632ab16f", "title": "LM-critic: Language models for unsupervised grammatical error correction", "year": "2021"}, {"id": "98b607e7cb84e1a5c87c8a49562ae35435e6722d", "title": "Learning from mistakes makes llm better reasoner", "year": "2023"}, {"id": "92746dfa09dcad92ecf1e6272ebb300c1112b7eb", "title": "Automatic calibration and error correction for large language models via pareto optimal self-supervision", "year": "2023"}, {"id": "27343da734be32fa5347f367730cacaa6d9b3c01", "title": "Exploring the integration of large language models into automatic speech recognition systems: An empirical study", "year": "2023"}, {"id": "9ec29a26336f043a705ac99baa04c8d7f69fe4b4", "title": "Gaining wisdom from setbacks: Aligning large language models via mistake analysis", "year": "2023"}, {"id": "f52ea31e37c45e0de7ab4a5324d4d970479c110a", "title": "Can generative large language models perform asr error correction?", "year": "2023"}, {"id": "4f601b4e561557c7a0bd5a741a54cabaec7dc70e", "title": "Leveraging pre-trained large language models to construct and utilize world models for model-based task planning", "year": "2023"}, {"id": "50e8ab900d2ca4d83da120bbfe5338ee93dbe741", "title": "Generative speech recognition error correction with large language models and task-activating prompting", "year": "2023"}, {"id": "fd291f8ab240af366da0133c5c5b31562484d5a3", "title": "Validating large language models with relm", "year": "2023"}, {"id": null, "title": "Planning with large language models via corrective re-prompting", "year": "2022"}, {"id": "25bfd05485c1cb1a004b1adb77741629f3b3ee35", "title": "Rtlfixer: Automatically fixing rtl syntax errors with large language models", "year": "2023"}, {"id": "c66271363c88407edc335fc9a314c7a0e0af38c1", "title": "On the (in) effectiveness of large language models for chinese text correction", "year": "2023"}, {"id": "87bd28003ca39c7ce5a2d7ca6a03446b2e482a4f", "title": "Exploring the responses of large language models to beginner programmers' help requests", "year": "2023"}, {"id": null, "title": "Quick start guide to large language models: strategies and best practices for using ChatGPT and other LLMs", "year": "emir"}, {"id": "ab91ce3fa3ebcffb637bd48b5caeba4967d2a79d", "title": "Addressing compiler errors: Stack overflow or large language models?", "year": "2023"}, {"id": "4fbd174e80502f8f3c4b9f48054872b028e2445a", "title": "Large language models for software engineering: Survey and open problems", "year": "2023"}, {"id": "24de1048791bac4972ecc16d1c3c1de23691407d", "title": "Large language models: a comprehensive survey of its applications, challenges, limitations, and future prospects", "year": "2023"}], "2023.ijcnlp-tutorials.5": [{"id": "7958647ee241185ab253cdaa63466033e37e78ca", "title": "Who Says What to Whom: A Survey of Multi-Party Conversations.", "year": "2022"}, {"id": "51b9f8aef39de4b6db820b5c4b5bca14fc32aa4d", "title": "MPC-BERT: A pre-trained language model for multi-party conversation understanding", "year": "2021"}, {"id": null, "title": "Towards Multi-Party Conversation Modeling", "year": "ajan"}, {"id": "d30cfc4b660c939e86b4bddb427e2ef06fa81297", "title": "MPC: A Multi-Party Chat Corpus for Modeling Social Phenomena in Discourse.", "year": "2010"}, {"id": "546f07df36e03293b3ba0996c692af1d1bb4bc10", "title": "Learning WHO Saying WHAT to WHOM in Multi-Party Conversations", "year": "2023"}, {"id": "6d02f9bb2b95484360e193a38d017d7d72914e55", "title": "Transformer-based multi-party conversation generation using dialogue discourse acts planning", "year": "2023"}, {"id": "2b823c198b044b0052eedb33e00e763f045d1296", "title": "Who Says What (WSW): A Novel Model for Utterance-Aware Speaker Identification in Text-Based Multi-Party Conversations.", "year": "2023"}, {"id": "daadd8b4af33abc89f1148ee1685b8a3099759ed", "title": "HeterMPC: A heterogeneous graph neural network for response generation in multi-party conversations", "year": "2022"}, {"id": "a97123a21f27ebd0e4bd0f6c4def42c87813fd64", "title": "Is ChatGPT a Good Multi-Party Conversation Solver?", "year": "2023"}, {"id": "a77fd5fd19e066b0fdb84d290305a3a9fae497e3", "title": "A Survey of Challenges and Methods in the Computational Modeling of Multi-Party Dialog", "year": "2023"}, {"id": "8a1a8290f7d42b0ce60445a4c0130ef737b3ff69", "title": "Multi-party goal tracking with llms: Comparing pre-training, fine-tuning, and prompt engineering", "year": "2023"}, {"id": "81b58944372ea10436ff7252b115e21e893d11c6", "title": "Enhanced speaker-aware multi-party multi-turn dialogue comprehension", "year": "2023"}, {"id": "9afec67cfcc6ce29df817145b13ffd5e38c5d328", "title": "Extending the MPC corpus to Chinese and Urdu-A Multiparty Multi-Lingual Chat Corpus for Modeling Social Phenomena in Language.", "year": "2012"}, {"id": "671e06255d5c4db3bd0340eeabda03066faaf910", "title": "Learning multi-party turn-taking models from dialogue logs", "year": "2019"}, {"id": "d8857a0490b4dc4d2ec7957ca8baae0cd3bec684", "title": "Incorporating interlocutor-aware context into response generation on multi-party chatbots", "year": "2019"}, {"id": "1847dcd891faed97bf0bf182b3acf8be71d6651d", "title": "Towards evaluation of multi-party dialogue systems", "year": "2022"}, {"id": "9c2d502097be3a364d51315123c248282d6d534e", "title": "GIFT: Graph-Induced Fine-Tuning for Multi-Party Conversation Understanding", "year": "2023"}, {"id": "a4f04b7a199f22351f806e7aeb1facd1ad23e56b", "title": "On the need for thoughtful data collection for multi-party dialogue: A survey of available corpora and collection methods", "year": "2021"}, {"id": "9033abb3959dd8dba8202578fa89333a9cb11223", "title": "Modeling influence in online multi-party discourse", "year": "2012"}, {"id": null, "title": "Data collection for multi-party task-based dialogue in social robotics", "year": "2023"}], "2024.eacl-tutorials.1": [{"id": "87a3fdc68b1e20fcbe2821be54fed91cb25ce82a", "title": "The neural and computational bases of semantic cognition", "year": "2017"}, {"id": "7ee0a337faec1d87bbb15d84856a43a4aa64ac65", "title": "Diachronic word embeddings reveal statistical laws of semantic change", "year": "2016"}, {"id": "3b6185b03bd247c33e52a35c0a0875cbb71df6f2", "title": "How the statistical revolution changes (computational) linguistics", "year": "2009"}, {"id": "0fe48b35848a178ef5f52f03b64b25aa70acd76a", "title": "Structure and deterioration of semantic memory: a neuropsychological and computational investigation.", "year": "2004"}, {"id": "a7a2a0eeaacb41aa39fc0355e6d42d6b04d6fc54", "title": "Semantic change driven generative semantic communication framework", "year": "2024"}, {"id": "a848b96512221f76c2fa15e3dd63a144f2875354", "title": "The large\u2010scale structure of semantic networks: Statistical analyses and a model of semantic growth", "year": "2005"}, {"id": "aafad1384030adf18f42ff513fafd898068aa5fd", "title": "Statistically significant detection of linguistic change", "year": "2015"}, {"id": "f76807536e7f6542a72609929a9630de802a597f", "title": "Extracting semantic representations from word co-occurrence statistics: A computational study", "year": "2007"}, {"id": "aabde8c3e1116dabf9c98758d66ed0755a40716c", "title": "Resclving inconsistency: A computational model of word naming", "year": "1987"}, {"id": "e1d108d3a250272860492eda88ab8e53a1c0d183", "title": "Individual and developmental differences in semantic priming: empirical and computational support for a single-mechanism account of lexical processing.", "year": "2000"}, {"id": "745d86adca56ec50761591733e157f84cfb19671", "title": "Composition in distributional models of semantics", "year": "2010"}, {"id": "0f3ab6835042ea45d2aab8e4a70151c11ca9a1d6", "title": "Topics in semantic representation.", "year": "2007"}, {"id": "98d6a531a741964ea547f5c8533a3b65e04603d9", "title": "Learning words from sights and sounds: A computational model", "year": "2002"}, {"id": "6b84e730bfc174f7a02b15c0c16f2a75f609a1bb", "title": "Computational models of emotion", "year": "2010"}, {"id": "967f14a9951d2fad59146902709c4c03894c234d", "title": "Modelling changes, stakeholders and their relations in semantic 3d city models", "year": "2021"}, {"id": "91b9d3ab7532ea24ae70cd726355f25235b1fe8b", "title": "Ten simple rules for the computational modeling of behavioral data", "year": "2019"}, {"id": "1500bbc178e0d7b3580879505526bd55ffd1f070", "title": "Biologically based computational models of high-level cognition", "year": "2006"}, {"id": "25353bc78453da76e43e199a925ab54457e18ca5", "title": "Latent semantic models for collaborative filtering", "year": "2004"}, {"id": "1137c5b2a1645598bf28dec00228c7b6a85a4134", "title": "Tracing the development of spanish participation constructions: an empirical study of semantic change", "year": "arco"}, {"id": "35cd567b6178cfb89b423701498ef1245e632129", "title": "Statistical and computational models of the visual world paradigm: Growth curves and individual differences", "year": "2008"}], "2024.eacl-tutorials.4": [{"id": "0acd7ff5817d29839b40197f7a4b600b7fba24e4", "title": "Transformer interpretability beyond attention visualization", "year": "2021"}, {"id": "2f47a4c37c01d3ad4e6c4b074ff61468f1e976b8", "title": "Attention-based interpretability with concept transformers", "year": "2021"}, {"id": "b503f607c8e73a117888e0d5f658c6855a11c319", "title": "Vit-net: Interpretable vision transformers with neural tree decoder", "year": "2022"}, {"id": "f80775a79d42a1ddfc0df808ea760c57af4949d0", "title": "Nested hierarchical transformer: Towards accurate, data-efficient and interpretable visual understanding", "year": "2022"}, {"id": "a5cc5edcabba4c9c62cfbc3379daa140084a2a24", "title": "Tracr: Compiled transformers as a laboratory for interpretability", "year": "2024"}, {"id": "1686203adc5f2dbc18627ce64f66d33eb81432a5", "title": "Self-attention attribution: Interpreting information interactions inside transformer", "year": "2021"}, {"id": "2256e8cde782799727fa3b1014f36f91b1e96666", "title": "Covid-transformer: Interpretable covid-19 detection using vision transformer for healthcare", "year": "2021"}, {"id": "059cd00d47eebfdea4fd74d430c9aa6a86e5ad56", "title": "InterpreT: An interactive visualization tool for interpreting transformers", "year": "2021"}, {"id": "73d5439f91fd3333d8b9c05600ae0ecea9fd4c31", "title": "Benchmarking post-hoc interpretability approaches for transformer-based misogyny detection", "year": "2022"}, {"id": "6cb8bc7398ffcd27c500fb743cf72c84cfe4df8d", "title": "Learning transformer programs", "year": "2024"}, {"id": "e60fe8a9b9ca2210b15b92be5fb364798de73330", "title": "Transformer for one stop interpretable cell type annotation", "year": "2023"}, {"id": "e2f2662f0734e2edc2b4b36a734de111c7f8d54d", "title": "IA-RED: Interpretability-Aware Redundancy Reduction for Vision Transformers", "year": "2021"}, {"id": "36ac95256d20e504fad7396433acd9098c307647", "title": "Focused attention in transformers for interpretable classification of retinal images", "year": "2022"}, {"id": "368b776ffc0c9ab87eb1d3c5b98ab0c26477217e", "title": "Transformer neural networks for interpretable flood forecasting", "year": "2023"}, {"id": "fddbfdb795cccf12aa9ca51398a04e305a0fb89b", "title": "ISTVT: interpretable spatial-temporal video transformer for deepfake detection", "year": "2023"}, {"id": "a3335ad0d5e4061edda2b66567e517022642ea96", "title": "Safety-enhanced autonomous driving using interpretable sensor fusion transformer", "year": "2023"}, {"id": "b70252f0de1c7832fdd6c862af35f6667349fe55", "title": "Transformer vae: A hierarchical model for structure-aware and interpretable music representation learning", "year": "2020"}, {"id": "e678898301a66faab85dfa4c84e51118e434b8f2", "title": "Vision-language transformer for interpretable pathology visual question answering", "year": "2022"}, {"id": "39bf629c24eafda33a4a6a3b190a89217b81a840", "title": "Logiformer: A two-branch graph transformer network for interpretable logical reasoning", "year": "2022"}, {"id": "dbf77735b956ec5cea0716fcc294654137eca495", "title": "Trading with the momentum transformer: An intelligent and interpretable architecture", "year": "2021"}], "2024.eacl-tutorials.5": [{"id": "8ee77f496e74ebc92161629cbd7de58ac9508a33", "title": "LLMs for Low Resource Languages in Multilingual, Multimodal and Dialectal Settings", "year": "2024"}, {"id": "be445964370b5ea8c15aa1bf6cf10f951fa90b9a", "title": "Multilingual large language model: A survey of resources, taxonomy and frontiers", "year": "2024"}, {"id": "e0bf0c7af09a17738458ae1059d9e08b4cdc9ea8", "title": "Shortcomings of LLMs for Low-Resource Translation: Retrieval and Understanding are Both the Problem", "year": "2024"}, {"id": "4af9902f47eb69f634fe4fd8157c85b75bc68295", "title": "A Survey on Large Language Models with Multilingualism: Recent Advances and New Frontiers", "year": "2024"}, {"id": "5760218e4635cc2841dc7fba1752427a023c2193", "title": "A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias", "year": "2024"}, {"id": "3d9f124dcaccc058417aa42a166f0997bf5aec63", "title": "Teaching Large Language Models to Translate on Low-resource Languages with Textbook Prompting", "year": "2024"}, {"id": "4c01dfec69f5d55daae00b668665e94eb9da7f39", "title": "LLMs Are Few-Shot In-Context Low-Resource Language Learners", "year": "2024"}, {"id": null, "title": "Spoken Language Translation in Low\u2010Resource Language", "year": "2024"}, {"id": "d70fe318d5fa97dab6ceaa3a5f14869f45b384dd", "title": "Natural language processing for dialects of a language: A survey", "year": "2024"}, {"id": "80d1cebc2dbbc03772fdd277b4fee4ad82b9c3aa", "title": "Beyond Metrics: Evaluating LLMs' Effectiveness in Culturally Nuanced, Low-Resource Real-World Scenarios", "year": "2024"}, {"id": "62ad7ea9467bbcdbfe325b9ee561cab3908e4583", "title": "Mega: Multilingual evaluation of generative ai", "year": "2023"}, {"id": "66c231fd4244e8fe2b6d456960a025197f333c88", "title": "PhonologyBench: Evaluating Phonological Skills of Large Language Models", "year": "2024"}, {"id": "a90560b3c9f52de21caccd82f151b092b45d9603", "title": "Large Language Models for Education: A Survey", "year": "2024"}, {"id": "de643836277d108e1f8410ea85b0c3ed0e686163", "title": "Mala-500: Massive language adaptation of large language models", "year": "2024"}, {"id": "8597c0dc4fa5805306d9dd73622b9d27f4e74557", "title": "A multimodal approach to cross-lingual sentiment analysis with ensemble of transformer and LLM", "year": "2024"}, {"id": "1f874c94d531f6776f65e0aa807adbf432ea35cf", "title": "Understanding and Mitigating Language Confusion in LLMs", "year": "2024"}, {"id": "3da5f21144fef19dd88f7dcc11a5d9f2edbfe417", "title": "RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs", "year": "2024"}, {"id": null, "title": "Towards Dialogue Modelling in Code-Mixed Low Resource Language Settings", "year": "duri"}, {"id": "b24afe3b2db58260731e4bbac7c3c05111cae132", "title": "Large language models for foreign language acquisition", "year": "dan\u2026"}, {"id": "bbcf7f15c4f470bc765ac5e8520a99b42e193166", "title": "IrokoBench: A New Benchmark for African Languages in the Age of Large Language Models", "year": "2024"}], "2024.lrec-tutorials.10": [{"id": "dddd1de22beca06119ca83122afd82059abbf48a", "title": "Towards a Human-Computer Collaborative Scientific Paper Lifecycle: A Pilot Study and Hands-On Tutorial", "year": "2024"}, {"id": "74de610dbd5ed4685fbe16b8a9b7474cf91a880d", "title": "Life Cycle Assessment for the Unconventional Construction Materials in Collaboration with a Large Language Model", "year": "2023"}, {"id": "3d60d8273cea724226d4dd62f469bc77374d3656", "title": "The life cycle of large language models in education: A framework for understanding sources of bias", "year": "2024"}, {"id": "66ddaeb00d068f4309954408a5ebd3ac4d85fe57", "title": "A Case Study on the Generative AI Project Life Cycle Using Large Language Models", "year": "2024"}, {"id": "d1ee50572803f31a1d6e14887a3c33b2b1227eed", "title": "Enhancing user experience in large language models through human-centered design: Integrating theoretical insights with an experimental study to meet diverse\u00a0\u2026", "year": "2024"}, {"id": "bca0ef2b207163c168eb8843f6598b515b71aa4d", "title": "Generating Specifications from Requirements Documents for Smart Devices Using Large Language Models (LLMs)", "year": "2024"}, {"id": "888728745dbb769e29ed475d4f7661eebe1a71cf", "title": "A survey on evaluation of large language models", "year": "2024"}, {"id": "9d4bd6f057fde94e2956a14711655e9044257044", "title": "From Text to Transformation: A Comprehensive Review of Large Language Models' Versatility", "year": "2024"}, {"id": "681ec8743f214b299f801359c8375eae90c833f9", "title": "\" I'm categorizing LLM as a productivity tool\": Examining ethics of LLM use in HCI research practices", "year": "2024"}, {"id": "4b5b7f8ff26df8ef2aeb0ca7cbaa78f628077246", "title": "Human-Centered Explainable AI (HCXAI): Reloading Explainability in the Era of Large Language Models (LLMs)", "year": "2024"}, {"id": "f0204dae7095ed5b68e498830afcda33a2536faa", "title": "The Life Cycle of Large Language Models: A Review of Biases in Education", "year": "2024"}, {"id": "c894ac9cbb77d96b7ff6f4754b7831c37c825510", "title": "Rocks Coding, Not Development: A Human-Centric, Experimental Evaluation of LLM-Supported SE Tasks", "year": "2024"}, {"id": "812b2662aa17fcd8021d99362723511b02791e46", "title": "Trustllm: Trustworthiness in large language models", "year": "2024"}, {"id": "dbea7141f8f3f1c1a298308721e56b749613c0c5", "title": "Are Large Language Models the New Interface for Data Pipelines?", "year": "2024"}, {"id": "dbea7141f8f3f1c1a298308721e56b749613c0c5", "title": "Are Large Language Models the New Interface for Data Pipelines?", "year": "2024"}, {"id": "784e03977f16b0b5a00c16523fdbcb9ffcefc545", "title": "Supporting human-ai collaboration in auditing llms with llms", "year": "2023"}, {"id": "5a9ce2055a0f200fd53b7eeddf1c05f9e01ccf5a", "title": "Large language models and games: A survey and roadmap", "year": "2024"}, {"id": "f2c17758e74707d379b87372528221656d14b697", "title": "Taxonomy of risks posed by language models", "year": "2022"}, {"id": "825d9f7b7806b2c8265351caeee2b26d10a6abaa", "title": "DOLLmC: DevOPs for Large Language model Customization", "year": "2024"}, {"id": "0251bb95be75d472c8d5b873751615e7fe2feb1d", "title": "A comprehensive study of knowledge editing for large language models", "year": "2024"}], "2024.lrec-tutorials.11": [{"id": "5272acad9e4201e93dabe3fd99bd7ead9b1a544d", "title": "A comprehensive survey of hallucination mitigation techniques in large language models", "year": "2024"}, {"id": "d00735241af700d21762d2f3ca00d920241a15a4", "title": "Siren's song in the AI ocean: a survey on hallucination in large language models", "year": "2023"}, {"id": "fc4c380102d6f72657d1ab54dffd6be536bb01c7", "title": "A survey on hallucination in large vision-language models", "year": "2024"}, {"id": "396305230ddcf915b19a19683a89e34d76321a33", "title": "Cognitive mirage: A review of hallucinations in large language models", "year": "2023"}, {"id": "1e909e2a8cdacdcdff125ebcc566f37cb869a1c8", "title": "A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions", "year": "2023"}, {"id": "fac468032e0c38ea10dfb95ba6cdeac51a473050", "title": "Hallucination detection: Robustly discerning reliable answers in large language models", "year": "2023"}, {"id": "5cd671efa2af8456c615c5faf54d1be4950f3819", "title": "Hallucination is inevitable: An innate limitation of large language models", "year": "2024"}, {"id": "bb1083425517bdac8d9a6438fcf5032543acb20e", "title": "Evaluation and analysis of hallucination in large vision-language models", "year": "2023"}, {"id": "3d3a55074000b375625c6233332f08648430d413", "title": "Large legal fictions: Profiling legal hallucinations in large language models", "year": "2024"}, {"id": "24b6b70e1b1525535155cc9fa66dfd9d5d42d6b5", "title": "Hill: A hallucination identifier for large language models", "year": "2024"}, {"id": "3b43cfe8aeaadec8b58a8fa8759a1aa42f1b35b2", "title": "Knowledge injection to counter large language model (LLM) hallucination", "year": "2023"}, {"id": "29652bb2dc0396ab27c0be0c5f24c114c757df0f", "title": "Evaluating hallucinations in chinese large language models", "year": "2023"}, {"id": "bb3cc013c462ff2bf3dc5be90f731ebf34996f86", "title": "Autohall: Automated hallucination dataset generation for large language models", "year": "2023"}, {"id": "99bfe503743c5ec8e16e50ab8438159cdb533a89", "title": "The troubling emergence of hallucination in large language models--an extensive definition, quantification, and prescriptive remediations", "year": "2023"}, {"id": null, "title": "Mitigating Hallucinations of Large Language Models via Knowledge Consistent Alignment", "year": "2024"}, {"id": "1b387e3fbec0447c8bf2dcee21f6db59cdddf698", "title": "The dawn after the dark: An empirical study on factuality hallucination in large language models", "year": "2024"}, {"id": "2f231367b55f30186467158c644a9890c498e4cf", "title": "Gemini goes to med school: exploring the capabilities of multimodal large language models on medical challenge problems & hallucinations", "year": "2024"}, {"id": "4c3447dce6798b894313bb3ff2735ef139cbf071", "title": "PoLLMgraph: Unraveling Hallucinations in Large Language Models via State Transition Dynamics", "year": "2024"}, {"id": "4b0b56be0ae9479d2bd5c2f0943db1906343c10f", "title": "Chain-of-verification reduces hallucination in large language models", "year": "2023"}, {"id": "411b725522e2747e890ba5acfbf43d22f759c00a", "title": "Unsupervised real-time hallucination detection based on the internal states of large language models", "year": "2024"}], "2024.lrec-tutorials.13": [{"id": "b9b347dc13c416a1a1a80b4f9ddb0fe0aedf9ad7", "title": "Knowledge-enhanced Response Generation in Dialogue Systems: Current Advancements and Emerging Horizons", "year": "2024"}, {"id": "c3568b97005539cfaa6cd8e50b8b663e8cb032ac", "title": "Improving Context Understanding in Multimodal Large Language Models via Multimodal Composition Learning", "year": "al\u00a0\u2026"}], "2024.lrec-tutorials.2": [{"id": "af3388b61dc642b1d0be0c7147948fe800abb4c9", "title": "GRASP: A Disagreement Analysis Framework to Assess Group Associations in Perspectives", "year": "2024"}, {"id": "347192591d37037d19b59f98931f420d4a12c9b7", "title": "Uncovering Stereotypes in Large Language Models: A Task Complexity-based Approach", "year": "2024"}], "2024.lrec-tutorials.3": [{"id": "d9dc7d27ad31e977dec4f703bc75f699ae456f76", "title": "From discourse to logic: Introduction to modeltheoretic semantics of natural language, formal logic and discourse representation theory", "year": "eyle"}, {"id": "35751e6410682b4629ec79250f96cd7474196a27", "title": "Natural language processing", "year": "2020"}, {"id": "de4961a6431b9553d9f13319236570a9f033fcab", "title": "Understanding natural language", "year": "1972"}, {"id": "2a4e915fda85287f6165c04769dcc9ce92cdac98", "title": "Mental spaces: Aspects of meaning construction in natural language", "year": "nier"}, {"id": "abd0d4ed53a86f7af4674b838d590edff6edf9a4", "title": "Natural language processing: an introduction", "year": "2011"}, {"id": "2932a16f87dd9bad2cc59145a8263239c6a9cfcc", "title": "Conceptual dependency: A theory of natural language understanding", "year": "1972"}, {"id": "e72e5ee5de14fd463ab58ce830474157258e3578", "title": "Abstract meaning representation for sembanking", "year": "2013"}, {"id": "e75b3c12da067552fda910a5bbed8b4d0e82dbcb", "title": "Neural network methods for natural language processing", "year": "berg"}, {"id": "ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c", "title": "Supervised learning of universal sentence representations from natural language inference data", "year": "2017"}, {"id": "7602c565ee1f5345b4d114b42618d53780eaa4e2", "title": "A theory of truth and semantic representation", "year": "2013"}, {"id": "58daf6d9444631708e7328689396d0480056eeed", "title": "An overview of KRL, a knowledge representation language", "year": "1977"}, {"id": "b724783ffa9d9baea948107421baf9ba16e5bbd0", "title": "Pragmatics and natural language understanding", "year": "reen"}, {"id": "56edaa1368ff4dfa45388e4be24fdfbded7d88a7", "title": "A primer on neural network models for natural language processing", "year": "2016"}, {"id": "93b4cc549a1bc4bc112189da36c318193d05d806", "title": "Allennlp: A deep semantic natural language processing platform", "year": "2018"}, {"id": "f04df4e20a18358ea2f689b4c129781628ef7fc1", "title": "A large annotated corpus for learning natural language inference", "year": "2015"}, {"id": "dbe79abbbc1fc7df6ce90d263a363d99fabd3489", "title": "Natural language and natural selection", "year": "1990"}, {"id": "c3245983b40b3c9b90f62f50bbe99372c04e973d", "title": "Psychological aspects of natural language use: Our words, our selves", "year": "2003"}, {"id": "8862c1760476de1cf859e2a59998231e18e33317", "title": "Generalized quantifiers and natural language", "year": "1981"}, {"id": "795272f429be6bca08be4672c02c31174cd7675a", "title": "Evolving a Pipeline Approach for Abstract Meaning Representation Parsing Towards Dynamic Neural Networks.", "year": "2023"}, {"id": "bc1022b031dc6c7019696492e8116598097a8c12", "title": "Natural language processing (almost) from scratch", "year": "2011"}], "2024.lrec-tutorials.4": [{"id": "45a476cb04cccee74b9ddabce4d58d928be99f7d", "title": "Evaluating large language models: A comprehensive survey", "year": "2023"}, {"id": "888728745dbb769e29ed475d4f7661eebe1a71cf", "title": "A survey on evaluation of large language models", "year": "2024"}, {"id": "a1f76db91c0debcf93ae9889736bce8470902113", "title": "Large language models: A survey", "year": "2024"}, {"id": "5d4a6ce39cfe7bfc6305cba86464efff8bc20c97", "title": "A review on large Language Models: Architectures, applications, taxonomies, open issues and challenges", "year": "2024"}, {"id": "3e2734025037fc626873c56e05ddb43ccccd3858", "title": "A survey on large language models: Applications, challenges, limitations, and practical usage", "year": "2023"}, {"id": null, "title": "Large language models still can't plan (a benchmark for llms on planning and reasoning about change)", "year": "2022"}, {"id": "068ff3def994d1424832e1f56ed72ef8245a42f0", "title": "Inadequacies of large language model benchmarks in the era of generative artificial intelligence", "year": "2024"}, {"id": "24de1048791bac4972ecc16d1c3c1de23691407d", "title": "Large language models: a comprehensive survey of its applications, challenges, limitations, and future prospects", "year": "2023"}, {"id": "e850d4c0dad3aee3b8b40be5e5d5e5c31354d8cc", "title": "Planbench: An extensible benchmark for evaluating large language models on planning and reasoning about change", "year": "2024"}, {"id": null, "title": "Quick start guide to large language models: strategies and best practices for using ChatGPT and other LLMs", "year": "emir"}, {"id": "105669ec59a58fb2d4dd3021a984af33c227c5ab", "title": "Exploring the potential of large language models (llms) in learning on graphs", "year": "2024"}, {"id": "000f964393dafe113a8e66734d63b2a145844159", "title": "Large language models for software engineering: A systematic literature review", "year": "2023"}, {"id": "cbd81507197e2d32b6f6c8ac99039f3a607ee8f1", "title": "Verilogeval: Evaluating large language models for verilog code generation", "year": "2023"}, {"id": "6052486bc9144dc1730c12bf35323af3792a1fd0", "title": "Large language models encode clinical knowledge", "year": "2023"}, {"id": "4309d572a37d655779f9dce6a2c98c66334132de", "title": "Seed-bench: Benchmarking multimodal llms with generative comprehension", "year": "2023"}, {"id": "ac771182d1780c863954243809d1e144433919f9", "title": "Aligning large language models with human: A survey", "year": "2023"}, {"id": "378a545c3a1cf6c4aada8f9ee8820c0d8008220a", "title": "Benchmarking foundation models with language-model-as-an-examiner", "year": "2024"}, {"id": "b45ec1cb2ba6b2d1ac24723fa836aee06a3db97a", "title": "Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation", "year": "2024"}, {"id": "812b2662aa17fcd8021d99362723511b02791e46", "title": "Trustllm: Trustworthiness in large language models", "year": "2024"}, {"id": "28e2ecb4183ebc0eec504b12dddc677f8aef8745", "title": "Benchmarking large language models in retrieval-augmented generation", "year": "2024"}], "2024.lrec-tutorials.7": [{"id": "759526e9358e62fce56e44f3ae1db1a9afbda5e6", "title": "The DBpedia Technology Tutorial", "year": "2021"}, {"id": "b7a1dd2c7fc22377ccd16a4e71351e4d75eb4826", "title": "DBpedia FlexiFusion the best of Wikipedia> Wikidata> your data", "year": "2019"}, {"id": null, "title": "An approach to automatically update the Spanish DBpedia using DBpedia Databus", "year": "aoui"}, {"id": "20aa85c0b0b07c3bef15f435b9d5292781b7c751", "title": "The new dbpedia release cycle: Increasing agility and efficiency in knowledge extraction workflows", "year": "2020"}, {"id": "d58e5817a76f40d9d0d1460ccf7b6ca33e80378b", "title": "Semantic relatedness in DBpedia: A comparative and experimental assessment", "year": "2023"}, {"id": "94225d8458f29b032ddf28a6090b3a45d1ea542e", "title": "Embedding Knowledge Graphs with RDF2vec", "year": "isch"}, {"id": "0731544ac1570b63c9c851b07ae274d165cbb5b6", "title": "Structured knowledge creation for Urdu language: A DBpedia approach", "year": "2023"}, {"id": "f36a0c4cb8e084539311974fa40452b305840e93", "title": "Universal Knowledge Graph Embeddings", "year": "2024"}, {"id": "64bc7ec08e87b2943cf6242d53c6b3887707f5a2", "title": "DBpedia Archivo: a web-scale interface for ontology archiving under consumer-oriented aspects", "year": "2020"}, {"id": "80c0884380e44da849c1daebdcbc8471e2b3a8b7", "title": "Rdfframes: Knowledge graph access for machine learning tools", "year": "2020"}, {"id": "80c0884380e44da849c1daebdcbc8471e2b3a8b7", "title": "RDFFrames: knowledge graph access for machine learning tools", "year": "2022"}, {"id": "21f9009954a7d6a8ee6aa81ce4fe2effe47d3ed0", "title": "How does knowledge evolve in open knowledge graphs?", "year": "2023"}, {"id": "ef6c78270591f5723ffeb6714364fead03475b3c", "title": "Transforming Table to Knowledge Graph using A Rule-based Pipeline", "year": "2021"}, {"id": "94225d8458f29b032ddf28a6090b3a45d1ea542e", "title": "Embedding Knowledge Graphs with RDF2vec", "year": "isch"}, {"id": "abeeb2075b24f73d83527e8e08defd504b499011", "title": "Databus Mods-Linked Data-driven Enrichment of Metadata", "year": "ofer"}, {"id": "96189fdc8329e62d658bc14bf6e0d8a35547e53e", "title": "An analytical computing infrastructure for monitoring dynamic networks based on knowledge graphs", "year": "2020"}, {"id": null, "title": "Construction of Knowledge Graphs: Current State and Challenges", "year": "RN\u00a0\u2026"}, {"id": "d3d791af8405a73f3ccbf85b7e52b95c9b8f8c12", "title": "The graph of things: A step towards the live knowledge graph of connected things", "year": "2016"}, {"id": "12163999e9df4909dd6ca44f337d93e5349d23d1", "title": "Using embeddings to predict changes in large semantic graphs", "year": "2020"}, {"id": "7284af281373a151d2b1bb0746daed5fe250430f", "title": "SKG4EOSC-Scholarly Knowledge Graphs for EOSC: Establishing a backbone of knowledge graphs for FAIR Scholarly Information in EOSC", "year": "2022"}], "2024.lrec-tutorials.8": [{"id": "a66fc96952372b965f6b6d5acca080292c0e3e2f", "title": "ChemNLP: a natural language-processing-based library for materials chemistry text data", "year": "2023"}, {"id": "c20dd209bfe5fd9d5935a69ae00f3be8530b40e9", "title": "Exploring chemical space using natural language processing methodologies for drug discovery", "year": "2020"}, {"id": "7cd91e3ea97ff7366628370e46a69aaa046f7146", "title": "ChemicalTagger: A tool for semantic text-mining in chemistry", "year": "2011"}, {"id": "6424a6092c443cb10c39810d09471fb20e447091", "title": "A transfer learning protocol for chemical catalysis using a recurrent neural network adapted from natural language processing", "year": "2022"}, {"id": "e451e1717a8fd4238b7d36e06da478d2d3333f1a", "title": "Chemu 2020: Natural language processing methods are effective for information extraction from chemical patents", "year": "2021"}, {"id": "c09d2dca442e704d3dc1919d56974390fff61a19", "title": "Application of natural language processing in HAZOP reports", "year": "2021"}, {"id": "96186342c99763e3822ec1ef667d4c3df2500806", "title": "Using natural language processing techniques to extract information on the properties and functionalities of energetic materials from large text corpora", "year": "2019"}, {"id": "caab0d1913f44c361e865f408434ac06163a8dd2", "title": "Extraction of cyp chemical interactions from biomedical literature using natural language processing methods", "year": "2009"}, {"id": "0af28544a5b7854df8b3987d6f7618bafc0fd462", "title": "A natural language processing approach based on embedding deep learning from heterogeneous compounds for quantitative structure\u2013activity relationship modeling", "year": "2020"}, {"id": "0578dfb2a28b77abde19b32de777e0365df3020e", "title": "Data-driven materials research enabled by natural language processing and information extraction", "year": "2020"}, {"id": "b6cb6f1735953305470b9640f7012830a7b721f6", "title": "Using natural language processing techniques to inform research on nanotechnology", "year": "2015"}, {"id": "9d0b5ea23b78265906f28fb429693c87d56d3cd0", "title": "Knowledge acquisition from chemical accident databases using an ontology-based method and natural language processing", "year": "2020"}, {"id": "dce1d276586e4c7ef3a8ca64dc0615a4b9feece9", "title": "Treat molecular linear notations as sentences: accurate quantitative structure\u2013property relationship modeling via a natural language processing approach", "year": "2023"}, {"id": "36f6e6c951f87db6b4ef5b9c8d6d6e7d2a870834", "title": "NLP-inspired structural pattern recognition in chemical application", "year": "2014"}, {"id": "2c41acbc5896f9d95eff5917dd78fed9cfc11c31", "title": "Machine learning and natural language processing enable a data-oriented experimental design approach for producing biochar and hydrochar from biomass", "year": "2022"}, {"id": "42ef18d0911017102df9c028e84e363b3c880161", "title": "Question answering system for chemistry\u2014A semantic agent extension", "year": "2022"}, {"id": "2fc722cfabbad6d2f5c63368a7188f0595099459", "title": "Application of an automated natural language processing (NLP) workflow to enable federated search of external biomedical content in drug discovery and\u00a0\u2026", "year": "2016"}, {"id": "062b9f5148af8c53694c38d3905e3ef5f88a3b03", "title": "Question answering system for chemistry", "year": "2021"}, {"id": "b4354536b8259c147301cdc4468aa8fa67432437", "title": "How can natural language processing help model informed drug development?: a review", "year": "2022"}, {"id": "655d8c5ea0287f1cf703b1582a0c7dd81e33f367", "title": "Natural language processing in oncology: a review", "year": "2016"}], "2024.lrec-tutorials.9": [{"id": "e04a80263d252a3d8a382ba37a249b9345620570", "title": "Plug and play language models: A simple approach to controlled text generation", "year": "2019"}, {"id": "be8e58320203a92bfacc1a1f95f6e65f3ee4fa5c", "title": "A survey of controllable text generation using transformer-based pre-trained language models", "year": "2023"}, {"id": "b3c73de96640ee858f83c3f0eda2a3d15d59b847", "title": "Privacy risks of general-purpose language models", "year": "2020"}, {"id": "bc87279d4b32a425377ff18ab63f7ecf95ff228c", "title": "Rethinking embedding coupling in pre-trained language models", "year": "2020"}, {"id": "b21504732d3ccece1ccd1b2ac2f73e81aba0c20a", "title": "Embedding-based query language models", "year": "2016"}, {"id": "ccfa7a251644aafc7f85ca66c6652adfcf93429c", "title": "From word embeddings to pre-trained language models: A state-of-the-art walkthrough", "year": "2022"}, {"id": "a41cf8154a64fe95f9c362e5664aebb02b18ee85", "title": "Diachronic word embeddings and semantic shifts: a survey", "year": "2018"}, {"id": "cf8235e0b592f52848c3dc4a9b76222c25d172cb", "title": "Sgpt: Gpt sentence embeddings for semantic search", "year": "2022"}, {"id": "75669c9df94f992985ac3318a744c4f3feb132ef", "title": "Do multi-sense embeddings improve natural language understanding?", "year": "2015"}, {"id": "5df0b8b80aecda1efdebac5d1ab7bcf94a88c68f", "title": "Probing biomedical embeddings from language models", "year": "2019"}, {"id": "b15469d0ab3dc3a9dec037d761817b3fe546bed6", "title": "Pre-trained language models in biomedical domain: A systematic survey", "year": "2023"}, {"id": "ac879df2cc36f3f824fa24149517622b6bc7bd09", "title": "Implicit representations of meaning in neural language models", "year": "2021"}, {"id": "0c181f508ec9de8e48f62523ba8a9bcb1f51f83a", "title": "Pre-trained language models for text generation: A survey", "year": "2024"}, {"id": "79950179d60ba39a74d5fe2aedc47a57c0bf4c03", "title": "Unifiedskg: Unifying and multi-tasking structured knowledge grounding with text-to-text language models", "year": "2022"}, {"id": "56cafbac34f2bb3f6a9828cd228ff281b810d6bb", "title": "KEPLER: A unified model for knowledge embedding and pre-trained language representation", "year": "2021"}, {"id": "a5991db236c230b6e1dca0ddb8944cd478c20fa5", "title": "The expressive power of word embeddings", "year": "2013"}, {"id": "7d0c1cb43e8b398ad5b064e74f00802d4d585be6", "title": "Palmtree: Learning an assembly language model for instruction embedding", "year": "2021"}, {"id": "06a1bf4a7333bbc78dbd7470666b33bd9e26882b", "title": "Can you tell me how to get past sesame street? sentence-level pretraining beyond language modeling", "year": "2018"}, {"id": "a292a4a6f913cb4962936db8e44cf76019cfb69a", "title": "Contextual semantic embeddings for ontology subsumption prediction", "year": "2023"}, {"id": "02033e83ff310f35e4623bd339982c52d926f2d5", "title": "Chatgpt is not enough: Enhancing large language models with knowledge graphs for fact-aware language modeling", "year": "2023"}], "2024.naacl-tutorials.2": [{"id": "74a2ef37466667c843b6322691c49b0475030cb0", "title": "Security and privacy challenges of large language models: A survey", "year": "2024"}, {"id": "383c598625110e0a4c60da4db10a838ef822fbcf", "title": "A survey on large language model (llm) security and privacy: The good, the bad, and the ugly", "year": "2024"}, {"id": "1359b818543bfde35f0966b74612d18ae28ca41f", "title": "On protecting the data privacy of large language models (llms): A survey", "year": "2024"}, {"id": "25bf40ab1d5844039ee06aa4c6cdb03c6c65a335", "title": "Can large language models provide security & privacy advice? measuring the ability of llms to refute misconceptions", "year": "2023"}, {"id": "812b2662aa17fcd8021d99362723511b02791e46", "title": "Trustllm: Trustworthiness in large language models", "year": "2024"}, {"id": "afaad5ebbf8f037ada4d068eb2e804be08abeccb", "title": "Privacy-preserving large language models (PPLLMs)", "year": "2023"}, {"id": "3e2734025037fc626873c56e05ddb43ccccd3858", "title": "A survey on large language models: Applications, challenges, limitations, and practical usage", "year": "2023"}, {"id": null, "title": "Loose-lipped large language models spill your secrets: The privacy implications of large language models", "year": "2022"}, {"id": "24de1048791bac4972ecc16d1c3c1de23691407d", "title": "Large language models: a comprehensive survey of its applications, challenges, limitations, and future prospects", "year": "2023"}, {"id": "5d4a6ce39cfe7bfc6305cba86464efff8bc20c97", "title": "A review on large Language Models: Architectures, applications, taxonomies, open issues and challenges", "year": "2024"}, {"id": "1cef01ab4db546659f42de237a54dd510f9906cb", "title": "A new era in llm security: Exploring security concerns in real-world llm-based systems", "year": "2024"}, {"id": "030522cc114b93ec6cec078697caf241c407c4ce", "title": "Robustness, security, privacy, explainability, efficiency, and usability of large language models for code", "year": "2024"}, {"id": "7d46a13a1edd02dd6ae2b9f713e6f91ea001dfb4", "title": "When large language models meet personalization: Perspectives of challenges and opportunities", "year": "2024"}, {"id": "888728745dbb769e29ed475d4f7661eebe1a71cf", "title": "A survey on evaluation of large language models", "year": "2024"}, {"id": "c8996f183b883f4a16c05b4eaff2b892fb6bf57d", "title": "Large language models for education: A survey and outlook", "year": "2024"}, {"id": null, "title": "Ethical implications of large language models a multidimensional exploration of societal, economic, and technical concerns", "year": "2023"}, {"id": "1f1aefa3ae39eb0ef7285a2a075acfbf06b66e03", "title": "The ethics of interaction: Mitigating security threats in llms", "year": "2024"}, {"id": "6258f562e4c12864516f9d65698632f6741c354a", "title": "LLM-PBE: Assessing Data Privacy in Large Language Models", "year": "ang\u2026"}, {"id": "33112b58e3eb4a6506fa537d892dc6742c5e794d", "title": "Large language models in health care: Development, applications, and challenges", "year": "2023"}, {"id": "597cad6c7b9de94eecc153c7cdcaf824905fe915", "title": "You are what you write: Preserving privacy in the era of large language models", "year": "2022"}], "2024.naacl-tutorials.4": [{"id": "22e95cf15f2d92c6804d23c6d63fc98473507485", "title": "Diversity in the classrooms: A human-centered approach to schools", "year": "2020"}, {"id": "8c1eb46e735a4f6ccdd6e7804c0f38b7f384d3e9", "title": "From Text to Context: Contextualizing Language with Humans, Groups, and Communities for Socially Aware NLP", "year": "2024"}, {"id": "22e95cf15f2d92c6804d23c6d63fc98473507485", "title": "Diversity in the Classrooms: A Human-Centered Approach to Schools", "year": "2020"}, {"id": "d0612b2da897d7a653d0b88acd88a4003c4b787c", "title": "Community-based participatory research and human-centered design principles to advance hearing health equity", "year": "2022"}, {"id": "0d4487a1a130462a20e3be1f5ef88175df1cb119", "title": "Enhancing community-based participatory research through human-centered design strategies", "year": "2020"}, {"id": "e19b54ad4c1c8af045069e9cac350ffc2ce60e1a", "title": "No language left behind: Scaling human-centered machine translation", "year": "2022"}, {"id": "8bd7097ee1cc860d2a7bb63c978fe8efed64a959", "title": "Beyond Human-centered Design", "year": "2022"}, {"id": "9c724468e2d98d26afbd0d7eae2235f68fe043a8", "title": "Integrating Human-Centered Design and Social Science Research to Improve Service-Delivery and Empower Community Health Workers: Lessons from\u00a0\u2026", "year": "2023"}, {"id": "fb71f7eae8addb2903ebe9102c99d86fe398a9de", "title": "Smart CALL: Personalization, contextualization, & socialization", "year": "well"}, {"id": null, "title": "Online Design Thinking and Community-Based Learning: Co-Designing an Indigenous Curriculum to Help Redress Language Marginalization", "year": "2023"}, {"id": "1d61e75ee910b000e29768d7bbcb07f5194d1dd4", "title": "Higher education spaces and protracted displacement: How learner-centered pedagogies and human-centered design can unleash refugee innovation", "year": "2018"}, {"id": "d8d4f915e285072539003d356bf6587eb39222da", "title": "Language minorities' localization in COVID-19 recovery: An ecological approach to navigating community-based user experience", "year": "2021"}, {"id": "f31225dc4eef4d3024c32310f9ed87e71afcadfb", "title": "Human-Centered Privacy Research in the Age of Large Language Models", "year": "2024"}, {"id": "87dc51d88c3e792ab2072e0303f13ad954c300ef", "title": "Human-centered design for global health equity", "year": "2020"}, {"id": "ee87bf4752f0dce3eee978afcea643e7886d3cd6", "title": "Things we could design: For more than human-centered worlds", "year": "kary"}, {"id": null, "title": "Designing Education Contexts to Empower Students' Contextualization of Their Learning Experiences", "year": "Desk"}, {"id": "7432e4601834160213ce4d590a6e28603a69085a", "title": "Identifying barriers and facilitators along the hepatitis C care cascade to inform human-centered design of contextualized treatment protocols for vulnerable\u00a0\u2026", "year": "2023"}, {"id": "abb63e79b216d7e2dd80d4b3c031549b968bfe9c", "title": "Against method: The portability of method in human-centered design", "year": " Lee"}, {"id": null, "title": "Applying Human-Centered Design to Human Services: Pilot Study Findings", "year": "Boyd"}, {"id": null, "title": "The Role of Human-Centered AI in User Modeling, Adaptation, and Personalization\u2014Models, Frameworks, and Paradigms", "year": "2024"}], "2024.naacl-tutorials.5": [{"id": "d3640eb3b542eaf36fee2261f037a6bf0d8eac9c", "title": "Ai chains: Transparent and controllable human-ai interaction by chaining large language model prompts", "year": "2022"}, {"id": "47a5211f10c58c4187c95ce071418f0a0ef6d745", "title": "The Future of Large Language Models: A Futuristic Dissection on AI and Human Interaction", "year": "2023"}, {"id": "911bae2b36d64101a41c6aebde062e07853b3918", "title": "Understanding User Experience in Large Language Model Interactions", "year": "2024"}, {"id": "9a99f1476e4428837cf318fa1274ed6146339d39", "title": "Probing Language Models' Gesture Understanding for Enhanced Human-AI Interaction", "year": "2024"}, {"id": "f6f4d2ba05114b6237fbf351cc920b4f1f6f3dff", "title": "Leveraging Large Language Models (LLMs) to Support Collaborative Human-AI Online Risk Data Annotation", "year": "2024"}, {"id": "4b5b7f8ff26df8ef2aeb0ca7cbaa78f628077246", "title": "Human-Centered Explainable AI (HCXAI): Reloading Explainability in the Era of Large Language Models (LLMs)", "year": "2024"}, {"id": null, "title": "Exploring the role of large language model (llm)-based chatbots for human resources", "year": "ingh"}, {"id": "5d4a6ce39cfe7bfc6305cba86464efff8bc20c97", "title": "A review on large Language Models: Architectures, applications, taxonomies, open issues and challenges", "year": "2024"}, {"id": null, "title": "LLMEra: Impact of Large Language Models", "year": "2024"}, {"id": "784e03977f16b0b5a00c16523fdbcb9ffcefc545", "title": "Supporting human-ai collaboration in auditing llms with llms", "year": "2023"}, {"id": "b8640f172976258ec977ceb00e70676e451fb431", "title": "In-IDE Human-AI Experience in the Era of Large Language Models; A Literature Review", "year": "2024"}, {"id": "51ee30f09ccba1f603ac548b6badfdc83c72f1a2", "title": "Human-AI Interaction in the Age of LLMs", "year": "2024"}, {"id": null, "title": "Simulating Iterative Human-AI Interaction in Programming with LLMs", "year": "2023"}, {"id": "a564f775a04a0cf5f30bfed1f48d4d18b37cdbcb", "title": "A proactive system for supporting users in interactions with large language models", "year": "2024"}, {"id": "2b5d234efd26e7377698cf16c901601a3d3c4e56", "title": "Coauthor: Designing a human-ai collaborative writing dataset for exploring language model capabilities", "year": "2022"}, {"id": "8f041c03023f46a74cc32cc408c89897b7e2059b", "title": "\u201cAs an AI language model, I cannot\u201d: Investigating LLM Denials of User Requests", "year": "2024"}, {"id": "f31225dc4eef4d3024c32310f9ed87e71afcadfb", "title": "Human-Centered Privacy Research in the Age of Large Language Models", "year": "2024"}, {"id": null, "title": "Human-ai interactions in the communication era: Autophagy makes large models achieving local optima", "year": "2024"}, {"id": "5a9ce2055a0f200fd53b7eeddf1c05f9e01ccf5a", "title": "Large language models and games: A survey and roadmap", "year": "2024"}, {"id": null, "title": "A human-centered approach to designing effective large language model (llm) based tools for writing software tutorials", "year": "Bhat"}], "P19-4004": [{"id": "b9921fb4d1448058642897797e77bdaf8f444404", "title": "Text as data: The promise and pitfalls of automatic content analysis methods for political texts", "year": "2013"}, {"id": "7d9cc63dfbd34acf271e3a2c922ea1c07fb2f482", "title": "Extracting policy positions from political texts using words as data", "year": "2003"}, {"id": "3e4a35ced9f7f81179028671b09129efae988baf", "title": "Predicting elections with twitter: What 140 characters reveal about political sentiment", "year": "2010"}, {"id": "77741d65afc5486ed806cda1967de76372dab7ba", "title": "Political analysis", "year": " Hay"}, {"id": "4d67e9db6229be9c24d7c60e79261d5be3a6bb78", "title": "Political discourse analysis: A method for advanced students", "year": "ough"}, {"id": "f87a322854eaf8920ec31d0e3052c07695a26057", "title": "Text and corpus analysis: Computer-assisted studies of language and culture", "year": "ubbs"}, {"id": "5b133516ba669169e8145f2a2379a9f9296b3803", "title": "Discourse and text: Linguistic and intertextual analysis within discourse analysis", "year": "1992"}, {"id": "40b2324cde863db7670178f0151fae400a9a2b93", "title": "Analyzing incomplete political science data: An alternative algorithm for multiple imputation", "year": "2001"}, {"id": "aceee0cbbaa6767084ff302b724f07d18d832c2f", "title": "Qualitative text analysis: A guide to methods, practice and using software", "year": "artz"}, {"id": "cb42704113df4cbff874806cdf4a9f05d5f8065f", "title": "Coh-Metrix: Analysis of text on cohesion and language", "year": "2004"}, {"id": "571c89c796c258ea7b17d4bff6f1e682a8cac669", "title": "Fitting equations to data: computer analysis of multifactor data", "year": "Wood"}, {"id": "3d7aca95ee1107ba69832f0860dc3f0c1ac535e7", "title": "Content analysis", "year": "1989"}, {"id": "297d01ff6731c3bd917ede3d378c94cb84650e8f", "title": "Opinion mining and sentiment analysis", "year": "2008"}, {"id": "bcdc102c04fb0e7d4652e8bcc7edd2983bb9576d", "title": "Vader: A parsimonious rule-based model for sentiment analysis of social media text", "year": "2014"}, {"id": "31090ca45da8638ce70684219cb307f4408418fd", "title": "Qualitative analysis", "year": "Ezzy"}, {"id": "b91a36398ebe174f4044eb88debb2c26a335fd33", "title": "Arlequin suite ver 3.5: a new series of programs to perform population genetics analyses under Linux and Windows", "year": "2010"}, {"id": "71171f8d34d0eec5630a16fff239c978fe53c383", "title": "Quantitative analysis of culture using millions of digitized books", "year": "2011"}, {"id": "25075e27b0df6f2be5a8c519171bdabd1c3ed817", "title": "Content analysis: An introduction to its methodology", "year": "orff"}, {"id": "8e7a1afec23b2cb5be827be62d9fa232ace09514", "title": "Framing analysis: An approach to news discourse", "year": "1993"}, {"id": "e9db152bb768ba947d735a9da04f338a51cb3cd9", "title": "The Galaxy platform for accessible, reproducible and collaborative biomedical analyses: 2016 update", "year": "2016"}]}