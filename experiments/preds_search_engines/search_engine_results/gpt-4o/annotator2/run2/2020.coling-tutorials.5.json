[
  {
    "title": [
      "Sure, here is a reading list of 20 articles up to 2020 that cover existing datasets for Question Answering (QA"
    ],
    "container-title": [
      "Natural Language Inference (NLI), and commonsense reasoning"
    ],
    "type": "chapter"
  },
  {
    "citation-number": [
      "1."
    ],
    "title": [
      "**\"SQuAD: 100,000+ Questions for Machine Comprehension of Text\"** - Rajpurkar et al"
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "note": [
      "- Dataset: Stanford Question Answering Dataset (SQuAD"
    ],
    "type": null
  },
  {
    "citation-number": [
      "2."
    ],
    "title": [
      "**\"TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension\"**"
    ],
    "date": [
      "2017"
    ],
    "type": "article-journal",
    "container-title": [
      "Joshi et al"
    ]
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Dataset: TriviaQA"
    ],
    "type": null
  },
  {
    "citation-number": [
      "3."
    ],
    "title": [
      "**\"QuAC: Question Answering in Context\"** - Choi et al"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Dataset: QuAC"
    ],
    "type": null
  },
  {
    "citation-number": [
      "4."
    ],
    "title": [
      "**\"CoQA: A Conversational Question Answering Challenge\"** - Reddy et al"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Dataset: CoQA"
    ],
    "type": null
  },
  {
    "citation-number": [
      "5."
    ],
    "title": [
      "**\"Natural Questions: A Benchmark for Question Answering Research\"**"
    ],
    "date": [
      "2019"
    ],
    "type": "article-journal",
    "container-title": [
      "Kwiatkowski et al"
    ]
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Dataset: Natural Questions"
    ],
    "type": null
  },
  {
    "citation-number": [
      "6."
    ],
    "title": [
      "**\"HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering\"**"
    ],
    "date": [
      "2018"
    ],
    "type": "article-journal",
    "container-title": [
      "Yang et al"
    ]
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Dataset: HotpotQA"
    ],
    "type": null
  },
  {
    "citation-number": [
      "7."
    ],
    "title": [
      "**\"DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs\"**"
    ],
    "date": [
      "2019"
    ],
    "type": "article-journal",
    "container-title": [
      "Dua et al"
    ]
  },
  {
    "citation-number": [
      "-"
    ],
    "location": [
      "Dataset"
    ],
    "publisher": [
      "DROP"
    ],
    "type": "book"
  },
  {
    "citation-number": [
      "8."
    ],
    "title": [
      "**\"SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference\"** - Zellers et al"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "citation-number": [
      "-"
    ],
    "location": [
      "Dataset"
    ],
    "publisher": [
      "SWAG"
    ],
    "type": "book"
  },
  {
    "citation-number": [
      "9."
    ],
    "title": [
      "**\"CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge\"** - Talmor et al"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Dataset: CommonsenseQA"
    ],
    "type": null
  },
  {
    "citation-number": [
      "10."
    ],
    "author": [
      {
        "literal": "**\"Winograd Schema Challenge\"** - Levesque et al."
      }
    ],
    "date": [
      "2012"
    ],
    "type": null
  },
  {
    "citation-number": [
      "-"
    ],
    "location": [
      "Dataset"
    ],
    "publisher": [
      "Winograd Schema Challenge"
    ],
    "type": "book"
  },
  {
    "citation-number": [
      "11."
    ],
    "title": [
      "**\"The Stanford Natural Language Inference (SNLI) Corpus\"** - Bowman et al"
    ],
    "date": [
      "2015"
    ],
    "type": null
  },
  {
    "citation-number": [
      "-"
    ],
    "location": [
      "Dataset"
    ],
    "publisher": [
      "SNLI"
    ],
    "type": "book"
  },
  {
    "citation-number": [
      "12."
    ],
    "title": [
      "**\"MultiNLI: The Stanford Natural Language Inference Corpus\"** - Williams et al"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Dataset: MultiNLI"
    ],
    "type": null
  },
  {
    "citation-number": [
      "13."
    ],
    "title": [
      "**\"SciTail: A Textual Entailment Dataset from Science Question Answering\"** - Khot et al"
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Dataset: SciTail"
    ],
    "type": null
  },
  {
    "citation-number": [
      "14."
    ],
    "title": [
      "**\"Adversarial NLI: A New Benchmark for Natural Language Understanding\"** - Nie et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "citation-number": [
      "-"
    ],
    "location": [
      "Dataset"
    ],
    "publisher": [
      "ANLI"
    ],
    "type": "book"
  },
  {
    "citation-number": [
      "15."
    ],
    "title": [
      "**\"Story Cloze Test: A corpus for research on understanding and generating coherent stories\"** - Mostafazadeh et al"
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "citation-number": [
      "-"
    ],
    "location": [
      "Dataset"
    ],
    "publisher": [
      "Story Cloze Test"
    ],
    "type": "book"
  },
  {
    "citation-number": [
      "16."
    ],
    "author": [
      {
        "given": "R.A.C.E."
      }
    ],
    "title": [
      "Large-scale ReAding Comprehension Dataset From Examinations\"** - Lai et al"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "citation-number": [
      "-"
    ],
    "location": [
      "Dataset"
    ],
    "publisher": [
      "RACE"
    ],
    "type": "book"
  },
  {
    "citation-number": [
      "17."
    ],
    "author": [
      {
        "family": "Cosmos",
        "given": "Q.A."
      }
    ],
    "title": [
      "Machine Reading Comprehension with Contextual Commonsense Reasoning\"** - Huang et al"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Dataset: Cosmos QA"
    ],
    "type": null
  },
  {
    "citation-number": [
      "18."
    ],
    "title": [
      "**\"Social IQa: Commonsense Reasoning about Social Interactions\"** - Sap et al"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Dataset: Social IQa"
    ],
    "type": null
  },
  {
    "citation-number": [
      "19."
    ],
    "container-title": [
      "**\"OpenBookQA: Open Book Question Answering\"** - Mihaylov et al"
    ],
    "date": [
      "2018"
    ],
    "type": "chapter"
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Dataset: OpenBookQA"
    ],
    "type": null
  },
  {
    "citation-number": [
      "20."
    ],
    "author": [
      {
        "given": "BoolQ"
      }
    ],
    "title": [
      "Exploring the Surprising Difficulty of Natural Yes/No Questions\"**"
    ],
    "publisher": [
      "Clark et al"
    ],
    "date": [
      "2019"
    ],
    "type": "book"
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Dataset: BoolQ"
    ],
    "type": null
  },
  {
    "title": [
      "These articles and datasets provide a comprehensive overview of the landscape of QA, NLI, and commonsense reasoning up to"
    ],
    "date": [
      "2020"
    ],
    "type": null
  }
]
