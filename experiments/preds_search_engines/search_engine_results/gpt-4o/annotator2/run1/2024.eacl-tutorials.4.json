[
  {
    "title": [
      "Sure, here is a list of 20 articles on interpretability methods for transformers that you can explore"
    ],
    "type": null
  },
  {
    "citation-number": [
      "1."
    ],
    "author": [
      {
        "family": "Jain",
        "given": "S.",
        "particle": "Attention is not Explanation\" by"
      },
      {
        "family": "Wallace",
        "given": "B.C."
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "2."
    ],
    "title": [
      "**\"A Closer Look at the Robustness of Vision Transformers\"** by Paul, S., et al"
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "citation-number": [
      "3."
    ],
    "title": [
      "**\"Explaining in Style: Training a GAN to explain a classifier in StyleSpace\"**"
    ],
    "editor": [
      {
        "family": "Lang",
        "given": "O.",
        "particle": "by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "citation-number": [
      "4."
    ],
    "title": [
      "**\"Transformers Interpretability Beyond Attention Visualization\"** by Chefer, H., et al"
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "citation-number": [
      "5."
    ],
    "title": [
      "**\"Explaining Transformers for Image Recognition\"** by Chefer, H., et al"
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "citation-number": [
      "6."
    ],
    "author": [
      {
        "family": "Wiegreffe",
        "given": "Attention Interpretability Across N.L.P.Tasks\"",
        "particle": "by"
      },
      {
        "given": "S."
      },
      {
        "family": "Pinter",
        "given": "Y."
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "7."
    ],
    "title": [
      "**\"Towards Robust Interpretability with Self-Explaining Neural Networks\"** by Alvarez-Melis"
    ],
    "editor": [
      {
        "given": "D."
      },
      {
        "family": "Jaakkola",
        "given": "T.S."
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "citation-number": [
      "8."
    ],
    "title": [
      "**\"Interpretable and Explainable Deep Learning: A Survey\"**"
    ],
    "editor": [
      {
        "family": "Zhang",
        "given": "Q.",
        "particle": "by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "citation-number": [
      "9."
    ],
    "title": [
      "**\"Visualizing and Understanding Neural Models in NLP\"**"
    ],
    "editor": [
      {
        "family": "Li",
        "given": "J.",
        "particle": "by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "citation-number": [
      "10."
    ],
    "title": [
      "**\"Attention-based Interpretability with Applications to Sentiment Analysis\"**"
    ],
    "editor": [
      {
        "family": "Lin",
        "given": "Z.",
        "particle": "by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "citation-number": [
      "11."
    ],
    "title": [
      "**\"Explaining and Harnessing Adversarial Examples\"** by Goodfellow"
    ],
    "editor": [
      {
        "given": "I.J."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2015"
    ],
    "type": null
  },
  {
    "citation-number": [
      "12."
    ],
    "title": [
      "**\"The Building Blocks of Interpretability\"**"
    ],
    "editor": [
      {
        "family": "Olah",
        "given": "C.",
        "particle": "by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "citation-number": [
      "13."
    ],
    "title": [
      "**\"Integrated Gradients: A Theory of Attribution for Deep Networks\"** by Sundararajan"
    ],
    "editor": [
      {
        "given": "M."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "citation-number": [
      "14."
    ],
    "title": [
      "**\"Learning Important Features Through Propagating Activation Differences\"** by Shrikumar, A., et al"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "citation-number": [
      "15."
    ],
    "author": [
      {
        "given": "DeepLIFT"
      }
    ],
    "title": [
      "Learning Important Features Through Propagating Activation Differences\"** by Shrikumar, A., et al"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "citation-number": [
      "16."
    ],
    "title": [
      "**\"Axiomatic Attribution for Deep Networks\"** by Sundararajan"
    ],
    "editor": [
      {
        "given": "M."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "citation-number": [
      "17."
    ],
    "title": [
      "**\"Interpretable Machine Learning: A Guide for Making Black Box Models Explainable\"** by Molnar"
    ],
    "volume": [
      "C"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "18."
    ],
    "title": [
      "**\"Explainable AI: Interpreting, Explaining and Visualizing Deep Learning\"**"
    ],
    "editor": [
      {
        "family": "Samek",
        "given": "W.",
        "particle": "by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "19."
    ],
    "title": [
      "**\"Towards Explainable AI: Interpreting and Visualizing Deep Learning Models\"**"
    ],
    "editor": [
      {
        "family": "Montavon",
        "given": "G.",
        "particle": "by"
      },
      {
        "others": true
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "citation-number": [
      "20."
    ],
    "title": [
      "**\"Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI\"** by Arrieta, A.B., et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "title": [
      "These articles cover a range of interpretability methods and techniques specifically for transformers and deep learning models in general. They provide a comprehensive understanding of the current state of research in this area and offer insights into various approaches to making these models more interpretable"
    ],
    "type": null
  }
]
