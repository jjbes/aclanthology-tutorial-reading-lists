[
  {
    "title": [
      "Sure, here is a reading list of 20 articles on LLM-driven instruction following up to 2023"
    ],
    "type": null
  },
  {
    "citation-number": [
      "1."
    ],
    "author": [
      {
        "family": "Brown",
        "given": "T.B."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Language Models are Few-Shot Learners.\"**"
    ],
    "note": [
      "arXiv preprint arXiv:2005.14165."
    ],
    "arxiv": [
      "2005.14165"
    ],
    "type": null
  },
  {
    "citation-number": [
      "2."
    ],
    "author": [
      {
        "family": "Raffel",
        "given": "C."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.\"**"
    ],
    "volume": [
      "21"
    ],
    "pages": [
      "1–67"
    ],
    "type": "article-journal",
    "container-title": [
      "Journal of Machine Learning Research"
    ],
    "issue": [
      "140"
    ]
  },
  {
    "citation-number": [
      "3."
    ],
    "author": [
      {
        "family": "Radford",
        "given": "A."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Language Models are Unsupervised Multitask Learners.\"** OpenAI Blog"
    ],
    "type": null
  },
  {
    "citation-number": [
      "4."
    ],
    "author": [
      {
        "family": "Devlin",
        "given": "J."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\"** NAACL-HLT"
    ],
    "type": null
  },
  {
    "citation-number": [
      "5."
    ],
    "author": [
      {
        "family": "Vaswani",
        "given": "A."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2017"
    ],
    "title": [
      "Attention is All You Need.\"** Advances in Neural Information Processing Systems"
    ],
    "type": null
  },
  {
    "citation-number": [
      "6."
    ],
    "author": [
      {
        "family": "Zhang",
        "given": "Y."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Dialogpt: Large-scale generative pre-training for conversational response generation.\"**"
    ],
    "note": [
      "arXiv preprint arXiv:1911.00536."
    ],
    "arxiv": [
      "1911.00536"
    ],
    "type": null
  },
  {
    "citation-number": [
      "7."
    ],
    "author": [
      {
        "family": "Gao",
        "given": "T."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2021"
    ],
    "title": [
      "Making pre-trained language models better few-shot learners.\"**"
    ],
    "note": [
      "arXiv preprint arXiv:2012.15723."
    ],
    "arxiv": [
      "2012.15723"
    ],
    "type": null
  },
  {
    "citation-number": [
      "8."
    ],
    "author": [
      {
        "family": "Wei",
        "given": "J."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2022"
    ],
    "title": [
      "Chain of Thought Prompting Elicits Reasoning in Large Language Models.\"**"
    ],
    "note": [
      "arXiv preprint arXiv:2201.11903."
    ],
    "arxiv": [
      "2201.11903"
    ],
    "type": null
  },
  {
    "citation-number": [
      "9."
    ],
    "author": [
      {
        "family": "Ouyang",
        "given": "L."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2022"
    ],
    "title": [
      "Training language models to follow instructions with human feedback.\"**"
    ],
    "note": [
      "arXiv preprint arXiv:2203.02155."
    ],
    "arxiv": [
      "2203.02155"
    ],
    "type": null
  },
  {
    "citation-number": [
      "10."
    ],
    "author": [
      {
        "family": "Schick",
        "given": "T."
      },
      {
        "family": "Schütze",
        "given": "H."
      }
    ],
    "date": [
      "2021"
    ],
    "title": [
      "Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference.\"** EACL"
    ],
    "type": null
  },
  {
    "citation-number": [
      "11."
    ],
    "author": [
      {
        "family": "Ziegler",
        "given": "D.M."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Fine-Tuning Language Models from Human Preferences.\"**"
    ],
    "note": [
      "arXiv preprint arXiv:1909.08593."
    ],
    "arxiv": [
      "1909.08593"
    ],
    "type": null
  },
  {
    "citation-number": [
      "12."
    ],
    "author": [
      {
        "family": "Stiennon",
        "given": "N."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Learning to summarize with human feedback.\"** Advances in Neural Information Processing Systems"
    ],
    "type": null
  },
  {
    "citation-number": [
      "13."
    ],
    "author": [
      {
        "family": "Kenton",
        "given": "J.D."
      },
      {
        "family": "Toutanova",
        "given": "K."
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\"**"
    ],
    "note": [
      "arXiv preprint arXiv:1810.04805."
    ],
    "arxiv": [
      "1810.04805"
    ],
    "type": null
  },
  {
    "citation-number": [
      "14."
    ],
    "author": [
      {
        "family": "Radford",
        "given": "A."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2021"
    ],
    "title": [
      "Learning Transferable Visual Models From Natural Language Supervision.\"**"
    ],
    "note": [
      "arXiv preprint arXiv:2103.00020."
    ],
    "arxiv": [
      "2103.00020"
    ],
    "type": null
  },
  {
    "citation-number": [
      "15."
    ],
    "author": [
      {
        "family": "Xu",
        "given": "J."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2022"
    ],
    "title": [
      "Learning to Follow Instructions"
    ],
    "note": [
      "in Text-based Games.\"** arXiv preprint arXiv:2206.01494."
    ],
    "arxiv": [
      "2206.01494"
    ],
    "type": null
  },
  {
    "citation-number": [
      "16."
    ],
    "author": [
      {
        "family": "Liu",
        "given": "P."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2021"
    ],
    "title": [
      "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing.\"**"
    ],
    "note": [
      "arXiv preprint arXiv:2107.13586."
    ],
    "arxiv": [
      "2107.13586"
    ],
    "type": null
  },
  {
    "citation-number": [
      "17."
    ],
    "author": [
      {
        "family": "Gururangan",
        "given": "S."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks.\"** ACL"
    ],
    "type": null
  },
  {
    "citation-number": [
      "18."
    ],
    "author": [
      {
        "family": "Levine",
        "given": "S."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2022"
    ],
    "title": [
      "Offline Reinforcement Learning: Tutorial"
    ],
    "note": [
      "and Perspectives on Open Problems.\"** arXiv preprint arXiv:2005.01643."
    ],
    "type": "article-journal",
    "container-title": [
      "Review"
    ],
    "arxiv": [
      "2005.01643"
    ]
  },
  {
    "citation-number": [
      "19."
    ],
    "author": [
      {
        "family": "Zellers",
        "given": "R."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Defending Against Neural Fake News.\"** NeurIPS"
    ],
    "type": null
  },
  {
    "citation-number": [
      "20."
    ],
    "author": [
      {
        "family": "Bommasani",
        "given": "R."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2021"
    ],
    "title": [
      "On the Opportunities and Risks of Foundation Models.\"**"
    ],
    "note": [
      "arXiv preprint arXiv:2108.07258."
    ],
    "arxiv": [
      "2108.07258"
    ],
    "type": null
  },
  {
    "title": [
      "These articles cover a range of topics related to LLM-driven instruction following, including foundational models, few-shot learning, human feedback, and specific applications in text-based games and summarization"
    ],
    "type": null
  }
]
