Certainly! Here is a list of 20 articles up to 2020 that cover existing datasets for Question Answering (QA), Natural Language Inference (NLI), and commonsense reasoning:

### Question Answering (QA)
1. **SQuAD: 100,000+ Questions for Machine Comprehension of Text**  
   Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang  
   *arXiv preprint arXiv:1606.05250* (2016)

2. **TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension**  
   Mandar Joshi, Eunsol Choi, Daniel S. Weld, Luke Zettlemoyer  
   *arXiv preprint arXiv:1705.03551* (2017)

3. **QuAC: Question Answering in Context**  
   Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Yejin Choi, Percy Liang, Luke Zettlemoyer  
   *EMNLP* (2018)

4. **DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs**  
   Danqi Chen, Adam Fisch, Jason Weston, Antoine Bordes  
   *NAACL* (2019)

5. **Natural Questions: A Benchmark for Question Answering Research**  
   Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, Slav Petrov  
   *Transactions of the Association for Computational Linguistics* (2019)

### Natural Language Inference (NLI)
6. **A Large Annotated Corpus for Learning Natural Language Inference**  
   Samuel R. Bowman, Gabor Angeli, Christopher Potts, Christopher D. Manning  
   *EMNLP* (2015)

7. **MultiNLI: The Stanford Natural Language Inference Corpus**  
   Samuel R. Bowman, Jon Gauthier, Abhinav Rastogi, Raghav Gupta, Christopher D. Manning, Christopher Potts  
   *arXiv preprint arXiv:1704.05426* (2017)

8. **SciTail: A Textual Entailment Dataset from Science Question Answering**  
   Tushar Khot, Ashish Sabharwal, Peter Clark  
   *AAAI* (2018)

9. **Adversarial NLI: A New Benchmark for Natural Language Understanding**  
   Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, Douwe Kiela  
   *arXiv preprint arXiv:1910.14599* (2019)

10. **XNLI: Evaluating Cross-lingual Sentence Representations**  
    Alexis Conneau, Ruty Rinott, Guillaume Lample, Adina Williams, Samuel R. Bowman, Holger Schwenk, Veselin Stoyanov  
    *EMNLP* (2018)

### Commonsense Reasoning
11. **SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference**  
    Rowan Zellers, Yonatan Bisk, Roy Schwartz, Yejin Choi  
    *EMNLP* (2018)

12. **CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge**  
    Alon Talmor, Jonathan Herzig, Nicholas Lourie, Jonathan Berant  
    *NAACL* (2019)

13. **Social IQa: Commonsense Reasoning about Social Interactions**  
    Maarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, Yejin Choi  
    *EMNLP* (2019)

14. **Cosmos QA: Machine Reading Comprehension with Contextual Commonsense Reasoning**  
    Alon Y. Halevy, Peter Norvig, Fernando Pereira  
    *EMNLP-IJCNLP* (2019)

15. **Winograd Schema Challenge: Evaluating Progress in Commonsense Reasoning**  
    Hector J. Levesque, Ernest Davis, Leora Morgenstern  
    *AAAI* (2012)

### Mixed or Related Areas
16. **GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding**  
    Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R. Bowman  
    *ICLR* (2019)

17. **SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems**  
    Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R. Bowman  
    *NeurIPS* (2019)

18. **RACE: Large-scale ReAding Comprehension Dataset From Examinations**  
    Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, Eduard Hovy  
    *EMNLP* (2017)

19. **CoQA: A Conversational Question Answering Challenge**  
    Siva Reddy, Danqi Chen, Christopher D. Manning  
    *TACL* (2019)

20. **BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions**  
    Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, Kristina Toutanova  
    *NAACL* (2019)

These articles should provide a comprehensive overview of the key datasets and benchmarks in the fields of QA, NLI, and commonsense reasoning up to the year 2020.