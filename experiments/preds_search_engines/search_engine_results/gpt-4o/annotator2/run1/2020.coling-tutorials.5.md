Sure! Here's a reading list of 20 articles up to 2020 that cover existing datasets for Question Answering (QA), Natural Language Inference (NLI), and commonsense reasoning:

### Question Answering (QA)
1. **SQuAD: 100,000+ Questions for Machine Comprehension of Text**
   - Rajpurkar, Pranav, et al. (2016)
   - URL: https://arxiv.org/abs/1606.05250

2. **TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension**
   - Joshi, Mandar, et al. (2017)
   - URL: https://arxiv.org/abs/1705.03551

3. **Natural Questions: A Benchmark for Question Answering Research**
   - Kwiatkowski, Tom, et al. (2019)
   - URL: https://arxiv.org/abs/1906.00300

4. **CoQA: A Conversational Question Answering Challenge**
   - Reddy, Siva, et al. (2018)
   - URL: https://arxiv.org/abs/1808.07042

5. **HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering**
   - Yang, Zhiyu, et al. (2018)
   - URL: https://arxiv.org/abs/1809.09600

### Natural Language Inference (NLI)
6. **A Large Annotated Corpus for Learning Natural Language Inference**
   - Bowman, Samuel R., et al. (2015)
   - URL: https://arxiv.org/abs/1508.05326

7. **MultiNLI: The Stanford Natural Language Inference Corpus**
   - Williams, Adina, et al. (2018)
   - URL: https://arxiv.org/abs/1704.05426

8. **SciTail: A Textual Entailment Dataset from Science Question Answering**
   - Khot, Tushar, et al. (2018)
   - URL: https://arxiv.org/abs/1804.07723

9. **Adversarial NLI: A New Benchmark for Natural Language Understanding**
   - Nie, Yixin, et al. (2020)
   - URL: https://arxiv.org/abs/1910.14599

10. **XNLI: Evaluating Cross-lingual Sentence Representations**
    - Conneau, Alexis, et al. (2018)
    - URL: https://arxiv.org/abs/1809.05053

### Commonsense Reasoning
11. **CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge**
    - Talmor, Alon, et al. (2018)
    - URL: https://arxiv.org/abs/1811.00937

12. **SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference**
    - Zellers, Rowan, et al. (2018)
    - URL: https://arxiv.org/abs/1808.05326

13. **Winograd Schema Challenge: Toward Human-Level Commonsense Reasoning**
    - Levesque, Hector J., et al. (2012)
    - URL: https://www.aaai.org/ocs/index.php/KR/KR12/paper/view/4492

14. **SocialIQA: Commonsense Reasoning about Social Interactions**
    - Sap, Maarten, et al. (2019)
    - URL: https://arxiv.org/abs/1904.09728

15. **Cosmos QA: Machine Reading Comprehension with Contextual Commonsense Reasoning**
    - Huang, Sheng-Chieh, et al. (2019)
    - URL: https://arxiv.org/abs/1909.00277

### Mixed/General
16. **GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding**
    - Wang, Alex, et al. (2018)
    - URL: https://arxiv.org/abs/1804.07461

17. **SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems**
    - Wang, Alex, et al. (2019)
    - URL: https://arxiv.org/abs/1905.00537

18. **RACE: Large-scale ReAding Comprehension Dataset From Examinations**
    - Lai, Guokun, et al. (2017)
    - URL: https://arxiv.org/abs/1704.04683

19. **DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs**
    - Dua, Dheeru, et al. (2019)
    - URL: https://arxiv.org/abs/1903.00161

20. **QuAC: Question Answering in Context**
    - Choi, Eunsol, et al. (2018)
    - URL: https://arxiv.org/abs/1808.07036

These articles provide a comprehensive overview of various datasets used in QA, NLI, and commonsense reasoning tasks, and are essential readings for anyone interested in these areas of natural language processing.