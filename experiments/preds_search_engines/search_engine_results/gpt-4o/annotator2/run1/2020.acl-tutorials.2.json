[
  {
    "author": [
      {
        "given": "Certainly!"
      }
    ],
    "title": [
      "Here is a reading list of 20 articles up to 2020 that focus on integrating ethics into the Natural Language Processing (NLP) curriculum"
    ],
    "type": null
  },
  {
    "citation-number": [
      "1."
    ],
    "author": [
      {
        "family": "Bender",
        "given": "E.M."
      },
      {
        "family": "Friedman",
        "given": "B."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "Data Statements for NLP: Toward Mitigating System Bias and Enabling Better Science"
    ],
    "volume": [
      "6"
    ],
    "pages": [
      "587–604"
    ],
    "type": "article-journal",
    "container-title": [
      "Transactions of the Association for Computational Linguistics"
    ]
  },
  {
    "citation-number": [
      "2."
    ],
    "author": [
      {
        "family": "Hovy",
        "given": "D."
      },
      {
        "family": "Spruit",
        "given": "S.L."
      }
    ],
    "date": [
      "2016"
    ],
    "title": [
      "The Social Impact of Natural Language Processing"
    ],
    "container-title": [
      "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers"
    ],
    "pages": [
      "591–598"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "3."
    ],
    "author": [
      {
        "family": "Crawford",
        "given": "K."
      },
      {
        "family": "Calo",
        "given": "R."
      }
    ],
    "date": [
      "2016"
    ],
    "title": [
      "There is a Blind Spot in AI Research"
    ],
    "volume": [
      "538"
    ],
    "pages": [
      "311–313"
    ],
    "type": "article-journal",
    "container-title": [
      "Nature"
    ],
    "issue": [
      "7625"
    ]
  },
  {
    "citation-number": [
      "4."
    ],
    "author": [
      {
        "family": "Green",
        "given": "B."
      },
      {
        "family": "Hu",
        "given": "L."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "The Myth in the Methodology: Towards a Recontextualization of Fairness in Machine Learning"
    ],
    "container-title": [
      "Proceedings of the Machine Learning: The Debates Workshop at ICML"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "5."
    ],
    "author": [
      {
        "literal": "Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., Daumé III, H., & Crawford, K."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "Datasheets for Datasets"
    ],
    "note": [
      "arXiv preprint arXiv:1803.09010."
    ],
    "arxiv": [
      "1803.09010"
    ],
    "type": null
  },
  {
    "citation-number": [
      "6."
    ],
    "author": [
      {
        "literal": "Blodgett, S. L., Barocas, S., Daumé III, H., & Wallach, H."
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Language (Technology) is Power: A Critical Survey of 'Bias' in NLP"
    ],
    "container-title": [
      "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"
    ],
    "pages": [
      "5454–5476"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "7."
    ],
    "author": [
      {
        "family": "Binns",
        "given": "R."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "Fairness in Machine Learning: Lessons from Political Philosophy"
    ],
    "container-title": [
      "Proceedings of the 2018 Conference on Fairness, Accountability, and Transparency"
    ],
    "pages": [
      "149–159"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "8."
    ],
    "author": [
      {
        "family": "Mitchell",
        "given": "M."
      },
      {
        "family": "Wu",
        "given": "S."
      },
      {
        "family": "Zaldivar",
        "given": "A."
      },
      {
        "family": "Barnes",
        "given": "P."
      },
      {
        "family": "Vasserman",
        "given": "L."
      },
      {
        "family": "Hutchinson",
        "given": "B."
      },
      {
        "family": "Gebru",
        "given": "T."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Model Cards for Model Reporting"
    ],
    "container-title": [
      "Proceedings of the Conference on Fairness, Accountability, and Transparency"
    ],
    "pages": [
      "220–229"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "9."
    ],
    "author": [
      {
        "family": "Raji",
        "given": "I.D."
      },
      {
        "family": "Buolamwini",
        "given": "J."
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Actionable Auditing: Investigating the Impact of Publicly Naming Biased Performance Results of Commercial AI Products"
    ],
    "container-title": [
      "Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society"
    ],
    "pages": [
      "429–435"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "10."
    ],
    "author": [
      {
        "family": "Bender",
        "given": "E.M."
      },
      {
        "family": "Gebru",
        "given": "T."
      },
      {
        "family": "McMillan-Major",
        "given": "A."
      },
      {
        "family": "Shmitchell",
        "given": "S."
      }
    ],
    "date": [
      "2021"
    ],
    "title": [
      "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?"
    ],
    "container-title": [
      "Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency"
    ],
    "pages": [
      "610–623"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "11."
    ],
    "author": [
      {
        "family": "Noble",
        "given": "S.U."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "Algorithms of Oppression: How Search Engines Reinforce Racism"
    ],
    "publisher": [
      "NYU Press"
    ],
    "type": "book"
  },
  {
    "citation-number": [
      "12."
    ],
    "author": [
      {
        "family": "Barocas",
        "given": "S."
      },
      {
        "family": "Hardt",
        "given": "M."
      },
      {
        "family": "Narayanan",
        "given": "A."
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Fairness and Machine Learning: Limitations and Opportunities"
    ],
    "container-title": [
      "fairmlbook.org"
    ],
    "type": "chapter"
  },
  {
    "citation-number": [
      "13."
    ],
    "author": [
      {
        "family": "Crawford",
        "given": "K."
      }
    ],
    "date": [
      "2017"
    ],
    "title": [
      "The Trouble with Bias"
    ],
    "container-title": [
      "Conference on Neural Information Processing Systems (NeurIPS 2017"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "14."
    ],
    "author": [
      {
        "family": "Veale",
        "given": "M."
      },
      {
        "family": "Kleek",
        "given": "M.",
        "particle": "Van"
      },
      {
        "family": "Binns",
        "given": "R."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "Fairness and Accountability Design Needs for Algorithmic Support in High-Stakes Public Sector Decision-Making"
    ],
    "container-title": [
      "Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems"
    ],
    "pages": [
      "1–14"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "15."
    ],
    "author": [
      {
        "family": "Angwin",
        "given": "J."
      },
      {
        "family": "Larson",
        "given": "J."
      },
      {
        "family": "Mattu",
        "given": "S."
      },
      {
        "family": "Kirchner",
        "given": "L."
      }
    ],
    "date": [
      "2016"
    ],
    "title": [
      "Machine Bias: There’s Software Used Across the Country to Predict Future Criminals. And it’s Biased Against Blacks"
    ],
    "publisher": [
      "ProPublica"
    ],
    "type": "book"
  },
  {
    "citation-number": [
      "16."
    ],
    "author": [
      {
        "family": "Dastin",
        "given": "J."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "Amazon Scraps Secret AI Recruiting Tool That Showed Bias Against Women"
    ],
    "type": "article-journal",
    "container-title": [
      "Reuters"
    ]
  },
  {
    "citation-number": [
      "17."
    ],
    "author": [
      {
        "family": "Eubanks",
        "given": "V."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor"
    ],
    "container-title": [
      "St"
    ],
    "publisher": [
      "Martin's Press"
    ],
    "type": "chapter"
  },
  {
    "citation-number": [
      "18."
    ],
    "author": [
      {
        "family": "O'Neil",
        "given": "C."
      }
    ],
    "date": [
      "2016"
    ],
    "title": [
      "Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy"
    ],
    "publisher": [
      "Crown Publishing Group"
    ],
    "type": "book"
  },
  {
    "citation-number": [
      "19."
    ],
    "author": [
      {
        "family": "Floridi",
        "given": "L."
      },
      {
        "family": "Cowls",
        "given": "J."
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "A Unified Framework of Five Principles for AI in Society"
    ],
    "volume": [
      "1"
    ],
    "type": "article-journal",
    "container-title": [
      "Harvard Data Science Review"
    ],
    "issue": [
      "1"
    ]
  },
  {
    "citation-number": [
      "20."
    ],
    "author": [
      {
        "family": "Zook",
        "given": "M."
      },
      {
        "family": "Barocas",
        "given": "S."
      },
      {
        "family": "Boyd",
        "given": "D."
      },
      {
        "family": "Crawford",
        "given": "K."
      },
      {
        "family": "Keller",
        "given": "E."
      },
      {
        "family": "Gangadharan",
        "given": "S.P."
      },
      {
        "family": "Pasquale",
        "given": "F."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2017"
    ],
    "title": [
      "Ten Simple Rules for Responsible Big Data Research"
    ],
    "volume": [
      "13"
    ],
    "pages": [
      "1005399"
    ],
    "type": "article-journal",
    "container-title": [
      "PLOS Computational Biology"
    ],
    "issue": [
      "3"
    ]
  },
  {
    "title": [
      "These articles cover a range of topics including ethical considerations, fairness, bias, accountability, and the social impact of NLP technologies. They provide a comprehensive foundation for integrating ethics into the NLP curriculum"
    ],
    "type": null
  }
]
