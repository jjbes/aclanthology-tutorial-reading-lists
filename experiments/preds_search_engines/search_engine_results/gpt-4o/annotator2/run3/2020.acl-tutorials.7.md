Certainly! Here's a reading list of 20 articles on commonsense reasoning in Natural Language Processing (NLP) up to the year 2020:

1. **"Commonsense Knowledge and Reasoning in NLP"** by Antoine Bosselut, Hannah Rashkin, Maarten Sap, Chaitanya Malaviya, Asli Celikyilmaz, and Yejin Choi (2019)
   - A comprehensive survey on the role of commonsense knowledge in NLP tasks.

2. **"COMET: Commonsense Transformers for Automatic Knowledge Graph Construction"** by Antoine Bosselut, Hannah Rashkin, Maarten Sap, Chaitanya Malaviya, Asli Celikyilmaz, and Yejin Choi (2019)
   - Introduces COMET, a model for generating commonsense knowledge.

3. **"ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning"** by Maarten Sap, Ronan LeBras, Emily Allaway, Chandra Bhagavatula, Nicholas Lourie, Hannah Rashkin, Brendan Roof, Noah A. Smith, and Yejin Choi (2019)
   - Presents ATOMIC, a large-scale knowledge graph for commonsense reasoning.

4. **"SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference"** by Rowan Zellers, Yonatan Bisk, Roy Schwartz, and Yejin Choi (2018)
   - Introduces SWAG, a dataset for evaluating grounded commonsense reasoning.

5. **"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"** by Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova (2019)
   - Although not solely focused on commonsense reasoning, BERT has been foundational in many commonsense reasoning tasks.

6. **"CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge"** by Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant (2019)
   - Introduces CommonsenseQA, a dataset for evaluating commonsense question answering.

7. **"Reasoning about Actions and State Changes by Injecting Commonsense Knowledge"** by Chandra Bhagavatula, Ronan LeBras, Chaitanya Malaviya, Keisuke Sakaguchi, Ari Holtzman, Hannah Rashkin, Doug Downey, Wen-tau Yih, and Yejin Choi (2020)
   - Discusses methods for integrating commonsense knowledge into reasoning about actions and state changes.

8. **"Social IQa: Commonsense Reasoning about Social Interactions"** by Maarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, and Yejin Choi (2019)
   - Introduces Social IQa, a dataset for commonsense reasoning in social interactions.

9. **"COSMOS QA: Machine Reading Comprehension with Contextual Commonsense Reasoning"** by Pradeep Dasigi, Nelson F. Liu, Ana Marasovic, Noah A. Smith, and Matt Gardner (2019)
   - Presents COSMOS QA, a dataset for evaluating contextual commonsense reasoning in reading comprehension.

10. **"RocStories: A Large-Scale Dataset for Story Understanding"** by Nasrin Mostafazadeh, Nathanael Chambers, Xiaodong He, Devi Parikh, Dhruv Batra, Lucy Vanderwende, Pushmeet Kohli, and James Allen (2016)
    - Introduces RocStories, a dataset for evaluating story understanding and commonsense reasoning.

11. **"Story Cloze Test: A New Benchmark for Story Understanding"** by Nasrin Mostafazadeh, Nathanael Chambers, Xiaodong He, Devi Parikh, Dhruv Batra, Lucy Vanderwende, Pushmeet Kohli, and James Allen (2016)
    - Presents the Story Cloze Test, a benchmark for evaluating story understanding.

12. **"Winograd Schema Challenge as a Test of Machine Intelligence"** by Hector J. Levesque, Ernest Davis, and Leora Morgenstern (2012)
    - Introduces the Winograd Schema Challenge, a benchmark for commonsense reasoning.

13. **"The Winograd Schema Challenge"** by Ernest Davis, Leora Morgenstern (2014)
    - Further elaborates on the Winograd Schema Challenge and its significance.

14. **"Probing Neural Network Comprehension of Natural Language Arguments"** by Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, and Sebastian Riedel (2018)
    - Investigates how well neural networks understand and reason with natural language arguments.

15. **"The NarrativeQA Reading Comprehension Challenge"** by Tomáš Kočiský, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, Gábor Melis, and Edward Grefenstette (2018)
    - Introduces NarrativeQA, a dataset for evaluating comprehension of narrative texts.

16. **"Learning to Reason: End-to-End Module Networks for Visual Question Answering"** by Ronghang Hu, Jacob Andreas, Trevor Darrell, and Kate Saenko (2017)
    - Discusses end-to-end module networks for reasoning in visual question answering, relevant for multimodal commonsense reasoning.

17. **"MultiQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension"** by Tushar Khot, Peter Clark, Michal Guerquin, Peter Jansen, and Ashish Sabharwal (2019)
    - Investigates generalization and transfer learning in reading comprehension, including commonsense reasoning aspects.

18. **"Neural Module Networks"** by Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein (2016)
    - Introduces neural module networks for compositional reasoning, relevant for commonsense reasoning tasks.

19. **"Reasoning with Heterogeneous Knowledge for Commonsense Machine Comprehension"** by Wenpeng Yin, Nazli Goharian, and Ophir Frieder (2019)
    - Explores methods for integrating heterogeneous knowledge sources for commonsense comprehension.

20. **"Commonsense Knowledge Base Completion with Structural and Semantic Context"** by Wenhan Xiong, Thien Hoang, and William Yang Wang (2018)
    - Discusses methods for completing commonsense knowledge bases using structural and semantic context.

These articles cover a range of topics related to commonsense reasoning in NLP, including datasets, models, benchmarks, and methodologies. They provide a solid foundation for understanding the current state of research in this area up to 2020.