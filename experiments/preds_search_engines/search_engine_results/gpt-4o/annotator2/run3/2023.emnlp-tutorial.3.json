[
  {
    "author": [
      {
        "given": "Sure!"
      }
    ],
    "title": [
      "Here's a reading list of 20 articles on human-NLP model interactions up to 2023"
    ],
    "type": null
  },
  {
    "citation-number": [
      "1."
    ],
    "author": [
      {
        "family": "Bender",
        "given": "E.M."
      },
      {
        "family": "Koller",
        "given": "A."
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Climbing towards NLU: On Meaning"
    ],
    "container-title": [
      "Form, and Understanding in the Age of Data.\"** In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "2."
    ],
    "author": [
      {
        "family": "Shin",
        "given": "R."
      },
      {
        "family": "Durme",
        "given": "B.",
        "particle": "Van"
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "On the Importance of Understanding the Label"
    ],
    "container-title": [
      "The Role of Contextualization in Neural Language Models.\"** In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "3."
    ],
    "author": [
      {
        "family": "Bisk",
        "given": "Y."
      },
      {
        "family": "Holtzman",
        "given": "A."
      },
      {
        "family": "Thomason",
        "given": "J."
      },
      {
        "family": "Andreas",
        "given": "J."
      },
      {
        "family": "Bengio",
        "given": "Y."
      },
      {
        "family": "Chai",
        "given": "J.Y."
      },
      {
        "family": "Zettlemoyer",
        "given": "L."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Experience Grounds Language.\"**"
    ],
    "container-title": [
      "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "4."
    ],
    "author": [
      {
        "family": "Wallace",
        "given": "E."
      },
      {
        "family": "Feng",
        "given": "S."
      },
      {
        "family": "Kandpal",
        "given": "N."
      },
      {
        "family": "Gardner",
        "given": "M."
      },
      {
        "family": "Singh",
        "given": "S."
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Universal Adversarial Triggers for Attacking and Analyzing NLP.\"**"
    ],
    "container-title": [
      "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "5."
    ],
    "author": [
      {
        "family": "Gururangan",
        "given": "S."
      },
      {
        "family": "Marasović",
        "given": "A."
      },
      {
        "family": "Swayamdipta",
        "given": "S."
      },
      {
        "family": "Lo",
        "given": "K."
      },
      {
        "family": "Beltagy",
        "given": "I."
      },
      {
        "family": "Downey",
        "given": "D."
      },
      {
        "family": "Smith",
        "given": "N.A."
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Don't Stop Pretraining: Adapt Language Models to Domains and Tasks.\"**"
    ],
    "container-title": [
      "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "6."
    ],
    "author": [
      {
        "family": "Ribeiro",
        "given": "M.T."
      },
      {
        "family": "Singh",
        "given": "S."
      },
      {
        "family": "Guestrin",
        "given": "C."
      }
    ],
    "date": [
      "2016"
    ],
    "title": [
      "Why Should I Trust You?\": Explaining the Predictions of Any Classifier.\"**"
    ],
    "container-title": [
      "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "7."
    ],
    "author": [
      {
        "family": "Doshi-Velez",
        "given": "F."
      },
      {
        "family": "Kim",
        "given": "B."
      }
    ],
    "date": [
      "2017"
    ],
    "title": [
      "Towards a Rigorous Science of Interpretable Machine Learning.\"**"
    ],
    "note": [
      "arXiv preprint arXiv:1702.08608."
    ],
    "arxiv": [
      "1702.08608"
    ],
    "type": null
  },
  {
    "citation-number": [
      "8."
    ],
    "author": [
      {
        "family": "Henderson",
        "given": "P."
      },
      {
        "family": "Hu",
        "given": "J."
      },
      {
        "family": "Romoff",
        "given": "J."
      },
      {
        "family": "Brunskill",
        "given": "E."
      },
      {
        "family": "Jurafsky",
        "given": "D."
      },
      {
        "family": "Pineau",
        "given": "J."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "Where's the Risk?"
    ],
    "container-title": [
      "Exploring the Effects of Risk and Ambiguity on Human-NLP Model Interaction.\"** In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "9."
    ],
    "author": [
      {
        "family": "Zellers",
        "given": "R."
      },
      {
        "family": "Holtzman",
        "given": "A."
      },
      {
        "family": "Bisk",
        "given": "Y."
      },
      {
        "family": "Farhadi",
        "given": "A."
      },
      {
        "family": "Choi",
        "given": "Y."
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "HellaSwag"
    ],
    "container-title": [
      "Can a Machine Really Finish Your Sentence?\"** In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "10."
    ],
    "author": [
      {
        "family": "Raji",
        "given": "I.D."
      },
      {
        "family": "Buolamwini",
        "given": "J."
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Actionable Auditing"
    ],
    "container-title": [
      "Investigating the Impact of Publicly Naming Biased Performance Results of Commercial AI Products.\"** In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society (AIES"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "11."
    ],
    "author": [
      {
        "family": "Liu",
        "given": "F."
      },
      {
        "family": "Avci",
        "given": "B."
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Incorporating Priors with Feature Attribution on Text Classification.\"**"
    ],
    "container-title": [
      "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "12."
    ],
    "author": [
      {
        "family": "Bansal",
        "given": "T."
      },
      {
        "family": "Wu",
        "given": "Y."
      },
      {
        "family": "Zhou",
        "given": "J."
      },
      {
        "family": "Fyshe",
        "given": "A."
      }
    ],
    "date": [
      "2021"
    ],
    "title": [
      "Self-Explainable Neural Networks for Few-Shot Learning.\"**"
    ],
    "container-title": [
      "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "13."
    ],
    "author": [
      {
        "family": "Lakkaraju",
        "given": "H."
      },
      {
        "family": "Rudin",
        "given": "C."
      }
    ],
    "date": [
      "2017"
    ],
    "title": [
      "Learning Cost-Effective and Interpretable Treatment Regimes.\"**"
    ],
    "container-title": [
      "Proceedings of the 20th International Conference on Artificial Intelligence and Statistics (AISTATS"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "14."
    ],
    "author": [
      {
        "family": "Binns",
        "given": "R."
      },
      {
        "family": "Veale",
        "given": "M."
      },
      {
        "family": "Kleek",
        "given": "M.",
        "particle": "Van"
      },
      {
        "family": "Shadbolt",
        "given": "N."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "‘It's Reducing a Human Being to a Percentage’"
    ],
    "container-title": [
      "Perceptions of Justice in Algorithmic Decisions.\"** In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "15."
    ],
    "author": [
      {
        "family": "Zhong",
        "given": "R."
      },
      {
        "family": "Tang",
        "given": "J."
      },
      {
        "family": "Liu",
        "given": "H."
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "An Interpretable Model with Globally Consistent Explanations for Text Classification.\"**"
    ],
    "container-title": [
      "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "16."
    ],
    "author": [
      {
        "family": "Rudin",
        "given": "C."
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead.\"**"
    ],
    "volume": [
      "1"
    ],
    "pages": [
      "206–215"
    ],
    "type": "article-journal",
    "container-title": [
      "Nature Machine Intelligence"
    ],
    "issue": [
      "5"
    ]
  },
  {
    "citation-number": [
      "17."
    ],
    "author": [
      {
        "family": "Hase",
        "given": "P."
      },
      {
        "family": "Bansal",
        "given": "M."
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?\"**"
    ],
    "container-title": [
      "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "18."
    ],
    "author": [
      {
        "family": "Wiegreffe",
        "given": "S."
      },
      {
        "family": "Pinter",
        "given": "Y."
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Attention is not Explanation.\"**"
    ],
    "container-title": [
      "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP"
    ],
    "type": "paper-conference"
  },
  {
    "citation-number": [
      "19."
    ],
    "author": [
      {
        "family": "Miller",
        "given": "T."
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Explanation in Artificial Intelligence: Insights from the Social Sciences.\"**"
    ],
    "volume": [
      "267"
    ],
    "pages": [
      "1–38"
    ],
    "type": "article-journal",
    "container-title": [
      "Artificial Intelligence"
    ]
  },
  {
    "citation-number": [
      "20."
    ],
    "author": [
      {
        "family": "Cheng",
        "given": "J."
      },
      {
        "family": "Danescu-Niculescu-Mizil",
        "given": "C."
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "A Framework for Understanding Human-NLP Model Collaboration.\"**"
    ],
    "container-title": [
      "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP"
    ],
    "type": "paper-conference"
  },
  {
    "title": [
      "These articles cover a range of topics related to human-NLP model interactions, including interpretability, trust, collaboration, and the impact of biases"
    ],
    "type": null
  }
]
