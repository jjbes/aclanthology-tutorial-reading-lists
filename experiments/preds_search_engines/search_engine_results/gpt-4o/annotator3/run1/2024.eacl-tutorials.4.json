[
  {
    "author": [
      {
        "given": "Certainly!"
      }
    ],
    "title": [
      "Here's a curated list of 20 articles up to 2024 that focus on interpretability methods specifically for transformer models"
    ],
    "type": null
  },
  {
    "citation-number": [
      "1."
    ],
    "author": [
      {
        "literal": "**Attention is not Explanation** - Jain, S., & Wallace, B. C."
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "2."
    ],
    "title": [
      "**A Closer Look at the Robustness of Text Classification Models to Spurious Correlations**"
    ],
    "editor": [
      {
        "family": "Swayamdipta",
        "given": "S."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "citation-number": [
      "3."
    ],
    "title": [
      "**Dissecting BERT: A Comprehensive Analysis of Transformer Layers**"
    ],
    "editor": [
      {
        "family": "Kovaleva",
        "given": "O."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "4."
    ],
    "title": [
      "**Visualizing and Understanding Neural Models in NLP**"
    ],
    "editor": [
      {
        "family": "Li",
        "given": "J."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "citation-number": [
      "5."
    ],
    "title": [
      "**Interpretable and Explainable Deep Learning for NLP: A Survey**"
    ],
    "editor": [
      {
        "family": "Danilevsky",
        "given": "M."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "citation-number": [
      "6."
    ],
    "author": [
      {
        "literal": "**Explaining and Harnessing Adversarial Examples** - Goodfellow, I. J., et al."
      }
    ],
    "date": [
      "2015"
    ],
    "type": null
  },
  {
    "citation-number": [
      "7."
    ],
    "title": [
      "**The Building Blocks of Interpretability**"
    ],
    "editor": [
      {
        "family": "Olah",
        "given": "C."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "citation-number": [
      "8."
    ],
    "title": [
      "**Towards Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks**"
    ],
    "editor": [
      {
        "family": "Zhang",
        "given": "Q."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "citation-number": [
      "9."
    ],
    "author": [
      {
        "literal": "**Attention is All You Need** - Vaswani, A., et al."
      }
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "citation-number": [
      "10."
    ],
    "title": [
      "**Transformer Interpretability Beyond Attention Visualization**"
    ],
    "editor": [
      {
        "family": "Chefer",
        "given": "H."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "citation-number": [
      "11."
    ],
    "title": [
      "**Explaining Transformers as Bayesian Inference: The Neural Tangent Kernel Perspective**"
    ],
    "editor": [
      {
        "family": "Hao",
        "given": "C."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "citation-number": [
      "12."
    ],
    "title": [
      "**Understanding Pre-trained BERT for Aspect-based Sentiment Analysis**"
    ],
    "editor": [
      {
        "family": "Sun",
        "given": "C."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "13."
    ],
    "title": [
      "**Analyzing the Structure of Attention in a Transformer Language Model**"
    ],
    "editor": [
      {
        "family": "Clark",
        "given": "K."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "citation-number": [
      "14."
    ],
    "title": [
      "**Explaining Transformers via Probabilistic Finite Automata**"
    ],
    "editor": [
      {
        "family": "Weiss",
        "given": "G."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "citation-number": [
      "15."
    ],
    "title": [
      "**Towards a Rigorous Science of Interpretable Machine Learning**"
    ],
    "editor": [
      {
        "family": "Doshi-Velez",
        "given": "F."
      },
      {
        "family": "Kim",
        "given": "B."
      }
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "citation-number": [
      "16."
    ],
    "title": [
      "**Attention Interpretability Across NLP Tasks**"
    ],
    "editor": [
      {
        "family": "Vig",
        "given": "J."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "citation-number": [
      "17."
    ],
    "title": [
      "**On the Importance of Single Directions for Generalization**"
    ],
    "editor": [
      {
        "family": "Morcos",
        "given": "A.S."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "citation-number": [
      "18."
    ],
    "title": [
      "**A Survey on Model Compression and Acceleration for Deep Neural Networks**"
    ],
    "editor": [
      {
        "family": "Cheng",
        "given": "Y."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "citation-number": [
      "19."
    ],
    "title": [
      "**The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks** - Frankle"
    ],
    "volume": [
      "M"
    ],
    "date": [
      "2019"
    ],
    "type": "article-journal",
    "container-title": [
      "J., & Carbin"
    ]
  },
  {
    "citation-number": [
      "20."
    ],
    "title": [
      "**Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions**"
    ],
    "editor": [
      {
        "family": "Koh",
        "given": "P.W."
      },
      {
        "family": "Liang",
        "given": "P."
      }
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "title": [
      "These articles cover a range of topics from foundational transformer models, attention mechanisms, interpretability techniques, and specific case studies on model behavior and visualization. This list should provide a comprehensive overview of the current state of research in transformer interpretability"
    ],
    "type": null
  }
]
