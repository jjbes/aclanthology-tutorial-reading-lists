[
  {
    "author": [
      {
        "given": "Certainly!"
      }
    ],
    "title": [
      "Here is a list of 20 articles focused on interpretability methods specific to transformer models, covering research up to 2024"
    ],
    "type": null
  },
  {
    "citation-number": [
      "1."
    ],
    "publisher": [
      "**Attention is Not Explanation**"
    ],
    "type": "book"
  },
  {
    "author": [
      {
        "family": "Jain",
        "given": "S."
      },
      {
        "family": "Wallace",
        "given": "B.C."
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:1902.10186"
    ],
    "arxiv": [
      "1902.10186"
    ],
    "type": null
  },
  {
    "citation-number": [
      "2."
    ],
    "title": [
      "**A Closer Look at the Robustness of Text Classification Models to Spurious Correlations**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Swayamdipta",
        "given": "S."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:2007.00676"
    ],
    "arxiv": [
      "2007.00676"
    ],
    "type": null
  },
  {
    "citation-number": [
      "3."
    ],
    "title": [
      "**Explaining Transformers as Bayesian Inference: Neural Architecture Induction**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Voita",
        "given": "E."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:1906.02856"
    ],
    "arxiv": [
      "1906.02856"
    ],
    "type": null
  },
  {
    "citation-number": [
      "4."
    ],
    "title": [
      "**Analyzing the Structure of Attention in a Transformer Language Model**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Clark",
        "given": "K."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:1906.04284"
    ],
    "arxiv": [
      "1906.04284"
    ],
    "type": null
  },
  {
    "citation-number": [
      "5."
    ],
    "title": [
      "**Dissecting Contextual Word Embeddings: Architecture and Representation**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Coenen",
        "given": "A."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:1906.01698"
    ],
    "arxiv": [
      "1906.01698"
    ],
    "type": null
  },
  {
    "citation-number": [
      "6."
    ],
    "title": [
      "**Interpreting and Understanding BERT: A Study on Layer-Wise Contextual Representations**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Tenney",
        "given": "I."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:1905.05950"
    ],
    "arxiv": [
      "1905.05950"
    ],
    "type": null
  },
  {
    "citation-number": [
      "7."
    ],
    "container-title": [
      "**Visualizing and Understanding Neural Machine Translation**"
    ],
    "type": "chapter"
  },
  {
    "author": [
      {
        "family": "Ding",
        "given": "D."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:1904.02681"
    ],
    "arxiv": [
      "1904.02681"
    ],
    "type": null
  },
  {
    "citation-number": [
      "8."
    ],
    "title": [
      "**Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Dong",
        "given": "Y."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:2103.03404"
    ],
    "arxiv": [
      "2103.03404"
    ],
    "type": null
  },
  {
    "citation-number": [
      "9."
    ],
    "title": [
      "**Understanding Pre-trained BERT for Aspect-based Sentiment Analysis**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Xu",
        "given": "H."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:1909.04839"
    ],
    "arxiv": [
      "1909.04839"
    ],
    "type": null
  },
  {
    "citation-number": [
      "10."
    ],
    "title": [
      "**Towards Interpretable NLP: A Contextualized Rationalization Model**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Jain",
        "given": "S."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:2004.12393"
    ],
    "arxiv": [
      "2004.12393"
    ],
    "type": null
  },
  {
    "citation-number": [
      "11."
    ],
    "title": [
      "**A Survey of Methods for Interpreting BERT**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Rogers",
        "given": "A."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:2002.12327"
    ],
    "arxiv": [
      "2002.12327"
    ],
    "type": null
  },
  {
    "citation-number": [
      "12."
    ],
    "title": [
      "**How Does BERT Answer Questions? A Layer-Wise Analysis of Transformer Representations**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Kovaleva",
        "given": "O."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:1909.06321"
    ],
    "arxiv": [
      "1909.06321"
    ],
    "type": null
  },
  {
    "citation-number": [
      "13."
    ],
    "title": [
      "**Explaining Neural Networks by Decoding Layer-Wise Relevance Propagation**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Arras",
        "given": "L."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:2004.02532"
    ],
    "arxiv": [
      "2004.02532"
    ],
    "type": null
  },
  {
    "citation-number": [
      "14."
    ],
    "title": [
      "**Transformers Interpretability Beyond Attention Visualization**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Chefer",
        "given": "H."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:2106.14112"
    ],
    "arxiv": [
      "2106.14112"
    ],
    "type": null
  },
  {
    "citation-number": [
      "15."
    ],
    "title": [
      "**Analyzing and Interpreting BERT's Attention**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Michel",
        "given": "P."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:1906.04341"
    ],
    "arxiv": [
      "1906.04341"
    ],
    "type": null
  },
  {
    "citation-number": [
      "16."
    ],
    "title": [
      "**Explaining Transformers with Robust Attribution Regularization**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Bastings",
        "given": "J."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:2004.14992"
    ],
    "arxiv": [
      "2004.14992"
    ],
    "type": null
  },
  {
    "citation-number": [
      "17."
    ],
    "title": [
      "**Self-Attention with Relative Position Representations**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Shaw",
        "given": "P."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:1803.02155"
    ],
    "arxiv": [
      "1803.02155"
    ],
    "type": null
  },
  {
    "citation-number": [
      "18."
    ],
    "location": [
      "Transformers"
    ],
    "publisher": [
      "State-of-the-Art Natural Language Processing**"
    ],
    "type": "book"
  },
  {
    "author": [
      {
        "family": "Wolf",
        "given": "T."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:1910.03771"
    ],
    "arxiv": [
      "1910.03771"
    ],
    "type": null
  },
  {
    "citation-number": [
      "19."
    ],
    "title": [
      "**Interpreting BERT's Predictions**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Vig",
        "given": "J."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:2001.09864"
    ],
    "arxiv": [
      "2001.09864"
    ],
    "type": null
  },
  {
    "citation-number": [
      "20."
    ],
    "title": [
      "**Explaining Transformer Predictions with Local Interpretable Model-Agnostic Explanations (LIME)**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "family": "Ribeiro",
        "given": "M.T."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "note": [
      "- arXiv:1602.04938"
    ],
    "arxiv": [
      "1602.04938"
    ],
    "type": null
  },
  {
    "title": [
      "These articles cover a range of techniques and approaches for interpreting transformer models, from attention mechanisms to layer-wise analysis and beyond. They provide a comprehensive overview of the current state of research in this area"
    ],
    "type": null
  }
]
