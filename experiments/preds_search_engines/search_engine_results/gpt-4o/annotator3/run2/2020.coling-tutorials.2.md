Sure! Here's a reading list of 20 articles up to 2020 that cover various types of word embeddings in natural language processing (NLP), including conventional embeddings, sense embeddings, graph-based embeddings, and contextual embeddings:

1. Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). "Efficient Estimation of Word Representations in Vector Space." arXiv preprint arXiv:1301.3781.
2. Pennington, J., Socher, R., & Manning, C. D. (2014). "GloVe: Global Vectors for Word Representation." Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP).
3. Bojanowski, P., Grave, E., Joulin, A., & Mikolov, T. (2017). "Enriching Word Vectors with Subword Information." Transactions of the Association for Computational Linguistics, 5, 135-146.
4. Levy, O., & Goldberg, Y. (2014). "Neural Word Embedding as Implicit Matrix Factorization." Advances in Neural Information Processing Systems (NeurIPS), 27.
5. Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018). "Deep Contextualized Word Representations." Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).
6. Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding." Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).
7. Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). "Distributed Representations of Words and Phrases and their Compositionality." Advances in Neural Information Processing Systems (NeurIPS), 26.
8. Pilehvar, M. T., & Collier, N. (2016). "De-conflated Semantic Representations." Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP).
9. Iacobacci, I., Pilehvar, M. T., & Navigli, R. (2015). "Sensembed: Learning sense embeddings for word and relational similarity." Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers).
10. Hamilton, W. L., Ying, R., & Leskovec, J. (2017). "Representation Learning on Graphs: Methods and Applications." arXiv preprint arXiv:1709.05584.
11. Kipf, T. N., & Welling, M. (2017). "Semi-Supervised Classification with Graph Convolutional Networks." International Conference on Learning Representations (ICLR).
12. Grover, A., & Leskovec, J. (2016). "node2vec: Scalable Feature Learning for Networks." Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD).
13. Pilehvar, M. T., & Camacho-Collados, J. (2019). "WiC: the Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations." Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).
14. Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., ... & Stoyanov, V. (2019). "RoBERTa: A Robustly Optimized BERT Pretraining Approach." arXiv preprint arXiv:1907.11692.
15. Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). "Improving Language Understanding by Generative Pre-Training." OpenAI.
16. Yang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R., & Le, Q. V. (2019). "XLNet: Generalized Autoregressive Pretraining for Language Understanding." Advances in Neural Information Processing Systems (NeurIPS), 32.
17. Peters, M. E., Ammar, W., Bhagavatula, C., & Power, R. (2017). "Semi-supervised sequence tagging with bidirectional language models." Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers).
18. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). "Attention is All You Need." Advances in Neural Information Processing Systems (NeurIPS), 30.
19. Camacho-Collados, J., & Pilehvar, M. T. (2018). "From Word to Sense Embeddings: A Survey on Vector Representations of Meaning." Journal of Artificial Intelligence Research, 63, 743-788.
20. Lample, G., Conneau, A., Denoyer, L., & Ranzato, M. (2018). "Unsupervised Machine Translation Using Monolingual Corpora Only." International Conference on Learning Representations (ICLR).

These articles cover a broad spectrum of word embedding techniques and their applications in NLP, providing a comprehensive understanding of the field up to 2020.