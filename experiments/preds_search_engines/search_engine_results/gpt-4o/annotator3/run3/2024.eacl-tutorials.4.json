[
  {
    "title": [
      "Sure, here's a curated reading list of 20 articles focused on interpretability methods specific to transformer models, up to 2024"
    ],
    "type": null
  },
  {
    "citation-number": [
      "1."
    ],
    "title": [
      "**Attention is All You Need** - Vaswani et al"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "The foundational paper introducing the Transformer model"
    ],
    "type": null
  },
  {
    "citation-number": [
      "2."
    ],
    "title": [
      "**Visualizing and Understanding Neural Models in NLP** - Li et al"
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Early work on interpretability in NLP models, including attention mechanisms"
    ],
    "type": null
  },
  {
    "citation-number": [
      "3."
    ],
    "title": [
      "**A Closer Look at Attention Mechanisms in Neural Networks** - Jain and Wallace"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Critically examines the interpretability of attention mechanisms"
    ],
    "type": null
  },
  {
    "citation-number": [
      "4."
    ],
    "author": [
      {
        "literal": "**Interpreting and Understanding BERT** - Clark et al."
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Analyzes the internal representations and attention heads in BERT"
    ],
    "type": null
  },
  {
    "citation-number": [
      "5."
    ],
    "title": [
      "**Dissecting BERT: Attention Heads and Layers** - Kovaleva et al"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Provides a detailed analysis of the roles of different attention heads and layers in BERT"
    ],
    "type": null
  },
  {
    "citation-number": [
      "6."
    ],
    "title": [
      "**Analyzing the Structure of Attention in a Transformer Language Model** - Voita et al"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Studies the structure and function of attention heads in Transformer models"
    ],
    "type": null
  },
  {
    "citation-number": [
      "7."
    ],
    "title": [
      "**Attention is not Explanation** - Serrano and Smith"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Argues that attention weights do not necessarily provide explanations for model predictions"
    ],
    "type": null
  },
  {
    "citation-number": [
      "8."
    ],
    "title": [
      "**Transformer Interpretability Beyond Attention Visualization** - Chefer et al"
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Proposes new methods for interpreting Transformer models beyond just visualizing attention"
    ],
    "type": null
  },
  {
    "citation-number": [
      "9."
    ],
    "title": [
      "**Explaining Transformers as Bayesian Inference Engines** - Ravfogel et al"
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Offers a Bayesian perspective on Transformer interpretability"
    ],
    "type": null
  },
  {
    "citation-number": [
      "10."
    ],
    "title": [
      "**Towards Interpretable NLP: A Comparison of Feature Attribution Methods for Transformers** - De Cao et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Compares different feature attribution methods for interpreting Transformer models"
    ],
    "type": null
  },
  {
    "citation-number": [
      "11."
    ],
    "title": [
      "**Explaining Transformers with Robust Attribution** - Chefer et al"
    ],
    "date": [
      "2021"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces robust attribution methods for explaining Transformer decisions"
    ],
    "type": null
  },
  {
    "citation-number": [
      "12."
    ],
    "title": [
      "**Understanding Pre-trained BERT for Aspect-based Sentiment Analysis** - Sun et al"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Focuses on interpreting BERT in the context of sentiment analysis"
    ],
    "type": null
  },
  {
    "citation-number": [
      "13."
    ],
    "title": [
      "**Explaining Neural Networks with DeepLIFT** - Shrikumar et al"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "While not specific to Transformers, this paper is foundational for understanding feature attribution methods"
    ],
    "type": null
  },
  {
    "citation-number": [
      "14."
    ],
    "title": [
      "**Explaining and Improving Model Robustness with Attribution Priors** - Ross et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses how attribution priors can be used to improve model interpretability and robustness"
    ],
    "type": null
  },
  {
    "citation-number": [
      "15."
    ],
    "title": [
      "**Integrated Gradients: Axiomatic Attribution for Deep Networks** - Sundararajan et al"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces Integrated Gradients, a widely-used method for interpreting deep learning models, including Transformers"
    ],
    "type": null
  },
  {
    "citation-number": [
      "16."
    ],
    "author": [
      {
        "given": "L.I.M.E."
      }
    ],
    "title": [
      "Local Interpretable Model-agnostic Explanations** - Ribeiro et al"
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Proposes a model-agnostic method for interpreting complex models, applicable to Transformers"
    ],
    "type": null
  },
  {
    "citation-number": [
      "17."
    ],
    "author": [
      {
        "given": "S.H.A.P."
      }
    ],
    "title": [
      "Shapley Additive Explanations** - Lundberg and Lee"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces SHAP values, another model-agnostic interpretability method"
    ],
    "type": null
  },
  {
    "citation-number": [
      "18."
    ],
    "title": [
      "**Explaining BERT with SHAP Values** - Jin et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Applies SHAP values specifically to BERT models"
    ],
    "type": null
  },
  {
    "citation-number": [
      "19."
    ],
    "title": [
      "**Towards Robust and Interpretable Neural Networks with Parametric Noise Injection** - Heo et al"
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses methods for improving the robustness and interpretability of neural networks, including Transformers"
    ],
    "type": null
  },
  {
    "citation-number": [
      "20."
    ],
    "title": [
      "**Explaining Transformers with Contextual Decomposition** - Voita et al"
    ],
    "date": [
      "2020"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces Contextual Decomposition as a method for interpreting Transformer models"
    ],
    "type": null
  },
  {
    "title": [
      "These articles provide a comprehensive overview of the current state of interpretability methods for Transformer models, ranging from foundational concepts to cutting-edge research"
    ],
    "type": null
  }
]
