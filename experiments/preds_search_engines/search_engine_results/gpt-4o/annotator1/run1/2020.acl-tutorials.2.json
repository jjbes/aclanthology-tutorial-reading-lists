[
  {
    "title": [
      "Sure, here is a reading list of 20 articles on ethics in natural language processing (NLP) and best practices up to 2020"
    ],
    "type": null
  },
  {
    "citation-number": [
      "1."
    ],
    "author": [
      {
        "family": "Bender",
        "given": "E.M."
      },
      {
        "family": "Friedman",
        "given": "B."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science"
    ],
    "volume": [
      "6"
    ],
    "pages": [
      "587–604"
    ],
    "type": "article-journal",
    "container-title": [
      "Transactions of the Association for Computational Linguistics"
    ]
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "This paper introduces the concept of \"data statements\" to document datasets used in NLP research, aiming to mitigate bias and improve reproducibility"
    ],
    "type": null
  },
  {
    "citation-number": [
      "2."
    ],
    "author": [
      {
        "literal": "**Blodgett, S. L., Barocas, S., Daumé III, H., & Wallach, H."
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Language (Technology) is Power: A Critical Survey of 'Bias' in NLP"
    ],
    "container-title": [
      "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.**"
    ],
    "type": "paper-conference"
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "A critical survey of how bias is addressed in NLP research, with a focus on the implications of language technology on power dynamics"
    ],
    "type": null
  },
  {
    "citation-number": [
      "3."
    ],
    "author": [
      {
        "family": "Hovy",
        "given": "D."
      },
      {
        "family": "Spruit",
        "given": "S.L."
      }
    ],
    "date": [
      "2016"
    ],
    "title": [
      "The Social Impact of Natural Language Processing"
    ],
    "container-title": [
      "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.**"
    ],
    "type": "paper-conference"
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "This paper discusses the broader social impacts of NLP technologies and the ethical considerations that researchers should take into account"
    ],
    "type": null
  },
  {
    "citation-number": [
      "4."
    ],
    "author": [
      {
        "literal": "**Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., Daumé III, H., & Crawford, K."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "Datasheets for Datasets"
    ],
    "note": [
      "arXiv preprint arXiv:1803.09010.**"
    ],
    "arxiv": [
      "1803.09010"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Proposes the use of datasheets for documenting datasets, inspired by the electronics industry, to ensure transparency and accountability"
    ],
    "type": null
  },
  {
    "citation-number": [
      "5."
    ],
    "author": [
      {
        "family": "Crawford",
        "given": "K."
      },
      {
        "family": "Paglen",
        "given": "T."
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Excavating AI: The Politics of Training Sets for Machine Learning"
    ],
    "publisher": [
      "AI Now Institute.**"
    ],
    "type": "book"
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "An exploration of the political and ethical implications of training datasets used in AI and NLP"
    ],
    "type": null
  },
  {
    "citation-number": [
      "6."
    ],
    "author": [
      {
        "family": "Raji",
        "given": "I.D."
      },
      {
        "family": "Buolamwini",
        "given": "J."
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Actionable Auditing: Investigating the Impact of Publicly Naming Biased Performance Results of Commercial AI Products"
    ],
    "container-title": [
      "Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society.**"
    ],
    "type": "paper-conference"
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Investigates the impact of publicly disclosing biased performance results of AI products, including NLP systems"
    ],
    "type": null
  },
  {
    "citation-number": [
      "7."
    ],
    "author": [
      {
        "family": "Mitchell",
        "given": "M."
      },
      {
        "family": "Wu",
        "given": "S."
      },
      {
        "family": "Zaldivar",
        "given": "A."
      },
      {
        "family": "Barnes",
        "given": "P."
      },
      {
        "family": "Vasserman",
        "given": "L."
      },
      {
        "family": "Hutchinson",
        "given": "B."
      },
      {
        "family": "Gebru",
        "given": "T."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Model Cards for Model Reporting"
    ],
    "container-title": [
      "Proceedings of the Conference on Fairness, Accountability, and Transparency.**"
    ],
    "type": "paper-conference"
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces \"model cards\" as a method for documenting the performance characteristics and ethical considerations of machine learning models"
    ],
    "type": null
  },
  {
    "citation-number": [
      "8."
    ],
    "author": [
      {
        "family": "Binns",
        "given": "R."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "Fairness in Machine Learning: Lessons from Political Philosophy"
    ],
    "container-title": [
      "Proceedings of the 2018 Conference on Fairness, Accountability, and Transparency.**"
    ],
    "type": "paper-conference"
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses how concepts from political philosophy can inform fairness in machine learning, including NLP applications"
    ],
    "type": null
  },
  {
    "citation-number": [
      "9."
    ],
    "author": [
      {
        "family": "Caliskan",
        "given": "A."
      },
      {
        "family": "Bryson",
        "given": "J.J."
      },
      {
        "family": "Narayanan",
        "given": "A."
      }
    ],
    "date": [
      "2017"
    ],
    "title": [
      "Semantics derived automatically from language corpora contain human-like biases"
    ],
    "volume": [
      "356"
    ],
    "pages": [
      "183–186"
    ],
    "type": "article-journal",
    "container-title": [
      "Science"
    ],
    "issue": [
      "6334"
    ]
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Demonstrates that word embeddings trained on large text corpora can reflect human-like biases, with significant ethical implications"
    ],
    "type": null
  },
  {
    "citation-number": [
      "10."
    ],
    "author": [
      {
        "family": "Sun",
        "given": "T."
      },
      {
        "family": "Gaut",
        "given": "A."
      },
      {
        "family": "Tang",
        "given": "S."
      },
      {
        "family": "Huang",
        "given": "Y."
      },
      {
        "family": "ElSherief",
        "given": "M."
      },
      {
        "family": "Zhao",
        "given": "J."
      },
      {
        "family": "Wang",
        "given": "W.Y."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Mitigating Gender Bias in Natural Language Processing: Literature Review"
    ],
    "container-title": [
      "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics.**"
    ],
    "type": "paper-conference"
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "A comprehensive review of methods to mitigate gender bias in NLP systems"
    ],
    "type": null
  },
  {
    "citation-number": [
      "11."
    ],
    "author": [
      {
        "family": "Zou",
        "given": "J."
      },
      {
        "family": "Schiebinger",
        "given": "L."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "AI can be sexist and racist — it’s time to make it fair"
    ],
    "volume": [
      "559"
    ],
    "pages": [
      "324–326"
    ],
    "type": "article-journal",
    "container-title": [
      "Nature"
    ],
    "issue": [
      "7714"
    ]
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the ethical challenges of bias in AI and NLP systems and proposes strategies for making these technologies fairer"
    ],
    "type": null
  },
  {
    "citation-number": [
      "12."
    ],
    "author": [
      {
        "family": "Green",
        "given": "B."
      },
      {
        "family": "Viljoen",
        "given": "S."
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Algorithmic Realism: Expanding the Boundaries of Algorithmic Thought"
    ],
    "container-title": [
      "Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency.**"
    ],
    "type": "paper-conference"
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Explores the limitations of current approaches to fairness and ethics in algorithmic systems, including NLP"
    ],
    "type": null
  },
  {
    "citation-number": [
      "13."
    ],
    "author": [
      {
        "family": "Shah",
        "given": "S."
      },
      {
        "family": "Schwartz",
        "given": "R."
      },
      {
        "family": "Hovy",
        "given": "D."
      },
      {
        "family": "Sap",
        "given": "M."
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview"
    ],
    "container-title": [
      "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.**"
    ],
    "type": "paper-conference"
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Provides a conceptual framework for understanding and addressing predictive biases in NLP models"
    ],
    "type": null
  },
  {
    "citation-number": [
      "14."
    ],
    "author": [
      {
        "family": "Kiritchenko",
        "given": "S."
      },
      {
        "family": "Mohammad",
        "given": "S.M."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems"
    ],
    "container-title": [
      "Proceedings of the 7th Joint Conference on Lexical and Computational Semantics.**"
    ],
    "type": "paper-conference"
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "An empirical study examining gender and race biases in sentiment analysis systems"
    ],
    "type": null
  },
  {
    "citation-number": [
      "15."
    ],
    "author": [
      {
        "family": "Henderson",
        "given": "P."
      },
      {
        "family": "Hu",
        "given": "J."
      },
      {
        "family": "Romoff",
        "given": "J."
      },
      {
        "family": "Brunskill",
        "given": "E."
      },
      {
        "family": "Jurafsky",
        "given": "D."
      },
      {
        "family": "Pineau",
        "given": "J."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "Ethical Challenges in Data-Driven Dialogue Systems"
    ],
    "container-title": [
      "Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society.**"
    ],
    "type": "paper-conference"
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the ethical challenges specific to data-driven dialogue systems, including issues of privacy, bias, and user manipulation"
    ],
    "type": null
  },
  {
    "citation-number": [
      "16."
    ],
    "author": [
      {
        "family": "Leidner",
        "given": "J.L."
      },
      {
        "family": "Plachouras",
        "given": "V."
      }
    ],
    "date": [
      "2017"
    ],
    "title": [
      "Ethical by Design: Ethics Best Practices for Natural Language Processing"
    ],
    "container-title": [
      "Proceedings of the First ACL Workshop on Ethics in Natural Language Processing.**"
    ],
    "type": "paper-conference"
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "A set of best practices for ensuring ethical considerations are integrated into the design of NLP systems"
    ],
    "type": null
  },
  {
    "citation-number": [
      "17."
    ],
    "author": [
      {
        "family": "Mittelstadt",
        "given": "B.D."
      },
      {
        "family": "Allo",
        "given": "P."
      },
      {
        "family": "Taddeo",
        "given": "M."
      },
      {
        "family": "Wachter",
        "given": "S."
      },
      {
        "family": "Floridi",
        "given": "L."
      }
    ],
    "date": [
      "2016"
    ],
    "title": [
      "The ethics of algorithms: Mapping the debate"
    ],
    "volume": [
      "3"
    ],
    "type": "article-journal",
    "container-title": [
      "Big Data & Society"
    ],
    "issue": [
      "2"
    ]
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Maps the ethical debates surrounding algorithmic decision-making, including applications in NLP"
    ],
    "type": null
  },
  {
    "citation-number": [
      "18."
    ],
    "author": [
      {
        "family": "Binns",
        "given": "R."
      },
      {
        "family": "Veale",
        "given": "M."
      },
      {
        "family": "Kleek",
        "given": "M.",
        "particle": "Van"
      },
      {
        "family": "Shadbolt",
        "given": "N."
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "‘It's Reducing a Human Being to a Percentage’: Perceptions of Justice in Algorithmic Decisions"
    ],
    "container-title": [
      "Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems.**"
    ],
    "type": "paper-conference"
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Examines public perceptions of justice and fairness in algorithmic decision-making, relevant to NLP applications"
    ],
    "type": null
  },
  {
    "citation-number": [
      "19."
    ],
    "author": [
      {
        "family": "Birhane",
        "given": "A."
      },
      {
        "family": "Cummins",
        "given": "F."
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Algorithmic Injustice: A Relational Ethics Approach"
    ],
    "container-title": [
      "Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society.**"
    ],
    "type": "paper-conference"
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Proposes a relational ethics approach to addressing algorithmic injustice, with implications for NLP systems"
    ],
    "type": null
  },
  {
    "citation-number": [
      "20."
    ],
    "author": [
      {
        "family": "Jobin",
        "given": "A."
      },
      {
        "family": "Ienca",
        "given": "M."
      },
      {
        "family": "Vayena",
        "given": "E."
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "The global landscape of AI ethics guidelines"
    ],
    "volume": [
      "1"
    ],
    "pages": [
      "389–399"
    ],
    "type": "article-journal",
    "container-title": [
      "Nature Machine Intelligence"
    ],
    "issue": [
      "9"
    ]
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Surveys the landscape of AI ethics guidelines globally, providing context for ethical considerations in NLP"
    ],
    "type": null
  },
  {
    "title": [
      "These articles cover a range of topics related to ethics in NLP, including bias, fairness, transparency, and the social impact of language technologies. They provide a solid foundation for understanding the ethical challenges and best practices in the field"
    ],
    "type": null
  }
]
