[
  {
    "title": [
      "Sure, here's a curated reading list of 20 articles up to 2023 that focus on complex reasoning in natural language processing (NLP"
    ],
    "note": [
      "with an emphasis on pretrained language models (PLMs):"
    ],
    "type": null
  },
  {
    "citation-number": [
      "1."
    ],
    "author": [
      {
        "family": "Vaswani",
        "given": "A."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2017"
    ],
    "title": [
      "Attention is All You Need.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "This seminal paper introduces the Transformer architecture, which is foundational for many PLMs"
    ],
    "type": null
  },
  {
    "citation-number": [
      "2."
    ],
    "author": [
      {
        "family": "Devlin",
        "given": "J."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "This paper presents BERT, a groundbreaking PLM that set new benchmarks in NLP tasks"
    ],
    "type": null
  },
  {
    "citation-number": [
      "3."
    ],
    "author": [
      {
        "family": "Radford",
        "given": "A."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "Language Models are Unsupervised Multitask Learners.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "This paper introduces GPT-2, highlighting its capabilities in various NLP tasks through unsupervised learning"
    ],
    "type": null
  },
  {
    "citation-number": [
      "4."
    ],
    "author": [
      {
        "family": "Brown",
        "given": "T."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Language Models are Few-Shot Learners.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "This paper presents GPT-3, showcasing its ability to perform tasks with minimal task-specific training data"
    ],
    "type": null
  },
  {
    "citation-number": [
      "5."
    ],
    "author": [
      {
        "family": "Clark",
        "given": "K."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces ELECTRA, a more sample-efficient approach to pre-training language models"
    ],
    "type": null
  },
  {
    "citation-number": [
      "6."
    ],
    "author": [
      {
        "family": "Raffel",
        "given": "C."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "This paper presents T5, a model that frames all NLP tasks as text-to-text transformations"
    ],
    "type": null
  },
  {
    "citation-number": [
      "7."
    ],
    "author": [
      {
        "family": "Khashabi",
        "given": "D."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "UnifiedQA: Crossing Format Boundaries with a Single QA System.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses a unified question-answering system that works across multiple formats using PLMs"
    ],
    "type": null
  },
  {
    "citation-number": [
      "8."
    ],
    "author": [
      {
        "family": "Lewis",
        "given": "P."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces RAG, a model that combines retrieval mechanisms with generation for improved performance on knowledge-intensive tasks"
    ],
    "type": null
  },
  {
    "citation-number": [
      "9."
    ],
    "author": [
      {
        "family": "Liu",
        "given": "Y."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "RoBERTa: A Robustly Optimized BERT Pretraining Approach.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "This paper presents RoBERTa, an optimized version of BERT that achieves better performance through training modifications"
    ],
    "type": null
  },
  {
    "citation-number": [
      "10."
    ],
    "author": [
      {
        "family": "Lan",
        "given": "Z."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces ALBERT, a lighter and more efficient version of BERT"
    ],
    "type": null
  },
  {
    "citation-number": [
      "11."
    ],
    "author": [
      {
        "family": "Yang",
        "given": "Z."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "XLNet: Generalized Autoregressive Pretraining for Language Understanding.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "This paper presents XLNet, which integrates the best of autoregressive and autoencoding pretraining methods"
    ],
    "type": null
  },
  {
    "citation-number": [
      "12."
    ],
    "author": [
      {
        "family": "Khot",
        "given": "T."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "QASC: A Dataset for Question Answering via Sentence Composition.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces QASC, a dataset designed to test complex reasoning through sentence composition"
    ],
    "type": null
  },
  {
    "citation-number": [
      "13."
    ],
    "author": [
      {
        "family": "Zellers",
        "given": "R."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "HellaSwag: Can a Machine Really Finish Your Sentence?\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses HellaSwag, a dataset for testing commonsense reasoning in PLMs"
    ],
    "type": null
  },
  {
    "citation-number": [
      "14."
    ],
    "author": [
      {
        "family": "Clark",
        "given": "P."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Presents the ARC dataset, designed to challenge models with complex reasoning questions"
    ],
    "type": null
  },
  {
    "citation-number": [
      "15."
    ],
    "author": [
      {
        "family": "Talmor",
        "given": "A."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2019"
    ],
    "title": [
      "CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces CommonsenseQA, a dataset focused on evaluating commonsense reasoning in PLMs"
    ],
    "type": null
  },
  {
    "citation-number": [
      "16."
    ],
    "author": [
      {
        "family": "Rajpurkar",
        "given": "P."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2018"
    ],
    "title": [
      "Know What You Don't Know: Unanswerable Questions for SQuAD.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the addition of unanswerable questions to the SQuAD dataset to test model robustness"
    ],
    "type": null
  },
  {
    "citation-number": [
      "17."
    ],
    "author": [
      {
        "family": "Zhou",
        "given": "B."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Towards Interpretable Natural Language Understanding with Explanations.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Explores methods for making PLMs' reasoning processes more interpretable"
    ],
    "type": null
  },
  {
    "citation-number": [
      "18."
    ],
    "author": [
      {
        "family": "Yin",
        "given": "W."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "TabFact: A Large-scale Dataset for Table-based Fact Verification.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces TabFact, a dataset for evaluating models' abilities to verify facts using tabular data"
    ],
    "type": null
  },
  {
    "citation-number": [
      "19."
    ],
    "author": [
      {
        "family": "Khashabi",
        "given": "D."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "MultiQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Investigates the generalization and transfer capabilities of PLMs across multiple QA datasets"
    ],
    "type": null
  },
  {
    "citation-number": [
      "20."
    ],
    "author": [
      {
        "family": "Ribeiro",
        "given": "M.T."
      },
      {
        "others": true
      }
    ],
    "date": [
      "2020"
    ],
    "title": [
      "Beyond Accuracy: Behavioral Testing of NLP Models with CheckList.\"**"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Proposes CheckList, a methodology for testing NLP models' capabilities beyond accuracy, focusing on behavioral aspects"
    ],
    "type": null
  },
  {
    "title": [
      "These articles cover a range of topics from foundational architectures and models to datasets and evaluation methods, providing a comprehensive overview of complex reasoning in NLP using PLMs"
    ],
    "type": null
  }
]
