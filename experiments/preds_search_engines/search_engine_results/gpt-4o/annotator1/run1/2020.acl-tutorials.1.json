[
  {
    "author": [
      {
        "given": "Certainly!"
      }
    ],
    "title": [
      "Here is a list of 20 articles published before 2021 that focus on the interpretability and analysis of neural network models'"
    ],
    "note": [
      "behaviors in natural language processing (NLP):"
    ],
    "type": null
  },
  {
    "citation-number": [
      "1."
    ],
    "author": [
      {
        "literal": "**\"Attention is not Explanation\"** - Jain, S., & Wallace, B. C."
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "This paper questions the interpretability of attention mechanisms in neural networks"
    ],
    "type": null
  },
  {
    "citation-number": [
      "2."
    ],
    "title": [
      "**\"A Survey of Methods for Interpreting and Understanding Deep Neural Networks\"**"
    ],
    "editor": [
      {
        "family": "Montavon",
        "given": "G."
      },
      {
        "family": "Samek",
        "given": "W."
      },
      {
        "family": "MÃ¼ller",
        "given": "K.R."
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "A comprehensive survey on various methods for interpreting deep neural networks"
    ],
    "type": null
  },
  {
    "citation-number": [
      "3."
    ],
    "title": [
      "**\"Interpreting and Understanding Deep Models in NLP\"**"
    ],
    "editor": [
      {
        "family": "Belinkov",
        "given": "Y."
      },
      {
        "family": "Glass",
        "given": "J."
      }
    ],
    "date": [
      "2019"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "A review of techniques for interpreting and understanding deep learning models in NLP"
    ],
    "type": null
  },
  {
    "citation-number": [
      "4."
    ],
    "author": [
      {
        "literal": "**\"Visualizing and Understanding Neural Models in NLP\"** - Li, J., Chen, X., Hovy, E., & Jurafsky, D."
      }
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "This paper introduces methods for visualizing and understanding neural models in NLP"
    ],
    "type": null
  },
  {
    "citation-number": [
      "5."
    ],
    "author": [
      {
        "literal": "**\"Rationalizing Neural Predictions\"** - Lei, T., Barzilay, R., & Jaakkola, T."
      }
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Proposes a method for generating rationales for neural network predictions"
    ],
    "type": null
  },
  {
    "citation-number": [
      "6."
    ],
    "title": [
      "**\"Learning to Explain: An Information-Theoretic Perspective on Model Interpretation\"**"
    ],
    "editor": [
      {
        "family": "Chen",
        "given": "J."
      },
      {
        "family": "Song",
        "given": "L."
      },
      {
        "family": "Wainwright",
        "given": "M.J."
      },
      {
        "family": "Jordan",
        "given": "M.I."
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses an information-theoretic approach to model interpretation"
    ],
    "type": null
  },
  {
    "citation-number": [
      "7."
    ],
    "author": [
      {
        "given": "L.I.M.E."
      }
    ],
    "title": [
      "Local Interpretable Model-agnostic Explanations\"**"
    ],
    "editor": [
      {
        "family": "Ribeiro",
        "given": "M.T."
      },
      {
        "family": "Singh",
        "given": "S."
      },
      {
        "family": "Guestrin",
        "given": "C."
      }
    ],
    "date": [
      "2016"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces LIME, a technique for explaining the predictions of any classifier"
    ],
    "type": null
  },
  {
    "citation-number": [
      "8."
    ],
    "author": [
      {
        "literal": "**\"Anchors: High-Precision Model-Agnostic Explanations\"** - Ribeiro, M. T., Singh, S., & Guestrin, C."
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Extends LIME to provide high-precision explanations"
    ],
    "type": null
  },
  {
    "citation-number": [
      "9."
    ],
    "author": [
      {
        "given": "DeepLIFT"
      },
      {
        "family": "Shrikumar",
        "given": "A."
      },
      {
        "family": "Greenside",
        "given": "P."
      },
      {
        "family": "Kundaje",
        "given": "A."
      }
    ],
    "title": [
      "Learning Important Features Through Propagating Activation Differences\"**"
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Proposes DeepLIFT, a method for attributing the prediction of a neural network to its input features"
    ],
    "type": null
  },
  {
    "citation-number": [
      "10."
    ],
    "title": [
      "**\"Integrated Gradients: Axiomatic Attribution for Deep Networks\"**"
    ],
    "editor": [
      {
        "family": "Sundararajan",
        "given": "M."
      },
      {
        "family": "Taly",
        "given": "A."
      },
      {
        "family": "Yan",
        "given": "Q."
      }
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces Integrated Gradients, a method for attributing the output of a neural network to its input features"
    ],
    "type": null
  },
  {
    "citation-number": [
      "11."
    ],
    "title": [
      "**\"Explaining Black-box Machine Learning Models through Transparent Approximations\"**"
    ],
    "editor": [
      {
        "family": "Tan",
        "given": "C."
      },
      {
        "family": "Caruana",
        "given": "R."
      },
      {
        "family": "Hooker",
        "given": "G."
      },
      {
        "family": "Lou",
        "given": "Y."
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses methods for approximating black-box models with interpretable models"
    ],
    "type": null
  },
  {
    "citation-number": [
      "12."
    ],
    "title": [
      "**\"Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)\"**"
    ],
    "editor": [
      {
        "family": "Kim",
        "given": "B."
      },
      {
        "family": "Wattenberg",
        "given": "M."
      },
      {
        "family": "Gilmer",
        "given": "J."
      },
      {
        "family": "Cai",
        "given": "C."
      },
      {
        "family": "Wexler",
        "given": "J."
      },
      {
        "family": "Viegas",
        "given": "F."
      },
      {
        "family": "Sayres",
        "given": "R."
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces TCAV, a method for testing the influence of high-level concepts on model predictions"
    ],
    "type": null
  },
  {
    "citation-number": [
      "13."
    ],
    "title": [
      "**\"Contextual Decomposition for Neural Network Interpretability\"**"
    ],
    "editor": [
      {
        "family": "Murdoch",
        "given": "W.J."
      },
      {
        "family": "Szlam",
        "given": "A."
      }
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Proposes Contextual Decomposition, a method for interpreting neural network predictions"
    ],
    "type": null
  },
  {
    "citation-number": [
      "14."
    ],
    "author": [
      {
        "literal": "**\"Evaluating and Understanding the Robustness of Adversarial Logit Pairing\"** - Kannan, H., Kurakin, A., & Goodfellow, I."
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the robustness and interpretability of adversarial training methods"
    ],
    "type": null
  },
  {
    "citation-number": [
      "15."
    ],
    "author": [
      {
        "literal": "**\"The Building Blocks of Interpretability\"** - Olah, C., Satyanarayan, A., Johnson, I., Carter, S., Schubert, L., Ye, K., & Mordvintsev, A."
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Explores the fundamental components of interpretability in neural networks"
    ],
    "type": null
  },
  {
    "citation-number": [
      "16."
    ],
    "author": [
      {
        "literal": "**\"Attention is All You Need\"** - Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I."
      }
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "While primarily about the Transformer model, it has significant implications for interpretability in NLP"
    ],
    "type": null
  },
  {
    "citation-number": [
      "17."
    ],
    "title": [
      "**\"What You Get Is What You See: A Visual Markup Language for Verbalization of Deep Learning Models\"**"
    ],
    "editor": [
      {
        "family": "Strobelt",
        "given": "H."
      },
      {
        "family": "Gehrmann",
        "given": "S."
      },
      {
        "family": "Huber",
        "given": "B."
      },
      {
        "family": "Pfister",
        "given": "H."
      },
      {
        "family": "Rush",
        "given": "A.M."
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Introduces a visual markup language for explaining deep learning models"
    ],
    "type": null
  },
  {
    "citation-number": [
      "18."
    ],
    "title": [
      "**\"Learning Interpretable Models Using the Causal Structure of Data\"**"
    ],
    "editor": [
      {
        "family": "Louizos",
        "given": "C."
      },
      {
        "family": "Shalit",
        "given": "U."
      },
      {
        "family": "Mooij",
        "given": "J.M."
      },
      {
        "family": "Sontag",
        "given": "D."
      },
      {
        "family": "Zemel",
        "given": "R."
      },
      {
        "family": "Welling",
        "given": "M."
      }
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses learning interpretable models by leveraging the causal structure of data"
    ],
    "type": null
  },
  {
    "citation-number": [
      "19."
    ],
    "title": [
      "**\"Interpretability of Neural Networks: A Survey\"**"
    ],
    "editor": [
      {
        "family": "Gilpin",
        "given": "L.H."
      },
      {
        "family": "Bau",
        "given": "D."
      },
      {
        "family": "Yuan",
        "given": "B.Z."
      },
      {
        "family": "Bajwa",
        "given": "A."
      },
      {
        "family": "Specter",
        "given": "M."
      },
      {
        "family": "Kagal",
        "given": "L."
      }
    ],
    "date": [
      "2018"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "A survey on the interpretability of neural networks"
    ],
    "type": null
  },
  {
    "citation-number": [
      "20."
    ],
    "title": [
      "**\"Towards a Rigorous Science of Interpretable Machine Learning\"**"
    ],
    "editor": [
      {
        "family": "Doshi-Velez",
        "given": "F."
      },
      {
        "family": "Kim",
        "given": "B."
      }
    ],
    "date": [
      "2017"
    ],
    "type": null
  },
  {
    "author": [
      {
        "literal": "-"
      }
    ],
    "title": [
      "Discusses the need for a rigorous scientific approach to interpretable machine learning"
    ],
    "type": null
  },
  {
    "title": [
      "These articles cover a range of methods and perspectives on the interpretability and analysis of neural network models in NLP, providing a solid foundation for understanding this important area of research"
    ],
    "type": null
  }
]
