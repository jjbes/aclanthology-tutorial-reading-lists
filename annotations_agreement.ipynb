{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eb9f2f6-ef8e-40e2-ba1b-065bbc184b28",
   "metadata": {},
   "source": [
    "# Annotation agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "121e123d-b194-4eee-80e4-efe97897dc9b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/e154817e/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pke\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import stem\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from typing import Generator, Callable\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "stemmer = stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f40eb8bf-b2e6-4d0f-bca0-fffc26a5bc13",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Clean the string by removing non-alphanumeric characters and converting to lowercase \"\"\"\n",
    "def clean_string(string: str) -> str:\n",
    "    return re.sub(r'\\W+','', string).lower() \n",
    "    \n",
    "\"\"\" Stem the string and converting to lowercase \"\"\"\n",
    "def stem_string(string:str) -> str:\n",
    "    return stemmer.stem(string, to_lowercase=True)\n",
    "\n",
    "\"\"\" Pre-process a list of words \"\"\"\n",
    "def list_word_process(lst:list) -> Generator:\n",
    "    for kp in lst:\n",
    "        for word in kp.split():\n",
    "            clean_word = re.sub('[()]', '', word)\n",
    "            stem = stem_string(clean_word)\n",
    "            if stem not in stops:\n",
    "                yield(stem)\n",
    "                \n",
    "\"\"\" Perform exact match between two lists \"\"\"\n",
    "def exact_match(lst1:list, lst2:list) -> float:\n",
    "    if lst1 == lst2:\n",
    "        return 1\n",
    "    lst1 = list(map(stem_string, lst1))\n",
    "    lst2 = list(map(stem_string, lst2))\n",
    "    inter = list(set(lst1) & set(lst2))\n",
    "    union = list(set(lst1) | set(lst2))\n",
    "    return len(inter) / len(union) if len(union) > 0 else 0\n",
    "    \n",
    "\"\"\" Perform word exact match between two lists \"\"\"\n",
    "def word_exact_match(lst1:list, lst2:list) -> float:\n",
    "    return exact_match(list_word_process(lst1), list_word_process(lst2))\n",
    "    \n",
    "\"\"\" Score two annotations based on a score function \"\"\"\n",
    "def score(annotator1_keyphrases:dict, annotator2_keyphrases:dict, func:Callable=exact_match) -> float:\n",
    "    return sum([func(anot1, anot2) for anot1, anot2 in zip(annotator1_keyphrases, annotator2_keyphrases)])/ max(len(annotator1_keyphrases), len(annotator2_keyphrases))\n",
    "\n",
    "\"\"\" Display results as a matrix \"\"\"\n",
    "def matrix_annotations(annotations_dict:dict, func:Callable=word_exact_match, cols:list=[]) -> pd.DataFrame:\n",
    "    data = defaultdict(lambda : defaultdict(list))\n",
    "    for k, annotations in annotations_dict.items():\n",
    "        for col in cols:\n",
    "            data[k][col]= score(annotations, annotations_dict[col], func=func)\n",
    "    return pd.DataFrame(data).transpose()\n",
    "    \n",
    "\"\"\" Split keyphrases as singular expressions \"\"\"\n",
    "def split_queries_keyphrases(queries:list) -> list:\n",
    "    queries = queries.replace(np.nan, \"\")\n",
    "    return [[v.strip() for v in query.strip().split(\",\")] if query.strip().split(\",\") != [''] else [] for query in queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b68cb3c1-803d-42f0-9190-22b0734e5bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_lists = pd.read_csv(\"reading_lists.csv\")\n",
    "reading_lists = reading_lists.replace(np.nan, None)\n",
    "\n",
    "queries_kps = {}\n",
    "for annotator_i in [1,2,3, \"bart\"]:\n",
    "    queries_kps[annotator_i] = split_queries_keyphrases(pd.read_csv(f\"annotations/annotation_{annotator_i}.csv\")[\"query_keywords\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f621ed07-4a4c-4ef7-b664-bf4b865b6074",
   "metadata": {},
   "source": [
    "## Mean keyphrases queries amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5d9b5b4-3965-4f51-9672-b89f52f0b4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean # of KP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>2.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>3.835294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3</th>\n",
       "      <td>2.341176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bart-Large-KP20K</th>\n",
       "      <td>4.447059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Mean # of KP\n",
       "A1                    2.705882\n",
       "A2                    3.835294\n",
       "A3                    2.341176\n",
       "Bart-Large-KP20K      4.447059"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"A1\": np.mean([len(kws) for kws in queries_kps[1]]),\n",
    "    \"A2\": np.mean([len(kws) for kws in queries_kps[2]]), \n",
    "    \"A3\": np.mean([len(kws) for kws in queries_kps[3]]), \n",
    "    \"Bart-Large-KP20K\": np.mean([len(kws) for kws in queries_kps[\"bart\"]])\n",
    "}, index=[\"Mean # of KP\"]).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9651e56-bbec-419f-826c-348b261dbded",
   "metadata": {},
   "source": [
    "## Agreement of annotators and comparison to baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb6e9105-2abf-47a4-a774-31dc190772db",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstphrase_title_keyphrases = []\n",
    "\n",
    "for title in reading_lists[\"title\"]:\n",
    "    extractor = pke.unsupervised.FirstPhrases()\n",
    "    extractor.load_document(input=title, language='en')\n",
    "    extractor.candidate_selection()\n",
    "    extractor.candidate_weighting()\n",
    "    keyphrases = extractor.get_n_best(n=3)\n",
    "    firstphrase_title_keyphrases.append([kp_tuple[0] for kp_tuple in keyphrases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5324ad14-2d01-4758-89d7-fbe471b080b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "topicrank_keyphrases = []\n",
    "\n",
    "for title,abstract in zip(reading_lists[\"title\"],reading_lists[\"abstract\"]):\n",
    "    extractor = pke.unsupervised.TopicRank()\n",
    "    extractor.load_document(input=title+\"\\n \"+(abstract or \"\"), language='en')\n",
    "    extractor.candidate_selection()\n",
    "    extractor.candidate_weighting()\n",
    "    keyphrases = extractor.get_n_best(n=3)\n",
    "    topicrank_keyphrases.append([kp_tuple[0] for kp_tuple in keyphrases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77cd1af0-d02f-4026-a393-dd5489523110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3529411764705883"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(kws) for kws in firstphrase_title_keyphrases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "529e45a7-37c5-408f-a98b-ca4d8a00a43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(kws) for kws in topicrank_keyphrases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fb2f817-d5f5-4233-9d72-733aa6427099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = [\"A1\", \"A2\", \"A3\"]\n",
    "annotations = {\n",
    "    \"A1\":queries_kps[1],\n",
    "    \"A2\":queries_kps[2], \n",
    "    \"A3\":queries_kps[3], \n",
    "\n",
    "    \"FirstPhrase Title\":firstphrase_title_keyphrases, \n",
    "    \"TopicRank\":topicrank_keyphrases, \n",
    "    \"Bart-Large-KP20K\":queries_kps[\"bart\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abfc97d8-2c30-4767-86fa-fb5fafeb586d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305374</td>\n",
       "      <td>0.537675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>0.305374</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.313214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3</th>\n",
       "      <td>0.537675</td>\n",
       "      <td>0.313214</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FirstPhrase Title</th>\n",
       "      <td>0.403280</td>\n",
       "      <td>0.269857</td>\n",
       "      <td>0.404577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TopicRank</th>\n",
       "      <td>0.368888</td>\n",
       "      <td>0.230942</td>\n",
       "      <td>0.407870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bart-Large-KP20K</th>\n",
       "      <td>0.412099</td>\n",
       "      <td>0.325121</td>\n",
       "      <td>0.380824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         A1        A2        A3\n",
       "A1                 1.000000  0.305374  0.537675\n",
       "A2                 0.305374  1.000000  0.313214\n",
       "A3                 0.537675  0.313214  1.000000\n",
       "FirstPhrase Title  0.403280  0.269857  0.404577\n",
       "TopicRank          0.368888  0.230942  0.407870\n",
       "Bart-Large-KP20K   0.412099  0.325121  0.380824"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = matrix_annotations(annotations, func=word_exact_match, cols=columns); df\n",
    "#print(df.to_latex(float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70179a1-95ee-4547-a04d-2b844a4c0cf2",
   "metadata": {},
   "source": [
    "## Agreement of annotators on sentence queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac2fa675-ef64-4983-addb-e0f6533d5e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_sentences = {}\n",
    "for annotator_i in [1,2,3]:\n",
    "    annotator_sentences = [query.strip() for query in pd.read_csv(f\"annotations/annotation_{annotator_i}.csv\")[\"query_sentence\"].replace(np.nan, \"\")]\n",
    "    queries_sentences[annotator_i] = [[clean_string(stem_string(w)) for w in s.split() if w not in stops] for s in annotator_sentences]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0659b731-80e0-43fa-926f-1c8d8be88d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = [\"A1\", \"A2\", \"A3\"]\n",
    "annotations_sentences = {\n",
    "    \"A1\":queries_sentences[1],\n",
    "    \"A2\":queries_sentences[2], \n",
    "    \"A3\":queries_sentences[3], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87c9fdc3-1be0-4234-b00b-bf9fdf8e1659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.411043</td>\n",
       "      <td>0.603139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>0.411043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.406821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3</th>\n",
       "      <td>0.603139</td>\n",
       "      <td>0.406821</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A1        A2        A3\n",
       "A1  1.000000  0.411043  0.603139\n",
       "A2  0.411043  1.000000  0.406821\n",
       "A3  0.603139  0.406821  1.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = matrix_annotations(annotations_sentences, func=word_exact_match, cols=columns); df\n",
    "#print(df.to_latex(float_format=\"%.2f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
